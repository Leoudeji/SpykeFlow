{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "* This notebook has implementations of `Backprop` with binary spike feature vectors obtained from the `SPIKEFLOW`. Here, we will use tf.data API. Here the shape of the inputs is `[None, n_input]` instead of `[n_input, None]`. We had to do this because nested elements in `from_tensor_slices` must have the same dimension in 0th rank [see](https://stackoverflow.com/questions/49579684/what-is-the-difference-between-dataset-from-tensors-and-dataset-from-tensor-slic). Everytime an iterator `iter = dataset.make_initializable_iterator()` gets initialized, the dataset is randomly shuffled so we need not shuffle again, [see](https://stackoverflow.com/questions/49579684/what-is-the-difference-between-dataset-from-tensors-and-dataset-from-tensor-slic).\n",
    "## References\n",
    "* [Neural Nets](http://neuralnetworksanddeeplearning.com/chap3.html)\n",
    "* [Randombackprop](https://github.com/xuexue/randombp/blob/master/randombp.py)\n",
    "* [Randombackprop](https://github.com/sangyi92/feedback_alignment/blob/master/RFA.ipynb)\n",
    "* [Backprop](http://blog.aloni.org/posts/backprop-with-tensorflow/)\n",
    "* [Initializers](https://towardsdatascience.com/hyper-parameters-in-action-part-ii-weight-initializers-35aee1a28404)\n",
    "* [Dropout](https://github.com/pinae/TensorFlow-MNIST-example/blob/master/fully-connected.py)\n",
    "* [Softmax](https://stackoverflow.com/questions/34240703/what-is-logits-softmax-and-softmax-cross-entropy-with-logits)\n",
    "* [SoftmaxLogits](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits)\n",
    "* [TF memory leaks when  assigning in loop](https://github.com/tensorflow/tensorflow/issues/4151)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import tensorflow as tf\n",
    "from IPython.display import display, HTML\n",
    "tf.compat.v2.random.set_seed(0)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.client import timeline\n",
    "import h5py, pickle\n",
    "from keras.utils.np_utils import to_categorical \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import MNIST_Loader\n",
    "import seaborn as sb\n",
    "import theano, random, sys, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow' from '/home/ruthvik/.local/lib/python2.7/site-packages/tensorflow/__init__.pyc'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "print(tf.__version__)\n",
    "tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hide code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       "if (code_show){\n",
       "$('div.input').hide();\n",
       "} else {\n",
       "$('div.input').show();\n",
       "}\n",
       "code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    "if (code_show){\n",
    "$('div.input').hide();\n",
    "} else {\n",
    "$('div.input').show();\n",
    "}\n",
    "code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = 3.75,3\n",
    "mpl.rcParams['axes.titlesize'] = 12\n",
    "mpl.rcParams['axes.labelsize'] = 12\n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "mpl.rcParams['lines.markersize'] = 10\n",
    "mpl.rcParams['xtick.labelsize'] = 12\n",
    "mpl.rcParams['ytick.labelsize'] = 12\n",
    "mpl.rcParams['legend.fontsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = 15,10\n",
    "mpl.rcParams['axes.titlesize'] = 24\n",
    "mpl.rcParams['axes.labelsize'] = 25\n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "mpl.rcParams['lines.markersize'] = 10\n",
    "mpl.rcParams['xtick.labelsize'] = 30\n",
    "mpl.rcParams['ytick.labelsize'] = 22\n",
    "mpl.rcParams['legend.fontsize'] = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and separate set1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = MNIST_Loader.load_data_wrapper()\n",
    "#### LOAD TRAIN AND VALIDATION DATA AND LABELS\n",
    "train_images = np.concatenate([train_data[0], validation_data[0]], axis=0)\n",
    "train_labels = train_data[1] + validation_data[1]\n",
    "train_labels = np.array(train_labels)\n",
    "test_images = test_data[0]\n",
    "test_labels = np.array(test_data[1])\n",
    "num_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "#### EXTRACT REQUIRED LOCATIONS OF 0 TO 5 FOR TRAIN DATA\n",
    "def extract_class_data(start=0, stop=1):\n",
    "    set1_locs = np.where((train_labels>=start) & (train_labels<=stop))[0]\n",
    "    train_labels_set1 = to_categorical(train_labels[set1_locs], num_classes=num_classes)\n",
    "    train_images_set1 = train_images[set1_locs,:]\n",
    "    n_images = len(train_images_set1)\n",
    "\n",
    "    #### EXTRACT REQUIRED LOCATIONS OF 0 TO 5 FOR TEST DATA\n",
    "    set1_locs = np.where((test_labels>=start) & (test_labels<=stop))[0]\n",
    "    test_labels_set1 = to_categorical(test_labels[set1_locs], num_classes=num_classes)\n",
    "    test_images_set1 = test_images[set1_locs,:]\n",
    "    print('Test features:{}'.format(test_images_set1.shape))\n",
    "    print('Length of test labels:{}'.format(test_labels_set1.shape[0]))\n",
    "    test_data_set1 = (test_images_set1, test_labels_set1)\n",
    "    \n",
    "\n",
    "\n",
    "    train_images_set1 = train_images_set1[int(0.09*n_images):]\n",
    "    train_labels_set1 = train_labels_set1[int(0.09*n_images):]\n",
    "    print('Train features:{}'.format(train_images_set1.shape))\n",
    "    print('Length of train labels:{}'.format(train_labels_set1.shape[0]))\n",
    "    train_data_set1 = (train_images_set1, train_labels_set1)\n",
    "\n",
    "    valid_labels_set1 = train_labels_set1[0:int(0.09*n_images)]\n",
    "    valid_images_set1 = train_images_set1[0:int(0.09*n_images)]\n",
    "    print('Valid features:{}'.format(valid_images_set1.shape))\n",
    "    print('Length of valid labels:{}'.format(valid_labels_set1.shape[0]))\n",
    "    valid_data_set1 = (valid_images_set1, valid_labels_set1)\n",
    "    \n",
    "    n_train_set1 = train_labels_set1.shape[0]\n",
    "    n_test_set1 = test_labels_set1.shape[0]\n",
    "    n_valid_set1 = valid_labels_set1.shape[0]\n",
    "\n",
    "    return train_data_set1, valid_data_set1, test_data_set1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess= tf.InteractiveSession(config=config)\n",
    "run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "run_metadata = tf.RunMetadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$tanh(x) = \\frac{(e^{x} â€“ e^{-x})}{(e^{x} + e^{-x})}$\n",
    "\n",
    "$d\\frac{tanh(x)}{dx} = 1 â€“ (tanh(x))^{2}$\n",
    "\n",
    "$\\sigma(x) = \\frac{1.0}{1 + e^{-x}}$\n",
    "\n",
    "$d\\frac{\\sigma(x)}{dx} = \\sigma(x)*(1 - \\sigma(x))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the network graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784\n",
    "n_middle = 1024\n",
    "n_out = 10\n",
    "batch_size = tf.placeholder(tf.int64, name='batch_size') \n",
    "a_1 = tf.placeholder(tf.float32, [None, n_input], name = 'Input_batch')\n",
    "y = tf.placeholder(tf.float32, [None, n_out], name = 'output_batch')\n",
    "dataset = tf.data.Dataset.from_tensor_slices((a_1, y))\n",
    "#dataset = dataset.shuffle(buffer_size=len(all_train_labels), reshuffle_each_iteration=True)\n",
    "dataset = dataset.batch(batch_size)\n",
    "iter = dataset.make_initializable_iterator()\n",
    "features, labels = iter.get_next()\n",
    "\n",
    "drop_out = tf.placeholder(tf.float32)\n",
    "tau = tf.placeholder(tf.float32)\n",
    "set1_mask = tf.placeholder(tf.float32, [10], name='mask')\n",
    "eta = tf.placeholder(tf.float32)\n",
    "n_tot = tf.placeholder(tf.float32)\n",
    "lmbda = tf.placeholder(tf.float32, name='lambda')\n",
    "with tf.name_scope('hid_lyr_w_b'):  ###havier or glorot initialization\n",
    "    low = -4*tf.math.sqrt(6.0/(n_input + n_middle)) # use 4 for sigmoid, 1 for tanh activation \n",
    "    high = 4*tf.math.sqrt(6.0/(n_input + n_middle))\n",
    "    \n",
    "    low = -tf.math.sqrt(2.0/(n_input)) # use 4 for sigmoid, 1 for tanh activation \n",
    "    high = tf.math.sqrt(2.0/(n_input))\n",
    "    \n",
    "    w_2 = tf.Variable(tf.random_uniform(shape=[n_input,n_middle],minval=low,maxval=high), name = 'W_2')\n",
    "    #w_2 = tf.Variable(tf.truncated_normal(shape=[n_input,n_middle], stddev=0.01),name = 'W_2')\n",
    "    tf.summary.histogram('w_2', w_2)\n",
    "    b_2 = tf.Variable(tf.zeros([1,n_middle]), name = 'b_2')\n",
    "    tf.summary.histogram('b_2', b_2)\n",
    "    \n",
    "    w2_grad_accum = tf.Variable(np.zeros(shape=[n_input,n_middle], dtype=np.float32), name='w2_grad_accum')\n",
    "    b2_grad_accum = tf.Variable(np.zeros(shape=[1,n_middle], dtype=np.float32), name='b2_grad_accum')\n",
    "    \n",
    "    big_omeg_w2 = tf.Variable(np.zeros(shape=[n_input,n_middle], dtype=np.float32), name='omeg_w2')\n",
    "    tf.summary.histogram('big_omeg_w2', big_omeg_w2)\n",
    "    big_omeg_b2 = tf.Variable(np.zeros(shape=[1,n_middle], dtype=np.float32), name='omeg_b2')\n",
    "    tf.summary.histogram('big_omeg_b2', big_omeg_b2)\n",
    "    \n",
    "    star_w2 = tf.Variable(np.zeros(shape=[n_input,n_middle], dtype=np.float32), name='star_w2')\n",
    "    star_b2 = tf.Variable(np.zeros(shape=[1,n_middle], dtype=np.float32), name='star_b2')\n",
    "with tf.name_scope('op_lyr_w_b'):\n",
    "    \n",
    "    low = -tf.math.sqrt(2.0/(n_middle))\n",
    "    high = tf.math.sqrt(2.0/(n_middle))\n",
    "    w_3 = tf.Variable(tf.random_uniform(shape=[n_middle,10],minval=low,maxval=high), name = 'W_3')\n",
    "    #w_3 = tf.Variable(tf.truncated_normal(shape=[n_middle,n_out], stddev=0.01),name = 'W_3')\n",
    "    tf.summary.histogram('w_3', w_3)\n",
    "    b_3 = tf.Variable(tf.zeros([1,n_out]), name = 'b_3')\n",
    "    tf.summary.histogram('b_3', b_3)\n",
    "    \n",
    "    w3_grad_accum = tf.Variable(np.zeros(shape=[n_middle,n_out], dtype=np.float32), name='w3_grad_accum')\n",
    "    b3_grad_accum = tf.Variable(np.zeros(shape=[1,n_out], dtype=np.float32), name='b3_grad_accum')\n",
    "    \n",
    "    big_omeg_w3 = tf.Variable(np.zeros(shape=[n_middle,n_out], dtype=np.float32), name='omeg_w3')\n",
    "    tf.summary.histogram('big_omeg_w3', big_omeg_w3)\n",
    "    big_omeg_b3 = tf.Variable(np.zeros(shape=[1,n_out], dtype=np.float32), name='omeg_b3')\n",
    "    tf.summary.histogram('big_omeg_b3', big_omeg_b3)\n",
    "    \n",
    "    star_w3 = tf.Variable(np.zeros(shape=[n_middle,n_out], dtype=np.float32), name='star_w3')\n",
    "    star_b3 = tf.Variable(np.zeros(shape=[1,n_out], dtype=np.float32), name='star_b3')\n",
    "\n",
    "def sigma(x):\n",
    "    return tf.math.divide(tf.constant(1.0),\n",
    "                  tf.add(tf.constant(1.0), tf.exp(tf.negative(x))))\n",
    "def tanh(x):\n",
    "    return tf.math.divide(tf.subtract(tf.exp(x), tf.exp(tf.negative(x))), \n",
    "                          tf.add(tf.exp(x), tf.exp(tf.negative(x))) )\n",
    "\n",
    "def sigmaprime(x):\n",
    "    return tf.multiply(sigma(x), tf.subtract(tf.constant(1.0), sigma(x)))\n",
    "\n",
    "def tanhprime(x):\n",
    "    return tf.subtract(tf.constant(1.0),tf.square(tanh(x)))\n",
    "\n",
    "def spkNeuron(x):\n",
    "    return tf.where(tf.greater_equal(x,0.0), tf.ones_like(x), \n",
    "                        tf.zeros_like(x))\n",
    "\n",
    "def ReLU(x):\n",
    "    return tf.maximum(0.0, x)\n",
    "\n",
    "def ReLUprime(x):\n",
    "    return tf.where(tf.greater_equal(x,0.0), tf.ones_like(x), \n",
    "                        tf.zeros_like(x))\n",
    "\n",
    "def spkPrime1(x):\n",
    "    l1_bound_higher = tf.greater_equal(x,-0/4)\n",
    "    r1_bound_lesser = tf.less_equal(x,tau/4) \n",
    "    grad_one = tf.where(tf.logical_and(l1_bound_higher,r1_bound_lesser), tf.ones_like(x), tf.zeros_like(x))\n",
    "    return grad_one\n",
    "\n",
    "def firstLyrSpks(x):\n",
    "    return tf.where(tf.greater_equal(x,1.0), tf.ones_like(x), \n",
    "                        tf.zeros_like(x))\n",
    "\n",
    "    \n",
    "with tf.name_scope('hid_lyr_acti'):\n",
    "    z_2 = tf.add(tf.matmul(features,w_2,name = 'w_2xa_1'), b_2, name = 'z_2')\n",
    "    locs_to_drop = tf.random.categorical(tf.math.log([[1.0-drop_out, drop_out]]), tf.size(z_2))\n",
    "    locs_to_drop = tf.reshape(locs_to_drop, tf.shape(z_2))\n",
    "    z_2 = tf.where(locs_to_drop>0,-tf.ones_like(z_2),z_2, 'drop_out_app')\n",
    "    tf.summary.histogram('z_2', z_2)\n",
    "    a_2 = ReLU(z_2)\n",
    "    #@a_2 = sigma(z_2)\n",
    "    tf.summary.histogram('a_2', a_2)\n",
    "with tf.name_scope('op_lyr_acti'):\n",
    "    z_3 = tf.add(tf.matmul(a_2,w_3, name = 'w_3xa_2'),b_3, name = 'z_3')\n",
    "    #@z_3 = tf.floor(z_3)\n",
    "    #z_3 = tf.subtract(tf.reduce_max(z_3),z_3, name = 'inhibition')\n",
    "    tf.summary.histogram('z_3', z_3)\n",
    "    #@a_3  = sigma(z_3) ##UNCOMMENT THIS LINE AND COMMENT ABOVE LINE IF YOU WANT spike SQUISHING\n",
    "    a_3 = tf.cast(tf.nn.softmax(z_3,axis=1), tf.float32)\n",
    "    a_3 = tf.multiply(a_3, set1_mask, name='masking')\n",
    "    tf.summary.histogram('a_3', a_3)\n",
    "    ##COMMENT THE ABOVE LINE AND UNCOMMENT BELOW LINE IF YOU WANT SOFTMAX\n",
    "    #a_3 = tf.nn.softmax(z_3,axis=1) ##AXIS IS VERY IMPORTANT!!! axis=1 INDICATES THE CLASSES AS y IS [None,10]\n",
    "\n",
    "#cost = tf.reduce_mean(-tf.reduce_sum((y*tf.log(a_3) +tf.log(1-a_3)*(1-y)) ,axis=0), name = 'cost_calc') WORKS, USE BELOW\n",
    "with tf.name_scope('cost_calc'):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels,logits=z_3,axis=1),\n",
    "                          name = 'cost_calc')#WORKS\n",
    "        ##COMMENT BELOW LINES IF YOU WANT quadratic\n",
    "    #@dc_da = tf.multiply(-tf.subtract(labels,a_3, name = 'y_minus_a_3'), mask)\n",
    "    #@cost = tf.reduce_mean(tf.reduce_sum((1/2.0)*tf.square(dc_da),axis=1), name = 'cost_calc')\n",
    "    tf.summary.scalar('cost', cost)\n",
    "\n",
    "with tf.name_scope('op_lyr_grad'):\n",
    "    #@d_z_3 = tf.multiply(-tf.subtract(labels,a_3, name = 'delta3'), mask, name='masking')\n",
    "    d_z_3 = -tf.subtract(labels,a_3, name = 'delta3')\n",
    "    #d_z_3 = tf.multiply(dc_da,a_3, name = 'delta3')\n",
    "    d_b_3 = tf.expand_dims(tf.reduce_mean(d_z_3, axis=[0]), axis=0)\n",
    "    tf.summary.histogram('d_b_3', d_b_3)\n",
    "    d_w_3 = tf.multiply(1/tf.cast(batch_size, tf.float32),\n",
    "                        tf.matmul(tf.transpose(a_2),d_z_3), \n",
    "                        name='delta_w3')\n",
    "    tf.summary.histogram('d_w_3', d_w_3)\n",
    "    \n",
    "with tf.name_scope('hid_lyr_grad'):\n",
    "    d_z_2 = tf.multiply(tf.matmul(d_z_3,tf.transpose(w_3), name = 'w_3Txdelta3'), ReLUprime(z_2),\n",
    "                        name = 'delta2')\n",
    "    #@d_z_2 = tf.multiply(tf.matmul(d_z_3,tf.transpose(w_3), name = 'w_3Txdelta3'), sigmaprime(z_2),\n",
    "    #@                    name = 'delta2')\n",
    "    #d_z_2 = tf.matmul(d_z_3,tf.transpose(w_3), name = 'delta2')\n",
    "    d_b_2 = tf.expand_dims(tf.reduce_mean(d_z_2, axis=[0]), axis=0)\n",
    "    tf.summary.histogram('d_b_2', d_b_2)\n",
    "    d_w_2 = tf.multiply(1/tf.cast(batch_size, tf.float32),\n",
    "                        tf.matmul(tf.transpose(features),d_z_2), \n",
    "                        name='delta_w2')\n",
    "    tf.summary.histogram('d_w_2', d_w_2)\n",
    "    \n",
    "omega_step=[tf.assign(w2_grad_accum,\n",
    "                      tf.add(w2_grad_accum,tf.multiply(eta*eta*lmbda/n_tot, tf.square(d_w_2))),\n",
    "                     name='update_omeg_w2'),\n",
    "            tf.assign(b2_grad_accum,\n",
    "                      tf.add(b2_grad_accum,tf.multiply(eta*eta*lmbda/n_tot,tf.square(d_b_2))),\n",
    "                     name='update_omeg_b2'),\n",
    "            \n",
    "            tf.assign(w3_grad_accum,\n",
    "                      tf.add(w3_grad_accum,tf.multiply(eta*eta*lmbda/n_tot,tf.square(d_w_3))),\n",
    "                     name='update_omeg_w3'),\n",
    "            tf.assign(b3_grad_accum, \n",
    "                      tf.add(b3_grad_accum,tf.multiply(eta*eta*lmbda/n_tot,tf.square(d_b_3))),\n",
    "                     name='update_omeg_b3')\n",
    "]\n",
    "\n",
    "step = [tf.assign(w_2,\n",
    "                  tf.subtract(w_2, (eta*d_w_2+big_omeg_w2*(w_2-star_w2))),name='update_w_2'),\n",
    "        tf.assign(b_2,\n",
    "                  tf.subtract(b_2,(eta*d_b_2+big_omeg_b2*(b_2-star_b2))),name='update_b_2'),\n",
    "        \n",
    "        tf.assign(w_3,\n",
    "                  tf.subtract(w_3, (eta*d_w_3+big_omeg_w3*(w_3-star_w3))),name='update_w_3'),\n",
    "        tf.assign(b_3,\n",
    "                  tf.subtract(b_3,(eta*d_b_3+big_omeg_b3*(b_3-star_b3))),name='update_b_3')    \n",
    "]\n",
    "\n",
    "with tf.name_scope('acc_calc'):\n",
    "    predictions = tf.argmax(a_3, 1)\n",
    "    acct_mat = tf.equal(tf.argmax(a_3, 1), tf.argmax(labels, 1))\n",
    "    acct_res = tf.reduce_mean(tf.cast(acct_mat, tf.float32))\n",
    "    tf.summary.scalar('accuracy', acct_res)\n",
    "\n",
    "#valid_writer = tf.summary.FileWriter(path + '/valid')\n",
    "init_op = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/ruthvik/Desktop/Summer 2017/tf_graph_outputs/mnist/continual_learning/original_mnist_5sets'\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(path + '/3lyrs_working_he2', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametrization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test features:(2115, 784)\n",
      "Length of test labels:2115\n",
      "Train features:(11526, 784)\n",
      "Length of train labels:11526\n",
      "Valid features:(1139, 784)\n",
      "Length of valid labels:1139\n",
      "Number of batches:1152\n",
      "Repeat:0\n",
      "Epoch:0\n",
      "training cost:2.20772242546 and training accuracy:0.594308495522\n",
      "validation cost:2.20485949516 and validation accuracy:0.571554005146\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.54452800751\n",
      "Epoch:1\n",
      "training cost:0.0543882250786 and training accuracy:0.996095776558\n",
      "validation cost:0.0496128760278 and validation accuracy:0.996488153934\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.35335111618\n",
      "Epoch:2\n",
      "training cost:0.0173014551401 and training accuracy:0.996356070042\n",
      "validation cost:0.0151770692319 and validation accuracy:0.997366130352\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.23783493042\n",
      "Epoch:3\n",
      "training cost:0.0124439811334 and training accuracy:0.996703088284\n",
      "validation cost:0.0105488812551 and validation accuracy:0.997366130352\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.3752758503\n",
      "Epoch:4\n",
      "training cost:0.0107799610123 and training accuracy:0.996703088284\n",
      "validation cost:0.00898107979447 and validation accuracy:0.997366130352\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.20129704475\n",
      "Epoch:5\n",
      "training cost:0.00994363985956 and training accuracy:0.99705016613\n",
      "validation cost:0.00821624789387 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.85251903534\n",
      "Epoch:6\n",
      "training cost:0.00936370529234 and training accuracy:0.997310400009\n",
      "validation cost:0.00772946095094 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:5.20616102219\n",
      "Epoch:7\n",
      "training cost:0.00901820883155 and training accuracy:0.997397184372\n",
      "validation cost:0.00742879370227 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.2385160923\n",
      "Epoch:8\n",
      "training cost:0.00871908478439 and training accuracy:0.997570693493\n",
      "validation cost:0.00718992156908 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.23115491867\n",
      "Epoch:9\n",
      "training cost:0.00848461594433 and training accuracy:0.997570693493\n",
      "validation cost:0.00701280590147 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.21756696701\n",
      "Epoch:10\n",
      "training cost:0.00828528776765 and training accuracy:0.997657477856\n",
      "validation cost:0.00685535138473 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.22985601425\n",
      "Epoch:11\n",
      "training cost:0.00809861999005 and training accuracy:0.997744202614\n",
      "validation cost:0.00671265041456 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.19098997116\n",
      "Epoch:12\n",
      "training cost:0.00792435836047 and training accuracy:0.997830986977\n",
      "validation cost:0.00659008743241 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.19890904427\n",
      "Epoch:13\n",
      "training cost:0.00778018590063 and training accuracy:0.997830986977\n",
      "validation cost:0.00647558365017 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.21508097649\n",
      "Epoch:14\n",
      "training cost:0.0076654497534 and training accuracy:0.997917771339\n",
      "validation cost:0.00638009468094 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.20942902565\n",
      "Epoch:15\n",
      "training cost:0.00755988061428 and training accuracy:0.998004496098\n",
      "validation cost:0.00625367183238 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.66563010216\n",
      "Epoch:16\n",
      "training cost:0.00746481167153 and training accuracy:0.998004496098\n",
      "validation cost:0.00615832861513 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.22674798965\n",
      "Epoch:17\n",
      "training cost:0.00736973807216 and training accuracy:0.998004496098\n",
      "validation cost:0.00607455940917 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.17043709755\n",
      "Epoch:18\n",
      "training cost:0.00728667154908 and training accuracy:0.998004496098\n",
      "validation cost:0.00598159665242 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.17831587791\n",
      "Epoch:19\n",
      "training cost:0.0072300452739 and training accuracy:0.998004496098\n",
      "validation cost:0.00588010856882 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.23720002174\n",
      "Epoch:20\n",
      "training cost:0.00715100765228 and training accuracy:0.998004496098\n",
      "validation cost:0.00579831656069 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.20221590996\n",
      "Epoch:21\n",
      "training cost:0.00706317508593 and training accuracy:0.99809128046\n",
      "validation cost:0.00572935631499 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.30638599396\n",
      "Epoch:22\n",
      "training cost:0.00699253752828 and training accuracy:0.998004496098\n",
      "validation cost:0.00566297257319 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.54041099548\n",
      "Epoch:23\n",
      "training cost:0.00692423572764 and training accuracy:0.998004496098\n",
      "validation cost:0.00560115184635 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.19860005379\n",
      "Epoch:24\n",
      "training cost:0.00685201166198 and training accuracy:0.998004496098\n",
      "validation cost:0.00552543671802 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.16782093048\n",
      "Epoch:25\n",
      "training cost:0.00679116975516 and training accuracy:0.998004496098\n",
      "validation cost:0.00548940896988 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.16284894943\n",
      "Epoch:26\n",
      "training cost:0.00672783935443 and training accuracy:0.99809128046\n",
      "validation cost:0.00542954681441 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.19905018806\n",
      "Epoch:27\n",
      "training cost:0.00667061144486 and training accuracy:0.998264789581\n",
      "validation cost:0.00539473863319 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.18228077888\n",
      "Epoch:28\n",
      "training cost:0.00660954834893 and training accuracy:0.998351573944\n",
      "validation cost:0.00533944927156 and validation accuracy:0.999122023582\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.28320217133\n",
      "Epoch:29\n",
      "training cost:0.00655563548207 and training accuracy:0.998351573944\n",
      "validation cost:0.00529595511034 and validation accuracy:0.999122023582\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.42085003853\n",
      "Final test accuracy is:0.999054372311\n",
      "Test accuracy corresp to best val acc:0.999054372311\n",
      "Time taken:131.947491169\n",
      "omegW2-MAXIMUM:0.000248527707299,MEAN:3.812873274e-06,STD:1.16960954983e-05\n",
      "omegb2-MAXIMUM:0.000258599524386,MEAN:3.79661141778e-05,STD:4.59323637187e-05\n",
      "omegW3-MAXIMUM:0.004571064841,MEAN:7.68311365391e-05,STD:0.000252731872024\n",
      "omegb3-MAXIMUM:0.00108292582445,MEAN:0.000144777703099,STD:0.000331094983267\n",
      "Test features:(2042, 784)\n",
      "Length of test labels:2042\n",
      "Train features:(11001, 784)\n",
      "Length of train labels:11001\n",
      "Valid features:(1088, 784)\n",
      "Length of valid labels:1088\n",
      "Number of batches:1100\n",
      "Repeat:0\n",
      "Epoch:0\n",
      "training cost:16.4852294922 and training accuracy:0.487137526274\n",
      "validation cost:16.600151062 and validation accuracy:0.488970577717\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.026512146\n",
      "Epoch:1\n",
      "training cost:0.245519146323 and training accuracy:0.934824109077\n",
      "validation cost:0.238070994616 and validation accuracy:0.939338207245\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.01633119583\n",
      "Epoch:2\n",
      "training cost:0.156462132931 and training accuracy:0.944186866283\n",
      "validation cost:0.142640680075 and validation accuracy:0.949448525906\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.00916600227\n",
      "Epoch:3\n",
      "training cost:0.133650451899 and training accuracy:0.949640929699\n",
      "validation cost:0.118132673204 and validation accuracy:0.954963207245\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.02563619614\n",
      "Epoch:4\n",
      "training cost:0.123811408877 and training accuracy:0.954458713531\n",
      "validation cost:0.108343154192 and validation accuracy:0.962316155434\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.04341697693\n",
      "Epoch:5\n",
      "training cost:0.118500702083 and training accuracy:0.957912921906\n",
      "validation cost:0.10313320905 and validation accuracy:0.962316155434\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.02567791939\n",
      "Epoch:6\n",
      "training cost:0.114882841706 and training accuracy:0.959821820259\n",
      "validation cost:0.100815057755 and validation accuracy:0.964154422283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.50461697578\n",
      "Epoch:7\n",
      "training cost:0.112192161381 and training accuracy:0.961458027363\n",
      "validation cost:0.0985598862171 and validation accuracy:0.966911792755\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.02665519714\n",
      "Epoch:8\n",
      "training cost:0.11004268378 and training accuracy:0.963276088238\n",
      "validation cost:0.097419038415 and validation accuracy:0.96875\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.03833389282\n",
      "Epoch:9\n",
      "training cost:0.108921259642 and training accuracy:0.964912295341\n",
      "validation cost:0.0965344458818 and validation accuracy:0.969669103622\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.01312303543\n",
      "Epoch:10\n",
      "training cost:0.106779709458 and training accuracy:0.964639604092\n",
      "validation cost:0.0957153439522 and validation accuracy:0.969669103622\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.0172150135\n",
      "Epoch:11\n",
      "training cost:0.1052871719 and training accuracy:0.965912163258\n",
      "validation cost:0.0954381525517 and validation accuracy:0.96875\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.03074193001\n",
      "Epoch:12\n",
      "training cost:0.104265533388 and training accuracy:0.966821193695\n",
      "validation cost:0.0951072275639 and validation accuracy:0.96875\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.00886511803\n",
      "Epoch:13\n",
      "training cost:0.10315657407 and training accuracy:0.967093884945\n",
      "validation cost:0.0951543748379 and validation accuracy:0.96875\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.46730113029\n",
      "Epoch:14\n",
      "training cost:0.102472804487 and training accuracy:0.967366576195\n",
      "validation cost:0.0944819077849 and validation accuracy:0.971507370472\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.14602708817\n",
      "Epoch:15\n",
      "training cost:0.101557008922 and training accuracy:0.967730224133\n",
      "validation cost:0.0948882773519 and validation accuracy:0.969669103622\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.01384615898\n",
      "Epoch:16\n",
      "training cost:0.101026035845 and training accuracy:0.967912018299\n",
      "validation cost:0.0944523364305 and validation accuracy:0.96875\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.04655790329\n",
      "Epoch:17\n",
      "training cost:0.0999726429582 and training accuracy:0.968730092049\n",
      "validation cost:0.0944756865501 and validation accuracy:0.969669103622\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.008934021\n",
      "Epoch:18\n",
      "training cost:0.0990531295538 and training accuracy:0.968820989132\n",
      "validation cost:0.0950415655971 and validation accuracy:0.96875\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.01327610016\n",
      "Epoch:19\n",
      "training cost:0.098433278501 and training accuracy:0.96918463707\n",
      "validation cost:0.0949072316289 and validation accuracy:0.96875\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.00747799873\n",
      "Epoch:20\n",
      "training cost:0.0980651900172 and training accuracy:0.970184504986\n",
      "validation cost:0.0940961912274 and validation accuracy:0.973345577717\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.47895097733\n",
      "Epoch:21\n",
      "training cost:0.0973763093352 and training accuracy:0.970184504986\n",
      "validation cost:0.0941278710961 and validation accuracy:0.971507370472\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.03212308884\n",
      "Epoch:22\n",
      "training cost:0.0966280028224 and training accuracy:0.970275402069\n",
      "validation cost:0.0944323390722 and validation accuracy:0.972426474094\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.01974487305\n",
      "Epoch:23\n",
      "training cost:0.095931135118 and training accuracy:0.971093535423\n",
      "validation cost:0.0936029404402 and validation accuracy:0.972426474094\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.01948809624\n",
      "Epoch:24\n",
      "training cost:0.0954489782453 and training accuracy:0.971093535423\n",
      "validation cost:0.0936459675431 and validation accuracy:0.973345577717\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.00848889351\n",
      "Epoch:25\n",
      "training cost:0.0949521288276 and training accuracy:0.971457123756\n",
      "validation cost:0.0933434888721 and validation accuracy:0.974264681339\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.0304851532\n",
      "Epoch:26\n",
      "training cost:0.0943357497454 and training accuracy:0.97127532959\n",
      "validation cost:0.0938069671392 and validation accuracy:0.972426474094\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.01730489731\n",
      "Epoch:27\n",
      "training cost:0.0939461141825 and training accuracy:0.971366226673\n",
      "validation cost:0.0935966446996 and validation accuracy:0.972426474094\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.50102901459\n",
      "Epoch:28\n",
      "training cost:0.0934194400907 and training accuracy:0.971457123756\n",
      "validation cost:0.0935052186251 and validation accuracy:0.972426474094\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.03504180908\n",
      "Epoch:29\n",
      "training cost:0.0927740260959 and training accuracy:0.971366226673\n",
      "validation cost:0.0935215130448 and validation accuracy:0.972426474094\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.01177310944\n",
      "Final test accuracy is:0.975514173508\n",
      "Test accuracy corresp to best val acc:0.973555326462\n",
      "Time taken:124.812798977\n",
      "Testing accuracy on :set0 after training :set1 is :0.999527215958\n",
      "omegW2-MAXIMUM:0.00212089670822,MEAN:4.13884918089e-05,STD:0.000111130051664\n",
      "omegb2-MAXIMUM:0.0034514607396,MEAN:0.000371982110664,STD:0.000491212878842\n",
      "omegW3-MAXIMUM:0.0561068542302,MEAN:0.000893270713277,STD:0.00310454936698\n",
      "omegb3-MAXIMUM:0.00331533909775,MEAN:0.000647099572234,STD:0.00105008541141\n",
      "Test features:(1874, 784)\n",
      "Length of test labels:1874\n",
      "Train features:(10250, 784)\n",
      "Length of train labels:10250\n",
      "Valid features:(1013, 784)\n",
      "Length of valid labels:1013\n",
      "Number of batches:1025\n",
      "Repeat:0\n",
      "Epoch:0\n",
      "training cost:32.5637245178 and training accuracy:0.515804886818\n",
      "validation cost:32.3236083984 and validation accuracy:0.507403731346\n",
      "Testing accuracy on :set0 while training :set2 is :0.999527215958\n",
      "Testing accuracy on :set1 while training :set2 is :0.975514173508\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.71504497528\n",
      "Epoch:1\n",
      "training cost:0.216292068362 and training accuracy:0.920975625515\n",
      "validation cost:0.222394496202 and validation accuracy:0.921026647091\n",
      "Testing accuracy on :set0 while training :set2 is :0.998108744621\n",
      "Testing accuracy on :set1 while training :set2 is :0.968658149242\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.73333001137\n",
      "Epoch:2\n",
      "training cost:0.14464867115 and training accuracy:0.945658564568\n",
      "validation cost:0.143940225244 and validation accuracy:0.95360314846\n",
      "Testing accuracy on :set0 while training :set2 is :0.998108744621\n",
      "Testing accuracy on :set1 while training :set2 is :0.970617055893\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.7410531044\n",
      "Epoch:3\n",
      "training cost:0.110809117556 and training accuracy:0.958341479301\n",
      "validation cost:0.104807540774 and validation accuracy:0.967423498631\n",
      "Testing accuracy on :set0 while training :set2 is :0.998581588268\n",
      "Testing accuracy on :set1 while training :set2 is :0.972575902939\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.73671293259\n",
      "Epoch:4\n",
      "training cost:0.090975061059 and training accuracy:0.96624392271\n",
      "validation cost:0.08222399652 and validation accuracy:0.976307988167\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.972575902939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on :(4, 5)\n",
      "Epoch time:3.73360705376\n",
      "Epoch:5\n",
      "training cost:0.0786709412932 and training accuracy:0.971317052841\n",
      "validation cost:0.0686297863722 and validation accuracy:0.97828233242\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.972575902939\n",
      "Training on :(4, 5)\n",
      "Epoch time:4.27945399284\n",
      "Epoch:6\n",
      "training cost:0.0702411979437 and training accuracy:0.974634170532\n",
      "validation cost:0.0593448355794 and validation accuracy:0.97828233242\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.9730656147\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.73884296417\n",
      "Epoch:7\n",
      "training cost:0.0640175268054 and training accuracy:0.977170705795\n",
      "validation cost:0.0526843182743 and validation accuracy:0.97828233242\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.9730656147\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.73680210114\n",
      "Epoch:8\n",
      "training cost:0.059231556952 and training accuracy:0.979317069054\n",
      "validation cost:0.0474772937596 and validation accuracy:0.980256676674\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.9730656147\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.82185602188\n",
      "Epoch:9\n",
      "training cost:0.0562739558518 and training accuracy:0.979707300663\n",
      "validation cost:0.0444719493389 and validation accuracy:0.979269504547\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.973555326462\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.74077916145\n",
      "Epoch:10\n",
      "training cost:0.0530967265368 and training accuracy:0.981658518314\n",
      "validation cost:0.0410276465118 and validation accuracy:0.983218193054\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.974534749985\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.74647378922\n",
      "Epoch:11\n",
      "training cost:0.0506602451205 and training accuracy:0.982829272747\n",
      "validation cost:0.0384375527501 and validation accuracy:0.987166821957\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.974534749985\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.73526096344\n",
      "Epoch:12\n",
      "training cost:0.0487568601966 and training accuracy:0.98400002718\n",
      "validation cost:0.0364616028965 and validation accuracy:0.987166821957\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.974045038223\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.85636091232\n",
      "Epoch:13\n",
      "training cost:0.0469598174095 and training accuracy:0.985268294811\n",
      "validation cost:0.0345566011965 and validation accuracy:0.988153994083\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.974534749985\n",
      "Training on :(4, 5)\n",
      "Epoch time:4.3173251152\n",
      "Epoch:14\n",
      "training cost:0.0458492897451 and training accuracy:0.985756099224\n",
      "validation cost:0.0336123891175 and validation accuracy:0.988153994083\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.974534749985\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.77233314514\n",
      "Epoch:15\n",
      "training cost:0.044866874814 and training accuracy:0.985756099224\n",
      "validation cost:0.0326873101294 and validation accuracy:0.988153994083\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.974534749985\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.73948097229\n",
      "Epoch:16\n",
      "training cost:0.0433443151414 and training accuracy:0.986243903637\n",
      "validation cost:0.030660841614 and validation accuracy:0.991115510464\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.974534749985\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.72418022156\n",
      "Epoch:17\n",
      "training cost:0.0428395755589 and training accuracy:0.986536562443\n",
      "validation cost:0.0305597726256 and validation accuracy:0.990128338337\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.975024461746\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.71316313744\n",
      "Epoch:18\n",
      "training cost:0.0421403907239 and training accuracy:0.986634135246\n",
      "validation cost:0.0299773290753 and validation accuracy:0.990128338337\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.975024461746\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.72986006737\n",
      "Epoch:19\n",
      "training cost:0.0412377156317 and training accuracy:0.986926853657\n",
      "validation cost:0.0290064997971 and validation accuracy:0.990128338337\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.975024461746\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.78403782845\n",
      "Epoch:20\n",
      "training cost:0.0404704362154 and training accuracy:0.987024366856\n",
      "validation cost:0.028124043718 and validation accuracy:0.990128338337\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.975024461746\n",
      "Training on :(4, 5)\n",
      "Epoch time:4.22444820404\n",
      "Epoch:21\n",
      "training cost:0.0398085080087 and training accuracy:0.987121939659\n",
      "validation cost:0.027472788468 and validation accuracy:0.991115510464\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.975024461746\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.78812003136\n",
      "Epoch:22\n",
      "training cost:0.0393152795732 and training accuracy:0.987512171268\n",
      "validation cost:0.0271841045469 and validation accuracy:0.991115510464\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.975024461746\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.74223685265\n",
      "Epoch:23\n",
      "training cost:0.0387316644192 and training accuracy:0.987707316875\n",
      "validation cost:0.0266422089189 and validation accuracy:0.991115510464\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.975514173508\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.72960782051\n",
      "Epoch:24\n",
      "training cost:0.0382221452892 and training accuracy:0.987707316875\n",
      "validation cost:0.0262069329619 and validation accuracy:0.991115510464\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.975514173508\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.73415493965\n",
      "Epoch:25\n",
      "training cost:0.0377125442028 and training accuracy:0.987999975681\n",
      "validation cost:0.0256874300539 and validation accuracy:0.991115510464\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.975514173508\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.72703194618\n",
      "Epoch:26\n",
      "training cost:0.0378292426467 and training accuracy:0.987902462482\n",
      "validation cost:0.0262563806027 and validation accuracy:0.99210268259\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.975514173508\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.73758292198\n",
      "Epoch:27\n",
      "training cost:0.0371277108788 and training accuracy:0.988097548485\n",
      "validation cost:0.0255136229098 and validation accuracy:0.99210268259\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.975514173508\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.73452997208\n",
      "Epoch:28\n",
      "training cost:0.0368269495666 and training accuracy:0.988097548485\n",
      "validation cost:0.0252507925034 and validation accuracy:0.99210268259\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.975514173508\n",
      "Training on :(4, 5)\n",
      "Epoch time:4.21342396736\n",
      "Epoch:29\n",
      "training cost:0.0363251715899 and training accuracy:0.988487780094\n",
      "validation cost:0.0247345715761 and validation accuracy:0.993089854717\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.975514173508\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.73715186119\n",
      "Final test accuracy is:0.989327669144\n",
      "Test accuracy corresp to best val acc:0.989327669144\n",
      "Time taken:116.15706706\n",
      "Testing accuracy on :set0 after training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 after training :set2 is :0.975514173508\n",
      "omegW2-MAXIMUM:0.00215943832882,MEAN:7.36628135201e-05,STD:0.000158225186169\n",
      "omegb2-MAXIMUM:0.00435763690621,MEAN:0.000789288198575,STD:0.000772574567236\n",
      "omegW3-MAXIMUM:0.0561068542302,MEAN:0.00144635816105,STD:0.00363082438707\n",
      "omegb3-MAXIMUM:0.00331533909775,MEAN:0.00106364896055,STD:0.00120268121827\n",
      "Test features:(1986, 784)\n",
      "Length of test labels:1986\n",
      "Train features:(11087, 784)\n",
      "Length of train labels:11087\n",
      "Valid features:(1096, 784)\n",
      "Length of valid labels:1096\n",
      "Number of batches:1108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat:0\n",
      "Epoch:0\n",
      "training cost:49.0008888245 and training accuracy:0.444123744965\n",
      "validation cost:50.2406654358 and validation accuracy:0.453467160463\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.975514173508\n",
      "Testing accuracy on :set2 while training :set3 is :0.989327669144\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.08173108101\n",
      "Epoch:1\n",
      "training cost:0.0464920438826 and training accuracy:0.992423534393\n",
      "validation cost:0.0425009094179 and validation accuracy:0.991788327694\n",
      "Testing accuracy on :set0 while training :set3 is :0.99669033289\n",
      "Testing accuracy on :set1 while training :set3 is :0.971596479416\n",
      "Testing accuracy on :set2 while training :set3 is :0.982924222946\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.08504486084\n",
      "Epoch:2\n",
      "training cost:0.0274979751557 and training accuracy:0.994588255882\n",
      "validation cost:0.0252999477088 and validation accuracy:0.993613123894\n",
      "Testing accuracy on :set0 while training :set3 is :0.997163116932\n",
      "Testing accuracy on :set1 while training :set3 is :0.9730656147\n",
      "Testing accuracy on :set2 while training :set3 is :0.983991444111\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.08433580399\n",
      "Epoch:3\n",
      "training cost:0.0218625981361 and training accuracy:0.994588255882\n",
      "validation cost:0.0202251151204 and validation accuracy:0.994525551796\n",
      "Testing accuracy on :set0 while training :set3 is :0.998581588268\n",
      "Testing accuracy on :set1 while training :set3 is :0.972086191177\n",
      "Testing accuracy on :set2 while training :set3 is :0.983991444111\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.08662199974\n",
      "Epoch:4\n",
      "training cost:0.0180311594158 and training accuracy:0.995309829712\n",
      "validation cost:0.0166016183794 and validation accuracy:0.994525551796\n",
      "Testing accuracy on :set0 while training :set3 is :0.998581588268\n",
      "Testing accuracy on :set1 while training :set3 is :0.973555326462\n",
      "Testing accuracy on :set2 while training :set3 is :0.98505872488\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.09918904305\n",
      "Epoch:5\n",
      "training cost:0.0161001514643 and training accuracy:0.995400011539\n",
      "validation cost:0.0148138403893 and validation accuracy:0.994525551796\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.973555326462\n",
      "Testing accuracy on :set2 while training :set3 is :0.986659526825\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.55280303955\n",
      "Epoch:6\n",
      "training cost:0.0147013803944 and training accuracy:0.995490193367\n",
      "validation cost:0.0135020567104 and validation accuracy:0.994525551796\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.973555326462\n",
      "Testing accuracy on :set2 while training :set3 is :0.98719316721\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.13077712059\n",
      "Epoch:7\n",
      "training cost:0.0140335485339 and training accuracy:0.995760798454\n",
      "validation cost:0.0129153532907 and validation accuracy:0.994525551796\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.973555326462\n",
      "Testing accuracy on :set2 while training :set3 is :0.987726807594\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.08828186989\n",
      "Epoch:8\n",
      "training cost:0.0128431105986 and training accuracy:0.996031403542\n",
      "validation cost:0.0116762891412 and validation accuracy:0.995437979698\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.973555326462\n",
      "Testing accuracy on :set2 while training :set3 is :0.988260388374\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.0803809166\n",
      "Epoch:9\n",
      "training cost:0.0118916574866 and training accuracy:0.996572554111\n",
      "validation cost:0.0106960777193 and validation accuracy:0.996350347996\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.974045038223\n",
      "Testing accuracy on :set2 while training :set3 is :0.988260388374\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.08891916275\n",
      "Epoch:10\n",
      "training cost:0.0116036329418 and training accuracy:0.996662735939\n",
      "validation cost:0.010456177406 and validation accuracy:0.996350347996\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.974534749985\n",
      "Testing accuracy on :set2 while training :set3 is :0.989327669144\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.09610700607\n",
      "Epoch:11\n",
      "training cost:0.0111158648506 and training accuracy:0.996752977371\n",
      "validation cost:0.00998251419514 and validation accuracy:0.996350347996\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.974534749985\n",
      "Testing accuracy on :set2 while training :set3 is :0.989327669144\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.08898997307\n",
      "Epoch:12\n",
      "training cost:0.0105257378891 and training accuracy:0.996843159199\n",
      "validation cost:0.00935436785221 and validation accuracy:0.996350347996\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.974534749985\n",
      "Testing accuracy on :set2 while training :set3 is :0.989327669144\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.33950400352\n",
      "Epoch:13\n",
      "training cost:0.0100638000295 and training accuracy:0.997294127941\n",
      "validation cost:0.00885962415487 and validation accuracy:0.997262775898\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.974534749985\n",
      "Testing accuracy on :set2 while training :set3 is :0.989327669144\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.3771750927\n",
      "Epoch:14\n",
      "training cost:0.00985198561102 and training accuracy:0.997294127941\n",
      "validation cost:0.00864896830171 and validation accuracy:0.997262775898\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.974534749985\n",
      "Testing accuracy on :set2 while training :set3 is :0.989327669144\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.1070330143\n",
      "Epoch:15\n",
      "training cost:0.00957227312028 and training accuracy:0.997474491596\n",
      "validation cost:0.00832927133888 and validation accuracy:0.997262775898\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.975514173508\n",
      "Testing accuracy on :set2 while training :set3 is :0.989327669144\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.10406804085\n",
      "Epoch:16\n",
      "training cost:0.00949736963958 and training accuracy:0.997384309769\n",
      "validation cost:0.00826462823898 and validation accuracy:0.997262775898\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.975514173508\n",
      "Testing accuracy on :set2 while training :set3 is :0.989327669144\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.12348604202\n",
      "Epoch:17\n",
      "training cost:0.00905579514802 and training accuracy:0.997654914856\n",
      "validation cost:0.00778860691935 and validation accuracy:0.997262775898\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.975514173508\n",
      "Testing accuracy on :set2 while training :set3 is :0.989327669144\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.09519290924\n",
      "Epoch:18\n",
      "training cost:0.00886582955718 and training accuracy:0.997654914856\n",
      "validation cost:0.00759489322081 and validation accuracy:0.997262775898\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.975514173508\n",
      "Testing accuracy on :set2 while training :set3 is :0.989327669144\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.09489893913\n",
      "Epoch:19\n",
      "training cost:0.00868824031204 and training accuracy:0.997745096684\n",
      "validation cost:0.00739677296951 and validation accuracy:0.997262775898\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.975514173508\n",
      "Testing accuracy on :set2 while training :set3 is :0.989327669144\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.33479213715\n",
      "Epoch:20\n",
      "training cost:0.00853875745088 and training accuracy:0.997745096684\n",
      "validation cost:0.00722043728456 and validation accuracy:0.997262775898\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.976003944874\n",
      "Testing accuracy on :set2 while training :set3 is :0.989327669144\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.27752494812\n",
      "Epoch:21\n",
      "training cost:0.00840082298964 and training accuracy:0.997745096684\n",
      "validation cost:0.00706168217584 and validation accuracy:0.997262775898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.976003944874\n",
      "Testing accuracy on :set2 while training :set3 is :0.989327669144\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.13152813911\n",
      "Epoch:22\n",
      "training cost:0.00807881262153 and training accuracy:0.997745096684\n",
      "validation cost:0.00669263862073 and validation accuracy:0.997262775898\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.975514173508\n",
      "Testing accuracy on :set2 while training :set3 is :0.989327669144\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.09088087082\n",
      "Epoch:23\n",
      "training cost:0.00818093121052 and training accuracy:0.997925519943\n",
      "validation cost:0.00679019698873 and validation accuracy:0.997262775898\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.975514173508\n",
      "Testing accuracy on :set2 while training :set3 is :0.989327669144\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.08992314339\n",
      "Epoch:24\n",
      "training cost:0.00779335247353 and training accuracy:0.997745096684\n",
      "validation cost:0.00636118976399 and validation accuracy:0.997262775898\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.975514173508\n",
      "Testing accuracy on :set2 while training :set3 is :0.989861249924\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.08772301674\n",
      "Epoch:25\n",
      "training cost:0.00764072872698 and training accuracy:0.997745096684\n",
      "validation cost:0.00618368433788 and validation accuracy:0.997262775898\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.975514173508\n",
      "Testing accuracy on :set2 while training :set3 is :0.989861249924\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.07701778412\n",
      "Epoch:26\n",
      "training cost:0.00738498428836 and training accuracy:0.997835278511\n",
      "validation cost:0.0059005562216 and validation accuracy:0.997262775898\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.975024461746\n",
      "Testing accuracy on :set2 while training :set3 is :0.989861249924\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.13088083267\n",
      "Epoch:27\n",
      "training cost:0.0074012405239 and training accuracy:0.997835278511\n",
      "validation cost:0.00590414879844 and validation accuracy:0.997262775898\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.975024461746\n",
      "Testing accuracy on :set2 while training :set3 is :0.989861249924\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.48893094063\n",
      "Epoch:28\n",
      "training cost:0.00738049764186 and training accuracy:0.997745096684\n",
      "validation cost:0.00588236795738 and validation accuracy:0.997262775898\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.975024461746\n",
      "Testing accuracy on :set2 while training :set3 is :0.989861249924\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.09702396393\n",
      "Epoch:29\n",
      "training cost:0.00728551764041 and training accuracy:0.997835278511\n",
      "validation cost:0.00576571049169 and validation accuracy:0.997262775898\n",
      "Testing accuracy on :set0 while training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set3 is :0.975024461746\n",
      "Testing accuracy on :set2 while training :set3 is :0.989861249924\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.07976794243\n",
      "Final test accuracy is:0.994964778423\n",
      "Test accuracy corresp to best val acc:0.993454158306\n",
      "Time taken:126.930417061\n",
      "Testing accuracy on :set0 after training :set3 is :0.999054372311\n",
      "Testing accuracy on :set1 after training :set3 is :0.975024461746\n",
      "Testing accuracy on :set2 after training :set3 is :0.989861249924\n",
      "omegW2-MAXIMUM:0.00323532242328,MEAN:0.000100421006209,STD:0.000206974858884\n",
      "omegb2-MAXIMUM:0.007821906358,MEAN:0.00118653522804,STD:0.00112983805593\n",
      "omegW3-MAXIMUM:0.0561068542302,MEAN:0.00176075811032,STD:0.00364928808995\n",
      "omegb3-MAXIMUM:0.00331533909775,MEAN:0.0013229312608,STD:0.00109665771015\n",
      "Test features:(1983, 784)\n",
      "Length of test labels:1983\n",
      "Train features:(10738, 784)\n",
      "Length of train labels:10738\n",
      "Valid features:(1062, 784)\n",
      "Length of valid labels:1062\n",
      "Number of batches:1073\n",
      "Repeat:0\n",
      "Epoch:0\n",
      "training cost:72.9506835938 and training accuracy:0.230489850044\n",
      "validation cost:74.2315444946 and validation accuracy:0.211864411831\n",
      "Testing accuracy on :set0 while training :set4 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set4 is :0.975024461746\n",
      "Testing accuracy on :set2 while training :set4 is :0.989861249924\n",
      "Testing accuracy on :set3 while training :set4 is :0.994964778423\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.9829390049\n",
      "Epoch:1\n",
      "training cost:0.149885743856 and training accuracy:0.953436374664\n",
      "validation cost:0.13262988627 and validation accuracy:0.960451960564\n",
      "Testing accuracy on :set0 while training :set4 is :0.976359367371\n",
      "Testing accuracy on :set1 while training :set4 is :0.918217420578\n",
      "Testing accuracy on :set2 while training :set4 is :0.986125946045\n",
      "Testing accuracy on :set3 while training :set4 is :0.993957698345\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.99152684212\n",
      "Epoch:2\n",
      "training cost:0.118686705828 and training accuracy:0.958930909634\n",
      "validation cost:0.0986110419035 and validation accuracy:0.964218437672\n",
      "Testing accuracy on :set0 while training :set4 is :0.991489350796\n",
      "Testing accuracy on :set1 while training :set4 is :0.956415295601\n",
      "Testing accuracy on :set2 while training :set4 is :0.986659526825\n",
      "Testing accuracy on :set3 while training :set4 is :0.993957698345\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.98190402985\n",
      "Epoch:3\n",
      "training cost:0.109469912946 and training accuracy:0.961165964603\n",
      "validation cost:0.0885116532445 and validation accuracy:0.96233522892\n",
      "Testing accuracy on :set0 while training :set4 is :0.996217489243\n",
      "Testing accuracy on :set1 while training :set4 is :0.966699302197\n",
      "Testing accuracy on :set2 while training :set4 is :0.988260388374\n",
      "Testing accuracy on :set3 while training :set4 is :0.993957698345\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.99424099922\n",
      "Epoch:4\n",
      "training cost:0.104595638812 and training accuracy:0.962842226028\n",
      "validation cost:0.0823707506061 and validation accuracy:0.96798491478\n",
      "Testing accuracy on :set0 while training :set4 is :0.998581588268\n",
      "Testing accuracy on :set1 while training :set4 is :0.967678725719\n",
      "Testing accuracy on :set2 while training :set4 is :0.988260388374\n",
      "Testing accuracy on :set3 while training :set4 is :0.993957698345\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.46358799934\n",
      "Epoch:5\n",
      "training cost:0.101137779653 and training accuracy:0.964239180088\n",
      "validation cost:0.0782287195325 and validation accuracy:0.969868183136\n",
      "Testing accuracy on :set0 while training :set4 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set4 is :0.968168437481\n",
      "Testing accuracy on :set2 while training :set4 is :0.988260388374\n",
      "Testing accuracy on :set3 while training :set4 is :0.993454158306\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.99909710884\n",
      "Epoch:6\n",
      "training cost:0.0983774662018 and training accuracy:0.965636074543\n",
      "validation cost:0.0745513364673 and validation accuracy:0.970809817314\n",
      "Testing accuracy on :set0 while training :set4 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set4 is :0.968168437481\n",
      "Testing accuracy on :set2 while training :set4 is :0.988794028759\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.00203585625\n",
      "Epoch:7\n",
      "training cost:0.096985667944 and training accuracy:0.966753602028\n",
      "validation cost:0.0722951516509 and validation accuracy:0.971751391888\n",
      "Testing accuracy on :set0 while training :set4 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set4 is :0.96963763237\n",
      "Testing accuracy on :set2 while training :set4 is :0.989861249924\n",
      "Testing accuracy on :set3 while training :set4 is :0.993454158306\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.98180317879\n",
      "Epoch:8\n",
      "training cost:0.0943889096379 and training accuracy:0.967498600483\n",
      "validation cost:0.0693665221334 and validation accuracy:0.973634660244\n",
      "Testing accuracy on :set0 while training :set4 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set4 is :0.970127344131\n",
      "Testing accuracy on :set2 while training :set4 is :0.990394890308\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch time:3.98341703415\n",
      "Epoch:9\n",
      "training cost:0.0929265171289 and training accuracy:0.968243598938\n",
      "validation cost:0.067307010293 and validation accuracy:0.974576294422\n",
      "Testing accuracy on :set0 while training :set4 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set4 is :0.970127344131\n",
      "Testing accuracy on :set2 while training :set4 is :0.990928471088\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.99142193794\n",
      "Epoch:10\n",
      "training cost:0.0911535844207 and training accuracy:0.968802392483\n",
      "validation cost:0.0650940388441 and validation accuracy:0.975517868996\n",
      "Testing accuracy on :set0 while training :set4 is :0.999527215958\n",
      "Testing accuracy on :set1 while training :set4 is :0.970127344131\n",
      "Testing accuracy on :set2 while training :set4 is :0.990928471088\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.0674829483\n",
      "Epoch:11\n",
      "training cost:0.089786529541 and training accuracy:0.969733655453\n",
      "validation cost:0.0631843358278 and validation accuracy:0.975517868996\n",
      "Testing accuracy on :set0 while training :set4 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set4 is :0.970617055893\n",
      "Testing accuracy on :set2 while training :set4 is :0.990928471088\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.56436395645\n",
      "Epoch:12\n",
      "training cost:0.088876105845 and training accuracy:0.970013022423\n",
      "validation cost:0.0617853812873 and validation accuracy:0.976459503174\n",
      "Testing accuracy on :set0 while training :set4 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set4 is :0.971106767654\n",
      "Testing accuracy on :set2 while training :set4 is :0.990928471088\n",
      "Testing accuracy on :set3 while training :set4 is :0.992447137833\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.152354002\n",
      "Epoch:13\n",
      "training cost:0.0874504894018 and training accuracy:0.970199286938\n",
      "validation cost:0.0600609779358 and validation accuracy:0.977401137352\n",
      "Testing accuracy on :set0 while training :set4 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set4 is :0.971596479416\n",
      "Testing accuracy on :set2 while training :set4 is :0.990928471088\n",
      "Testing accuracy on :set3 while training :set4 is :0.992447137833\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.98973202705\n",
      "Epoch:14\n",
      "training cost:0.0868415310979 and training accuracy:0.970385551453\n",
      "validation cost:0.0589629933238 and validation accuracy:0.977401137352\n",
      "Testing accuracy on :set0 while training :set4 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set4 is :0.972086191177\n",
      "Testing accuracy on :set2 while training :set4 is :0.991462111473\n",
      "Testing accuracy on :set3 while training :set4 is :0.992447137833\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.97822189331\n",
      "Epoch:15\n",
      "training cost:0.0856473892927 and training accuracy:0.970851182938\n",
      "validation cost:0.0575124584138 and validation accuracy:0.977401137352\n",
      "Testing accuracy on :set0 while training :set4 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set4 is :0.972086191177\n",
      "Testing accuracy on :set2 while training :set4 is :0.991462111473\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.98833298683\n",
      "Epoch:16\n",
      "training cost:0.0845788195729 and training accuracy:0.971316814423\n",
      "validation cost:0.0562009401619 and validation accuracy:0.977401137352\n",
      "Testing accuracy on :set0 while training :set4 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set4 is :0.972575902939\n",
      "Testing accuracy on :set2 while training :set4 is :0.991462111473\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.96520709991\n",
      "Epoch:17\n",
      "training cost:0.0843624696136 and training accuracy:0.971782445908\n",
      "validation cost:0.0555057041347 and validation accuracy:0.97834277153\n",
      "Testing accuracy on :set0 while training :set4 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set4 is :0.972575902939\n",
      "Testing accuracy on :set2 while training :set4 is :0.991995751858\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.99304294586\n",
      "Epoch:18\n",
      "training cost:0.0830671191216 and training accuracy:0.972620606422\n",
      "validation cost:0.0539966486394 and validation accuracy:0.979284346104\n",
      "Testing accuracy on :set0 while training :set4 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set4 is :0.972575902939\n",
      "Testing accuracy on :set2 while training :set4 is :0.991995751858\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.48687601089\n",
      "Epoch:19\n",
      "training cost:0.0825756639242 and training accuracy:0.972993135452\n",
      "validation cost:0.0530927814543 and validation accuracy:0.979284346104\n",
      "Testing accuracy on :set0 while training :set4 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set4 is :0.972575902939\n",
      "Testing accuracy on :set2 while training :set4 is :0.991995751858\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.00017786026\n",
      "Epoch:20\n",
      "training cost:0.0820582956076 and training accuracy:0.973272502422\n",
      "validation cost:0.0526339411736 and validation accuracy:0.979284346104\n",
      "Testing accuracy on :set0 while training :set4 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set4 is :0.972575902939\n",
      "Testing accuracy on :set2 while training :set4 is :0.991995751858\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.99716997147\n",
      "Epoch:21\n",
      "training cost:0.0822357237339 and training accuracy:0.972806870937\n",
      "validation cost:0.0524593815207 and validation accuracy:0.980225980282\n",
      "Testing accuracy on :set0 while training :set4 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set4 is :0.972086191177\n",
      "Testing accuracy on :set2 while training :set4 is :0.991995751858\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.0070848465\n",
      "Epoch:22\n",
      "training cost:0.0819586515427 and training accuracy:0.972713708878\n",
      "validation cost:0.0520502664149 and validation accuracy:0.980225980282\n",
      "Testing accuracy on :set0 while training :set4 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set4 is :0.972086191177\n",
      "Testing accuracy on :set2 while training :set4 is :0.991995751858\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.0012691021\n",
      "Epoch:23\n",
      "training cost:0.0800954699516 and training accuracy:0.974017500877\n",
      "validation cost:0.0500236079097 and validation accuracy:0.980225980282\n",
      "Testing accuracy on :set0 while training :set4 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set4 is :0.972086191177\n",
      "Testing accuracy on :set2 while training :set4 is :0.991995751858\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.97924613953\n",
      "Epoch:24\n",
      "training cost:0.0806339457631 and training accuracy:0.973644971848\n",
      "validation cost:0.0502858608961 and validation accuracy:0.980225980282\n",
      "Testing accuracy on :set0 while training :set4 is :0.998581588268\n",
      "Testing accuracy on :set1 while training :set4 is :0.971596479416\n",
      "Testing accuracy on :set2 while training :set4 is :0.991462111473\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.99264907837\n",
      "Epoch:25\n",
      "training cost:0.0795726031065 and training accuracy:0.973831236362\n",
      "validation cost:0.0492238178849 and validation accuracy:0.980225980282\n",
      "Testing accuracy on :set0 while training :set4 is :0.998581588268\n",
      "Testing accuracy on :set1 while training :set4 is :0.971596479416\n",
      "Testing accuracy on :set2 while training :set4 is :0.991462111473\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.13320302963\n",
      "Epoch:26\n",
      "training cost:0.0788974687457 and training accuracy:0.974110662937\n",
      "validation cost:0.048383295536 and validation accuracy:0.980225980282\n",
      "Testing accuracy on :set0 while training :set4 is :0.998581588268\n",
      "Testing accuracy on :set1 while training :set4 is :0.971596479416\n",
      "Testing accuracy on :set2 while training :set4 is :0.991995751858\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch time:4.28892302513\n",
      "Epoch:27\n",
      "training cost:0.078252337873 and training accuracy:0.974483132362\n",
      "validation cost:0.0474344417453 and validation accuracy:0.980225980282\n",
      "Testing accuracy on :set0 while training :set4 is :0.998581588268\n",
      "Testing accuracy on :set1 while training :set4 is :0.971596479416\n",
      "Testing accuracy on :set2 while training :set4 is :0.991995751858\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.99735498428\n",
      "Epoch:28\n",
      "training cost:0.0780679285526 and training accuracy:0.974762499332\n",
      "validation cost:0.0471792221069 and validation accuracy:0.982109248638\n",
      "Testing accuracy on :set0 while training :set4 is :0.998581588268\n",
      "Testing accuracy on :set1 while training :set4 is :0.971596479416\n",
      "Testing accuracy on :set2 while training :set4 is :0.991462111473\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.97563409805\n",
      "Epoch:29\n",
      "training cost:0.0762803703547 and training accuracy:0.974855661392\n",
      "validation cost:0.0453692488372 and validation accuracy:0.980225980282\n",
      "Testing accuracy on :set0 while training :set4 is :0.998581588268\n",
      "Testing accuracy on :set1 while training :set4 is :0.971596479416\n",
      "Testing accuracy on :set2 while training :set4 is :0.991995751858\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.98872804642\n",
      "Final test accuracy is:0.969742834568\n",
      "Test accuracy corresp to best val acc:0.969238519669\n",
      "Time taken:124.052070141\n",
      "Testing accuracy on :set0 after training :set4 is :0.998581588268\n",
      "Testing accuracy on :set1 after training :set4 is :0.971106767654\n",
      "Testing accuracy on :set2 after training :set4 is :0.991462111473\n",
      "Testing accuracy on :set3 after training :set4 is :0.992950677872\n",
      "omegW2-MAXIMUM:0.00323532242328,MEAN:0.000100421006209,STD:0.000206974858884\n",
      "omegb2-MAXIMUM:0.007821906358,MEAN:0.00118653522804,STD:0.00112983805593\n",
      "omegW3-MAXIMUM:0.0561068542302,MEAN:0.00176075811032,STD:0.00364928808995\n",
      "omegb3-MAXIMUM:0.00331533909775,MEAN:0.0013229312608,STD:0.00109665771015\n"
     ]
    }
   ],
   "source": [
    "#INITIALIZE THE NETWORK\n",
    "sess.run(init_op,options=run_options, run_metadata=run_metadata)\n",
    "zeta = 1e-3\n",
    "new_big_omeg_w2 = np.zeros(shape=[n_input,n_middle], dtype=np.float32)\n",
    "new_big_omeg_b2 = np.zeros(shape=[1,n_middle], dtype=np.float32)\n",
    "new_big_omeg_w3 = np.zeros(shape=[n_middle,n_out], dtype=np.float32)\n",
    "new_big_omeg_b3 = np.zeros(shape=[1,n_out], dtype=np.float32)\n",
    "\n",
    "reset_w2_grad_accum = np.zeros(shape=[n_input,n_middle], dtype=np.float32)\n",
    "reset_b2_grad_accum = np.zeros(shape=[1,n_middle], dtype=np.float32)\n",
    "reset_w3_grad_accum = np.zeros(shape=[n_middle,n_out], dtype=np.float32)\n",
    "reset_b3_grad_accum = np.zeros(shape=[1,n_out], dtype=np.float32)\n",
    "    \n",
    "start_w2 = None\n",
    "start_b2 = None\n",
    "start_w3 = None\n",
    "start_b3 = None\n",
    "\n",
    "end_w2 = None\n",
    "end_b2 = None\n",
    "end_w3 = None\n",
    "end_b3 = None\n",
    "\n",
    "old_test_data = []\n",
    "historical_cross_test_acc = {}\n",
    "historical_train_accuracies = {}\n",
    "historical_train_costs = {}\n",
    "historical_val_accuracies = {}\n",
    "historical_val_costs = {}\n",
    "sets = [(0,1), (2,3), (4,5), (6,7), (8,9)]\n",
    "#sets = [(0,4),(5,9)]\n",
    "test_labels_set = []\n",
    "logging_count = 0\n",
    "n_test_samples = []\n",
    "for a_set in range(len(sets)):\n",
    "    current_set = sets[a_set]\n",
    "    current_set_name = 'set'+str(a_set)\n",
    "    mask_val = [0]*num_classes\n",
    "    for i in range(current_set[0], current_set[1]+1):\n",
    "        mask_val[i]=1\n",
    "    set_mask_val = np.array(mask_val, dtype=np.float32)\n",
    "    train_data_set, valid_data_set, test_data_set = extract_class_data(start=current_set[0],\n",
    "                                                                  stop=current_set[1])\n",
    "    train_images_set, train_labels_set = train_data_set[0], train_data_set[1]\n",
    "    valid_images_set, valid_labels_set = valid_data_set[0], valid_data_set[1]\n",
    "    test_images_set, test_labels_set = test_data_set[0], test_data_set[1]\n",
    "    n_test_samples.append(len(test_labels_set))\n",
    "    train_total = len(train_images_set)\n",
    "    n_batches = len(train_images_set)/BATCH_SIZE\n",
    "    print('Number of batches:{}'.format(n_batches))\n",
    "\n",
    "\n",
    "    set_omegas = [tf.assign(big_omeg_w2, new_big_omeg_w2), tf.assign(big_omeg_b2, new_big_omeg_b2), \n",
    "                  tf.assign(big_omeg_w3, new_big_omeg_w3), tf.assign(big_omeg_b3, new_big_omeg_b3)]\n",
    "    sess.run(set_omegas)\n",
    "    \n",
    "    reset_grad_accums = [tf.assign(w2_grad_accum, reset_w2_grad_accum),\n",
    "                         tf.assign(b2_grad_accum, reset_b2_grad_accum),\n",
    "                         tf.assign(w3_grad_accum, reset_w3_grad_accum),\n",
    "                         tf.assign(b3_grad_accum, reset_b3_grad_accum)]\n",
    "    sess.run(reset_grad_accums)\n",
    "                                                                                  \n",
    "    epochs = 30\n",
    "    repeats = 1\n",
    "    \n",
    "    for repeat in range(repeats):\n",
    "        tf.set_random_seed(repeat)\n",
    "        print('Repeat:{}'.format(repeat))\n",
    "        train_accuracies = []\n",
    "        train_costs = []\n",
    "        val_accuracies = []\n",
    "        val_costs = []\n",
    "        best_val = 0\n",
    "        first_params_set = None\n",
    "        last_params_set = None\n",
    "        T1 = time.time()\n",
    "        for i in range(epochs):\n",
    "            if(i==0):\n",
    "                start_w2, start_b2, start_w3, start_b3 = w_2.eval(), b_2.eval(), w_3.eval(), b_3.eval()\n",
    "            sess.run(iter.initializer, feed_dict={a_1: train_images_set, y: train_labels_set,\n",
    "                                                  batch_size: len(train_images_set)})\n",
    "            print('Epoch:{}'.format((i)))\n",
    "            t1 = time.time()\n",
    "\n",
    "            ### CALCULATE TRAIN COSTS AND TRAIN ACCURACIES\n",
    "            train_cost, train_accuracy = sess.run([cost, acct_res] ,feed_dict = {drop_out : 0.0, \n",
    "                                                                                 set1_mask:set_mask_val})\n",
    "            train_costs.append(train_cost)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            #train_writer.add_summary(summary,logging_count)\n",
    "\n",
    "            print('training cost:{} and training accuracy:{}'.format(train_costs[i], train_accuracies[i]))\n",
    "\n",
    "            ### CALCULATE VALID COSTS AND VALID ACCURACIES\n",
    "            sess.run(iter.initializer, feed_dict={a_1: valid_images_set, y: valid_labels_set,\n",
    "                                                  batch_size: len(valid_images_set)})\n",
    "            _, _, val_acc, val_cost, _ = sess.run([predictions,acct_mat,acct_res, cost, a_3],\n",
    "                                                  feed_dict = {drop_out : 0.0,set1_mask:set_mask_val})\n",
    "            val_costs.append(val_cost)\n",
    "            val_accuracies.append(val_acc)\n",
    "\n",
    "            if(val_acc>best_val):\n",
    "                best_val = val_acc\n",
    "                best_params_set1 = [(w_2.eval(),b_2.eval()),(w_3.eval(),b_3.eval())]\n",
    "            print('validation cost:{} and validation accuracy:{}'.format(val_cost, val_acc))   \n",
    "            sess.run(iter.initializer, feed_dict={a_1: train_images_set, y: train_labels_set,\n",
    "                                                  batch_size: BATCH_SIZE})\n",
    "            \n",
    "            for d in range(len(old_test_data)):\n",
    "                previous_set_name = 'set'+str(d)           \n",
    "                prev_set = sets[d]\n",
    "                prev_mask_val = [0]*num_classes\n",
    "                for clas in range(prev_set[0], prev_set[1]+1):\n",
    "                    prev_mask_val[clas]=1\n",
    "                prev_set_mask_val = np.array(prev_mask_val, dtype=np.float32)\n",
    "                sess.run(iter.initializer, feed_dict={a_1: old_test_data[d][0], y: old_test_data[d][1],\n",
    "                                                  batch_size: len(old_test_data[d][0])})\n",
    "                _, _, hist_test_acc, _, _ = sess.run([predictions,acct_mat,acct_res, cost, a_3],\n",
    "                                                      feed_dict = {drop_out : 0.0,set1_mask:prev_set_mask_val})\n",
    "                \n",
    "                print('Testing accuracy on :{} while training :{} is :{}'.format(previous_set_name,\n",
    "                                                                          current_set_name,\n",
    "                                                                          hist_test_acc))\n",
    "                if(current_set_name+'-'+previous_set_name in historical_cross_test_acc.keys()):\n",
    "                    historical_cross_test_acc[current_set_name+'-'+previous_set_name].append(hist_test_acc)\n",
    "                else:\n",
    "                    historical_cross_test_acc[current_set_name+'-'+previous_set_name] = [hist_test_acc]\n",
    "            sess.run(iter.initializer, feed_dict={a_1: train_images_set, y: train_labels_set,\n",
    "                                              batch_size: BATCH_SIZE})\n",
    "            print('Training on :{}'.format(current_set))\n",
    "            for j in range(n_batches):\n",
    "                \n",
    "                if(not (np.isnan(w_2.eval().any() and np.isnan(w_3.eval()).any()))):\n",
    "                    #if(a_set==1):\n",
    "                    #    print(j, w_2.eval().sum(), w_3.eval().sum())\n",
    "                    if(((j)% 1000 ==0)):\n",
    "                        logging_count+=1\n",
    "                        summary,_,_ = sess.run([merged,step, omega_step], \n",
    "                                             feed_dict = {drop_out:0.5,batch_size: BATCH_SIZE, tau:0.5,\n",
    "                                                          set1_mask:set_mask_val, eta:0.001,\n",
    "                                                          lmbda:1.0e4,n_tot:train_total})\n",
    "                        #train_writer.add_summary(summary, (i+1)*j)\n",
    "                        train_writer.add_summary(summary, logging_count)\n",
    "                    else:\n",
    "                        sess.run([step, omega_step], feed_dict = {drop_out:0.5,batch_size: BATCH_SIZE, tau:0.5,\n",
    "                                                                 set1_mask:set_mask_val, eta:0.001,\n",
    "                                                                  lmbda:1.0e4,n_tot:train_total})\n",
    "                else:\n",
    "                    print('Nan encountered in epoch:{} and batch:{}'.format(i, j))\n",
    "            print('Epoch time:{}'.format(time.time()-t1))\n",
    "\n",
    "\n",
    "        sess.run(iter.initializer, feed_dict={a_1: test_images_set, y: test_labels_set,\n",
    "                                                  batch_size: len(test_images_set)})\n",
    "        _,final_test_acc,_ = sess.run([predictions, acct_res, a_3], \n",
    "                                                              feed_dict = {drop_out:0.0, \n",
    "                                                                           set1_mask:set_mask_val})\n",
    "        print('Final test accuracy is:{}'.format(final_test_acc))\n",
    "        end_w2, end_b2, end_w3, end_b3 = w_2.eval(), b_2.eval(), w_3.eval(), b_3.eval()\n",
    "        update_star_wbs = [tf.assign(star_w2,end_w2),tf.assign(star_b2,end_b2),tf.assign(star_w3,end_w3),\n",
    "                          tf.assign(star_b3,end_b3)]\n",
    "        sess.run(update_star_wbs)\n",
    "        #all_final_test_accs_set1.append(final_test_acc)\n",
    "\n",
    "\n",
    "        best_step = [tf.assign(w_2,best_params_set1[0][0]), tf.assign(b_2,best_params_set1[0][1]),\n",
    "                     tf.assign(w_3,best_params_set1[1][0]),tf.assign(b_3,best_params_set1[1][1])]\n",
    "        sess.run(best_step)\n",
    "        sess.run(iter.initializer, feed_dict={a_1: test_images_set, y: test_labels_set,\n",
    "                                                  batch_size: len(test_images_set)})\n",
    "        _,test_acc_corresp_best_val,_ = sess.run([predictions, acct_res, a_3],\n",
    "                                                 feed_dict = {drop_out:0.0,set1_mask:set_mask_val})\n",
    "\n",
    "        print('Test accuracy corresp to best val acc:{}'.format(test_acc_corresp_best_val))\n",
    "        print('Time taken:{}'.format(time.time()-T1))\n",
    "        if(i==epochs-1):\n",
    "            if(test_acc_corresp_best_val>final_test_acc):\n",
    "                end_w2, end_b2, end_w3, end_b3 = w_2.eval(), b_2.eval(), w_3.eval(), b_3.eval()\n",
    "                #all_final_test_accs_set1[-1] = test_acc_corresp_best_val\n",
    "                update_star_wbs = [tf.assign(star_w2,end_w2),tf.assign(star_b2,end_b2),tf.assign(star_w3,end_w3),\n",
    "                          tf.assign(star_b3,end_b3)]\n",
    "                sess.run(update_star_wbs)\n",
    "            \n",
    "            best_step = [tf.assign(w_2,end_w2), tf.assign(b_2,end_b2),\n",
    "                     tf.assign(w_3,end_w3),tf.assign(b_3,end_b3)]\n",
    "            sess.run(best_step)\n",
    "            \n",
    "            first_params_set = [(start_w2, start_b2), (start_w3, start_b3)]\n",
    "            last_params_set = [(end_w2, end_b2), (end_w3, end_b3)]\n",
    "            \n",
    "            small_omegas = [(w2_grad_accum.eval(), b2_grad_accum.eval()), (w3_grad_accum.eval(),\n",
    "                           b3_grad_accum.eval())]\n",
    "            \n",
    "            delta_ws = map(lambda x,y: np.square(x-y)+zeta,[item[0] for item in last_params_set],\n",
    "                       [item[0] for item in first_params_set])\n",
    "            \n",
    "            delta_bs = map(lambda x,y: np.square(x-y)+zeta,[item[1] for item in last_params_set],\n",
    "                       [item[1] for item in first_params_set])\n",
    "            delta_wbs = zip(delta_ws, delta_bs)\n",
    "            \n",
    "            big_omegas_ws = map(lambda x,y: (x/y),[item[0] for item in small_omegas],\n",
    "                       [item[0] for item in delta_wbs])\n",
    "            \n",
    "            big_omegas_bs = map(lambda x,y: (x/y),[item[1] for item in small_omegas],\n",
    "                       [item[1] for item in delta_wbs])\n",
    "            \n",
    "            big_omegas = zip(big_omegas_ws, big_omegas_bs)\n",
    "            if(a_set != len(sets)-1):     \n",
    "                new_big_omeg_w2 += big_omegas[0][0]\n",
    "                new_big_omeg_b2 += big_omegas[0][1]\n",
    "                new_big_omeg_w3 += big_omegas[1][0]\n",
    "                new_big_omeg_b3 += big_omegas[1][1]\n",
    "            \n",
    "            for d in range(len(old_test_data)):\n",
    "                previous_set_name = 'set'+str(d)\n",
    "                prev_set = sets[d]\n",
    "                prev_mask_val = [0]*num_classes\n",
    "                for clas in range(prev_set[0], prev_set[1]+1):\n",
    "                    prev_mask_val[clas]=1\n",
    "                prev_set_mask_val = np.array(prev_mask_val, dtype=np.float32)\n",
    "                sess.run(iter.initializer, feed_dict={a_1: old_test_data[d][0], y: old_test_data[d][1],\n",
    "                                                  batch_size: len(old_test_data[d][0])})\n",
    "                _, _, hist_test_acc, _, _ = sess.run([predictions,acct_mat,acct_res, cost, a_3],\n",
    "                                                      feed_dict = {drop_out : 0.0,set1_mask:prev_set_mask_val})\n",
    "                \n",
    "                historical_cross_test_acc[current_set_name+'-'+previous_set_name].append(hist_test_acc)\n",
    "                print('Testing accuracy on :{} after training :{} is :{}'.format(previous_set_name,\n",
    "                                                                          current_set_name,\n",
    "                                                                          hist_test_acc))\n",
    "                historical_cross_test_acc[current_set_name+'-'+current_set_name]=[test_acc_corresp_best_val]\n",
    "            old_test_data.append(test_data_set)\n",
    "            print('omegW2-MAXIMUM:{},MEAN:{},STD:{}'.format(new_big_omeg_w2.max(),\n",
    "                                                            new_big_omeg_w2.mean(),\n",
    "                                                            new_big_omeg_w2.std()))\n",
    "            print('omegb2-MAXIMUM:{},MEAN:{},STD:{}'.format(new_big_omeg_b2.max(),\n",
    "                                                            new_big_omeg_b2.mean(),\n",
    "                                                            new_big_omeg_b2.std()))\n",
    "            print('omegW3-MAXIMUM:{},MEAN:{},STD:{}'.format(new_big_omeg_w3.max(),\n",
    "                                                            new_big_omeg_w3.mean(),\n",
    "                                                            new_big_omeg_w3.std()))\n",
    "            print('omegb3-MAXIMUM:{},MEAN:{},STD:{}'.format(new_big_omeg_b3.max(),\n",
    "                                                            new_big_omeg_b3.mean(),\n",
    "                                                            new_big_omeg_b3.std()))\n",
    "            #sys.exit()\n",
    "    historical_train_accuracies[current_set_name]=train_accuracies\n",
    "    historical_train_costs[current_set_name]=train_costs\n",
    "    historical_val_accuracies[current_set_name]=val_accuracies\n",
    "    historical_val_costs[current_set_name]=val_costs\n",
    "            \n",
    "            \n",
    "train_writer.close()\n",
    "#valid_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Final accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on set 0:(0, 1) after training set 4:(4, 5) is:99.9527215958\n",
      "Accuracy on set 1:(2, 3) after training set 4:(4, 5) is:97.3555326462\n",
      "Accuracy on set 2:(4, 5) after training set 4:(4, 5) is:99.2529332638\n",
      "Accuracy on set 3:(6, 7) after training set 4:(4, 5) is:99.2950677872\n",
      "Accuracy on set 4:(8, 9) after training set 4:(4, 5) is:97.0751404762\n",
      "Final accuracy on all sets:98.5900008965\n"
     ]
    }
   ],
   "source": [
    "set_accs = []\n",
    "for i in range(0,num_classes/2):\n",
    "    set_acc =  historical_cross_test_acc['set4-set'+str(i)][-1]*100\n",
    "    print('Accuracy on set {}:{} after training set {}:{} is:{}'.format(i, sets[i],\\\n",
    "                                    4, sets[2], set_acc))\n",
    "    set_accs.append(set_acc)\n",
    "n_test_samples = np.array(n_test_samples)\n",
    "final_acc = (n_test_samples*set_accs).sum()/n_test_samples.sum()\n",
    "print('Final accuracy on all sets:{}'.format(final_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 270x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(w_2.eval().flatten(), 100)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Omega_W_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 270x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(new_big_omeg_w2.flatten(),bins=100,log=True)\n",
    "#plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 270x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(b_2.eval().flatten(), 100)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Omega_b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 270x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(new_big_omeg_b2.flatten(),100,log=True)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 270x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(w_3.eval().flatten(), 100)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Omega_W_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 270x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(new_big_omeg_w3.flatten(),100,log=True)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 270x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(b_3.eval().flatten(), 10)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Omega_b_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 270x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(new_big_omeg_b3.flatten(),10)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametrization 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#INITIALIZE THE NETWORK\n",
    "sess.run(init_op,options=run_options, run_metadata=run_metadata)\n",
    "zeta = 1e-3\n",
    "omega_scale = 1.5e-1\n",
    "max_clip = 1.0\n",
    "new_big_omeg_w2 = np.zeros(shape=[n_input,n_middle], dtype=np.float32)\n",
    "new_big_omeg_b2 = np.zeros(shape=[1,n_middle], dtype=np.float32)\n",
    "new_big_omeg_w3 = np.zeros(shape=[n_middle,n_out], dtype=np.float32)\n",
    "new_big_omeg_b3 = np.zeros(shape=[1,n_out], dtype=np.float32)\n",
    "\n",
    "reset_w2_grad_accum = np.zeros(shape=[n_input,n_middle], dtype=np.float32)\n",
    "reset_b2_grad_accum = np.zeros(shape=[1,n_middle], dtype=np.float32)\n",
    "reset_w3_grad_accum = np.zeros(shape=[n_middle,n_out], dtype=np.float32)\n",
    "reset_b3_grad_accum = np.zeros(shape=[1,n_out], dtype=np.float32)\n",
    "    \n",
    "start_w2 = None\n",
    "start_b2 = None\n",
    "start_w3 = None\n",
    "start_b3 = None\n",
    "\n",
    "end_w2 = None\n",
    "end_b2 = None\n",
    "end_w3 = None\n",
    "end_b3 = None\n",
    "\n",
    "old_test_data = []\n",
    "historical_cross_test_acc = {}\n",
    "historical_train_accuracies = {}\n",
    "historical_train_costs = {}\n",
    "historical_val_accuracies = {}\n",
    "historical_val_costs = {}\n",
    "sets = np.array_split(range(num_classes), int(num_classes/2))\n",
    "sets = [tuple(item.tolist()) for item in sets]\n",
    "n_test_samples = []\n",
    "evolving_omegas = []\n",
    "for a_set in range(len(sets)):\n",
    "    current_set = sets[a_set]\n",
    "    current_set_name = 'set'+str(a_set)\n",
    "    mask_val = [0]*num_classes\n",
    "    for i in range(current_set[0], current_set[1]+1):\n",
    "        mask_val[i]=1\n",
    "    set_mask_val = np.array(mask_val, dtype=np.float32)\n",
    "    train_data_set, valid_data_set, test_data_set = extract_class_data(start=current_set[0],\n",
    "                                                                  stop=current_set[1])\n",
    "    train_images_set, train_labels_set = train_data_set[0], train_data_set[1]\n",
    "    valid_images_set, valid_labels_set = valid_data_set[0], valid_data_set[1]\n",
    "    test_images_set, test_labels_set = test_data_set[0], test_data_set[1]\n",
    "    n_test_samples.append(len(test_labels_set))\n",
    "    train_total = len(train_images_set)\n",
    "    n_batches = len(train_images_set)/BATCH_SIZE\n",
    "    print('Number of batches:{}'.format(n_batches))\n",
    "\n",
    "\n",
    "    set_omegas = [tf.assign(big_omeg_w2, new_big_omeg_w2), tf.assign(big_omeg_b2, new_big_omeg_b2), \n",
    "                  tf.assign(big_omeg_w3, new_big_omeg_w3), tf.assign(big_omeg_b3, new_big_omeg_b3)]\n",
    "    sess.run(set_omegas)\n",
    "    \n",
    "    reset_grad_accums = [tf.assign(w2_grad_accum, reset_w2_grad_accum),\n",
    "                         tf.assign(b2_grad_accum, reset_b2_grad_accum),\n",
    "                         tf.assign(w3_grad_accum, reset_w3_grad_accum),\n",
    "                         tf.assign(b3_grad_accum, reset_b3_grad_accum)]\n",
    "    sess.run(reset_grad_accums)\n",
    "                                                                                        \n",
    "    epochs = 10\n",
    "    repeats = 1\n",
    "    \n",
    "    for repeat in range(repeats):\n",
    "        tf.set_random_seed(repeat)\n",
    "        print('Repeat:{}'.format(repeat))\n",
    "        train_accuracies = []\n",
    "        train_costs = []\n",
    "        val_accuracies = []\n",
    "        val_costs = []\n",
    "        best_val = 0\n",
    "        first_params_set = None\n",
    "        last_params_set = None\n",
    "        logging_count = 0\n",
    "        T1 = time.time()\n",
    "        for i in range(epochs):\n",
    "            if(i==0):\n",
    "                start_w2, start_b2, start_w3, start_b3 = w_2.eval(), b_2.eval(), w_3.eval(), b_3.eval()\n",
    "            sess.run(iter.initializer, feed_dict={a_1: train_images_set, y: train_labels_set,\n",
    "                                                  batch_size: len(train_images_set)})\n",
    "            print('Epoch:{}'.format((i)))\n",
    "            t1 = time.time()\n",
    "\n",
    "            ### CALCULATE TRAIN COSTS AND TRAIN ACCURACIES\n",
    "            train_cost, train_accuracy = sess.run([cost, acct_res] ,feed_dict = {drop_out : 0.0, \n",
    "                                                                                 set1_mask:set_mask_val})\n",
    "            train_costs.append(train_cost)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            #train_writer.add_summary(summary,logging_count)\n",
    "\n",
    "            print('training cost:{} and training accuracy:{}'.format(train_costs[i], train_accuracies[i]))\n",
    "\n",
    "            ### CALCULATE VALID COSTS AND VALID ACCURACIES\n",
    "            sess.run(iter.initializer, feed_dict={a_1: valid_images_set, y: valid_labels_set,\n",
    "                                                  batch_size: len(valid_images_set)})\n",
    "            _, _, val_acc, val_cost, _ = sess.run([predictions,acct_mat,acct_res, cost, a_3],\n",
    "                                                  feed_dict = {drop_out : 0.0,set1_mask:set_mask_val})\n",
    "            val_costs.append(val_cost)\n",
    "            val_accuracies.append(val_acc)\n",
    "\n",
    "            if(val_acc>best_val):\n",
    "                best_val = val_acc\n",
    "                best_params_set1 = [(w_2.eval(),b_2.eval()),(w_3.eval(),b_3.eval())]\n",
    "            print('validation cost:{} and validation accuracy:{}'.format(val_cost, val_acc))   \n",
    "            sess.run(iter.initializer, feed_dict={a_1: train_images_set, y: train_labels_set,\n",
    "                                                  batch_size: BATCH_SIZE})\n",
    "            \n",
    "            \n",
    "            for d in range(len(old_test_data)):\n",
    "                previous_set_name = 'set'+str(d)           \n",
    "                prev_set = sets[d]\n",
    "                prev_mask_val = [0]*num_classes\n",
    "                for clas in range(prev_set[0], prev_set[1]+1):\n",
    "                    prev_mask_val[clas]=1\n",
    "                prev_set_mask_val = np.array(prev_mask_val, dtype=np.float32)\n",
    "                \n",
    "                sess.run(iter.initializer, feed_dict={a_1: old_test_data[d][0], y: old_test_data[d][1],\n",
    "                                                  batch_size: len(old_test_data[d][0])})\n",
    "                _, _, hist_test_acc, _, _ = sess.run([predictions,acct_mat,acct_res, cost, a_3],\n",
    "                                                      feed_dict = {drop_out : 0.0,set1_mask:prev_set_mask_val})\n",
    "                \n",
    "                print('Testing accuracy on :{} while training :{} is :{}'.format(previous_set_name,\n",
    "                                                                          current_set_name,\n",
    "                                                                          hist_test_acc))\n",
    "                if(current_set_name+'-'+previous_set_name in historical_cross_test_acc.keys()):\n",
    "                    historical_cross_test_acc[current_set_name+'-'+previous_set_name].append(hist_test_acc)\n",
    "                else:\n",
    "                    historical_cross_test_acc[current_set_name+'-'+previous_set_name] = [hist_test_acc]\n",
    "            sess.run(iter.initializer, feed_dict={a_1: train_images_set, y: train_labels_set,\n",
    "                                              batch_size: BATCH_SIZE})\n",
    "            print('Training on :{}'.format(current_set))\n",
    "            for j in range(n_batches):\n",
    "                \n",
    "                if(not (np.isnan(w_2.eval().any() and np.isnan(w_3.eval()).any()))):\n",
    "                    #if(a_set==1):\n",
    "                    #    print(j, w_2.eval().sum(), w_3.eval().sum())\n",
    "                    if(((j)% 1000 ==0)):\n",
    "                        logging_count+=1\n",
    "                        summary,_,_ = sess.run([merged,step, omega_step], \n",
    "                                             feed_dict = {drop_out:0.5,batch_size: BATCH_SIZE, tau:0.5,\n",
    "                                                          set1_mask:set_mask_val, eta:1.0e-3, lmbda:5.0e7,\n",
    "                                                         n_tot:train_total})\n",
    "                        #train_writer.add_summary(summary, (i+1)*j)\n",
    "                        train_writer.add_summary(summary, logging_count)\n",
    "                    else:\n",
    "                        sess.run([step, omega_step], feed_dict = {drop_out:0.5,batch_size: BATCH_SIZE, tau:0.5,\n",
    "                                                                 set1_mask:set_mask_val,eta:1.0e-3,\n",
    "                                                                  lmbda:5.0e7,n_tot:train_total})\n",
    "                else:\n",
    "                    print('Nan encountered in epoch:{} and batch:{}'.format(i, j))\n",
    "            print('Epoch time:{}'.format(time.time()-t1))\n",
    "\n",
    "\n",
    "        sess.run(iter.initializer, feed_dict={a_1: test_images_set, y: test_labels_set,\n",
    "                                                  batch_size: len(test_images_set)})\n",
    "        _,final_test_acc,_ = sess.run([predictions, acct_res, a_3], \n",
    "                                                              feed_dict = {drop_out:0.0, \n",
    "                                                                           set1_mask:set_mask_val})\n",
    "        print('Final test accuracy is:{}'.format(final_test_acc))\n",
    "        end_w2, end_b2, end_w3, end_b3 = w_2.eval(), b_2.eval(), w_3.eval(), b_3.eval()\n",
    "        update_star_wbs = [tf.assign(star_w2,end_w2),tf.assign(star_b2,end_b2),tf.assign(star_w3,end_w3),\n",
    "                          tf.assign(star_b3,end_b3)]\n",
    "        sess.run(update_star_wbs)\n",
    "        #all_final_test_accs_set1.append(final_test_acc)\n",
    "\n",
    "\n",
    "        best_step = [tf.assign(w_2,best_params_set1[0][0]), tf.assign(b_2,best_params_set1[0][1]),\n",
    "                     tf.assign(w_3,best_params_set1[1][0]),tf.assign(b_3,best_params_set1[1][1])]\n",
    "        sess.run(best_step)\n",
    "        sess.run(iter.initializer, feed_dict={a_1: test_images_set, y: test_labels_set,\n",
    "                                                  batch_size: len(test_images_set)})\n",
    "        _,test_acc_corresp_best_val,_ = sess.run([predictions, acct_res, a_3],\n",
    "                                                 feed_dict = {drop_out:0.0,set1_mask:set_mask_val})\n",
    "\n",
    "        print('Test accuracy corresp to best val acc:{}'.format(test_acc_corresp_best_val))\n",
    "        print('Time taken:{}'.format(time.time()-T1))\n",
    "        if(i==epochs-1):\n",
    "            if(test_acc_corresp_best_val>final_test_acc):\n",
    "                end_w2, end_b2, end_w3, end_b3 = w_2.eval(), b_2.eval(), w_3.eval(), b_3.eval()\n",
    "                #all_final_test_accs_set1[-1] = test_acc_corresp_best_val\n",
    "                update_star_wbs = [tf.assign(star_w2,end_w2),tf.assign(star_b2,end_b2),tf.assign(star_w3,end_w3),\n",
    "                          tf.assign(star_b3,end_b3)]\n",
    "                sess.run(update_star_wbs)\n",
    "            \n",
    "            best_step = [tf.assign(w_2,end_w2), tf.assign(b_2,end_b2),\n",
    "                     tf.assign(w_3,end_w3),tf.assign(b_3,end_b3)]\n",
    "            sess.run(best_step)\n",
    "            \n",
    "            first_params_set = [(start_w2, start_b2), (start_w3, start_b3)]\n",
    "            last_params_set = [(end_w2, end_b2), (end_w3, end_b3)]\n",
    "            \n",
    "            small_omegas = [(w2_grad_accum.eval(), b2_grad_accum.eval()), (w3_grad_accum.eval(),\n",
    "                           b3_grad_accum.eval())]\n",
    "            \n",
    "            delta_ws = map(lambda x,y: np.square(x-y)+zeta,[item[0] for item in last_params_set],\n",
    "                       [item[0] for item in first_params_set])\n",
    "            \n",
    "            delta_bs = map(lambda x,y: np.square(x-y)+zeta,[item[1] for item in last_params_set],\n",
    "                       [item[1] for item in first_params_set])\n",
    "            delta_wbs = zip(delta_ws, delta_bs)\n",
    "            \n",
    "            big_omegas_ws = map(lambda x,y: (x/y),[item[0] for item in small_omegas],\n",
    "                       [item[0] for item in delta_wbs])\n",
    "            \n",
    "            big_omegas_bs = map(lambda x,y: (x/y),[item[1] for item in small_omegas],\n",
    "                       [item[1] for item in delta_wbs])\n",
    "            \n",
    "            big_omegas = zip(big_omegas_ws, big_omegas_bs)\n",
    "            evolving_omegas.append(big_omegas)\n",
    "            new_big_omeg_w2 += omega_scale*np.clip(big_omegas[0][0], 0, max_clip)\n",
    "            new_big_omeg_b2 += omega_scale*np.clip(big_omegas[0][1],  0, max_clip)\n",
    "            new_big_omeg_w3 += omega_scale*np.clip(big_omegas[1][0],  0, max_clip)\n",
    "            new_big_omeg_b3 += omega_scale*np.clip(big_omegas[1][1],  0, max_clip)\n",
    "            \n",
    "            for d in range(len(old_test_data)):\n",
    "                previous_set_name = 'set'+str(d)\n",
    "                prev_set = sets[d]\n",
    "                prev_mask_val = [0]*num_classes\n",
    "                for clas in range(prev_set[0], prev_set[1]+1):\n",
    "                    prev_mask_val[clas]=1\n",
    "                prev_set_mask_val = np.array(prev_mask_val, dtype=np.float32)\n",
    "                sess.run(iter.initializer, feed_dict={a_1: old_test_data[d][0], y: old_test_data[d][1],\n",
    "                                                  batch_size: len(old_test_data[d][0])})\n",
    "                _, _, hist_test_acc, _, _ = sess.run([predictions,acct_mat,acct_res, cost, a_3],\n",
    "                                                      feed_dict = {drop_out : 0.0,set1_mask:prev_set_mask_val})\n",
    "                \n",
    "                historical_cross_test_acc[current_set_name+'-'+previous_set_name].append(hist_test_acc)\n",
    "                print('Testing accuracy on :{} after training :{} is :{}'.format(previous_set_name,\n",
    "                                                                          current_set_name,\n",
    "                                                                          hist_test_acc))\n",
    "                historical_cross_test_acc[current_set_name+'-'+current_set_name]=[test_acc_corresp_best_val]\n",
    "                \n",
    "                \n",
    "            old_test_data.append(test_data_set)\n",
    "            print('MAXIMUM omegW2:{}, MEAN omegW2:{}'.format(new_big_omeg_w2.max(), new_big_omeg_w2.mean()))\n",
    "            print('MAXIMUM omegb2:{}, MEAN omegb2:{}'.format(new_big_omeg_b2.max(), new_big_omeg_b2.mean()))\n",
    "            print('MAXIMUM omegW3:{}, MEAN omegW3:{}'.format(new_big_omeg_w3.max(), new_big_omeg_w3.mean()))\n",
    "            print('MAXIMUM omegb3:{}, MEAN omegb3:{}'.format(new_big_omeg_b3.max(), new_big_omeg_b3.mean()))\n",
    "            #sys.exit()\n",
    "    #sys.exit()\n",
    "    historical_train_accuracies[current_set_name]=train_accuracies\n",
    "    historical_train_costs[current_set_name]=train_costs\n",
    "    historical_val_accuracies[current_set_name]=val_accuracies\n",
    "    historical_val_costs[current_set_name]=val_costs\n",
    "            \n",
    "            \n",
    "train_writer.close()\n",
    "valid_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(w_2.eval().flatten(), 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(new_big_omeg_w2.flatten(),100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(b_2.eval().flatten(), 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(new_big_omeg_b2.flatten(),100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(w_3.eval().flatten(), 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(new_big_omeg_w3.flatten(),100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(b_3.eval().flatten(), 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(new_big_omeg_b3.flatten(),100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Examining final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on set 0:(0, 1) after training set 4:(4, 5) is:99.9527215958\n",
      "Accuracy on set 1:(2, 3) after training set 4:(4, 5) is:97.4045038223\n",
      "Accuracy on set 2:(4, 5) after training set 4:(4, 5) is:98.8794028759\n",
      "Accuracy on set 3:(6, 7) after training set 4:(4, 5) is:98.8922476768\n",
      "Accuracy on set 4:(8, 9) after training set 4:(4, 5) is:95.7639932632\n",
      "Final accuracy on all sets:98.1900006497\n"
     ]
    }
   ],
   "source": [
    "set_accs = []\n",
    "for i in range(0,num_classes/2):\n",
    "    set_acc =  historical_cross_test_acc['set4-set'+str(i)][-1]*100\n",
    "    print('Accuracy on set {}:{} after training set {}:{} is:{}'.format(i, sets[i],\\\n",
    "                                    4, sets[2], set_acc))\n",
    "    set_accs.append(set_acc)\n",
    "n_test_samples = np.array(n_test_samples)\n",
    "final_acc = (n_test_samples*set_accs).sum()/n_test_samples.sum()\n",
    "print('Final accuracy on all sets:{}'.format(final_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a writer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/ruthvik/Desktop/Summer 2017/tf_graph_outputs/mnist/continual_learning/original_mnist_5sets'\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(path + '/3lyrs_working_without_SI', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test features:(2115, 784)\n",
      "Length of test labels:2115\n",
      "Train features:(11526, 784)\n",
      "Length of train labels:11526\n",
      "Valid features:(1139, 784)\n",
      "Length of valid labels:1139\n",
      "Number of batches:1152\n",
      "Repeat:0\n",
      "Epoch:0\n",
      "training cost:2.30443906784 and training accuracy:0.670397341251\n",
      "validation cost:2.30437278748 and validation accuracy:0.649692714214\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.30352497101\n",
      "Epoch:1\n",
      "training cost:0.644062042236 and training accuracy:0.954711079597\n",
      "validation cost:0.622508049011 and validation accuracy:0.955223858356\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.39017295837\n",
      "Epoch:2\n",
      "training cost:0.0483111739159 and training accuracy:0.995922267437\n",
      "validation cost:0.0437679290771 and validation accuracy:0.996488153934\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.22384405136\n",
      "Epoch:3\n",
      "training cost:0.0176283046603 and training accuracy:0.996442854404\n",
      "validation cost:0.0155012588948 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:5.26728892326\n",
      "Epoch:4\n",
      "training cost:0.0126531673595 and training accuracy:0.996616363525\n",
      "validation cost:0.0108884265646 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.71688604355\n",
      "Epoch:5\n",
      "training cost:0.0108796553686 and training accuracy:0.996963381767\n",
      "validation cost:0.00926772132516 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.20518279076\n",
      "Epoch:6\n",
      "training cost:0.0100176064298 and training accuracy:0.99705016613\n",
      "validation cost:0.00849617179483 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.32959485054\n",
      "Epoch:7\n",
      "training cost:0.00948605872691 and training accuracy:0.997310400009\n",
      "validation cost:0.00805158540606 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.25978803635\n",
      "Epoch:8\n",
      "training cost:0.00912215746939 and training accuracy:0.997310400009\n",
      "validation cost:0.00775788677856 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.24915504456\n",
      "Epoch:9\n",
      "training cost:0.00883830245584 and training accuracy:0.997397184372\n",
      "validation cost:0.00753641827032 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.16081595421\n",
      "Epoch:10\n",
      "training cost:0.00862089544535 and training accuracy:0.997483968735\n",
      "validation cost:0.00737234624103 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.18689107895\n",
      "Epoch:11\n",
      "training cost:0.00846821069717 and training accuracy:0.997483968735\n",
      "validation cost:0.00722371554002 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.19505500793\n",
      "Epoch:12\n",
      "training cost:0.00833182036877 and training accuracy:0.997570693493\n",
      "validation cost:0.00709919119254 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.15882897377\n",
      "Epoch:13\n",
      "training cost:0.00816862378269 and training accuracy:0.997397184372\n",
      "validation cost:0.0070190411061 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.18323802948\n",
      "Epoch:14\n",
      "training cost:0.00803288631141 and training accuracy:0.997483968735\n",
      "validation cost:0.00693701673299 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.19149303436\n",
      "Epoch:15\n",
      "training cost:0.00794242694974 and training accuracy:0.997657477856\n",
      "validation cost:0.00681770406663 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.18512010574\n",
      "Epoch:16\n",
      "training cost:0.00783761590719 and training accuracy:0.997830986977\n",
      "validation cost:0.00672957953066 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.17194509506\n",
      "Epoch:17\n",
      "training cost:0.00776035198942 and training accuracy:0.997917771339\n",
      "validation cost:0.00661896634847 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.17798781395\n",
      "Epoch:18\n",
      "training cost:0.00767117366195 and training accuracy:0.997917771339\n",
      "validation cost:0.00652942573652 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.18940591812\n",
      "Epoch:19\n",
      "training cost:0.00757704908028 and training accuracy:0.997917771339\n",
      "validation cost:0.00646872259676 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.18615794182\n",
      "Epoch:20\n",
      "training cost:0.00751675385982 and training accuracy:0.997917771339\n",
      "validation cost:0.00637301150709 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.16463208199\n",
      "Epoch:21\n",
      "training cost:0.00744838733226 and training accuracy:0.997917771339\n",
      "validation cost:0.00630822498351 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.17589592934\n",
      "Epoch:22\n",
      "training cost:0.00738753378391 and training accuracy:0.997917771339\n",
      "validation cost:0.00625063059852 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.22178411484\n",
      "Epoch:23\n",
      "training cost:0.0073157385923 and training accuracy:0.997917771339\n",
      "validation cost:0.00620393548161 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.14555501938\n",
      "Epoch:24\n",
      "training cost:0.00725897355005 and training accuracy:0.997917771339\n",
      "validation cost:0.00613149255514 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.15891909599\n",
      "Epoch:25\n",
      "training cost:0.00720517523587 and training accuracy:0.997917771339\n",
      "validation cost:0.00605590827763 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.15682792664\n",
      "Epoch:26\n",
      "training cost:0.00715016340837 and training accuracy:0.997917771339\n",
      "validation cost:0.00600340915844 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.21097517014\n",
      "Epoch:27\n",
      "training cost:0.00710214162245 and training accuracy:0.997917771339\n",
      "validation cost:0.00593852205202 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.15978717804\n",
      "Epoch:28\n",
      "training cost:0.00705331284553 and training accuracy:0.997917771339\n",
      "validation cost:0.00591804133728 and validation accuracy:0.998244047165\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.18231201172\n",
      "Epoch:29\n",
      "training cost:0.00700565334409 and training accuracy:0.998004496098\n",
      "validation cost:0.00583929568529 and validation accuracy:0.999122023582\n",
      "Training on :(0, 1)\n",
      "Epoch time:4.18531703949\n",
      "Final test accuracy is:0.999527215958\n",
      "Test accuracy corresp to best val acc:0.999527215958\n",
      "Time taken:129.992988825\n",
      "MAXIMUM omegW2:0.0, MEAN omegW2:0.0\n",
      "MAXIMUM omegb2:0.0, MEAN omegb2:0.0\n",
      "MAXIMUM omegW3:0.0, MEAN omegW3:0.0\n",
      "MAXIMUM omegb3:0.0, MEAN omegb3:0.0\n",
      "Test features:(2042, 784)\n",
      "Length of test labels:2042\n",
      "Train features:(11001, 784)\n",
      "Length of train labels:11001\n",
      "Valid features:(1088, 784)\n",
      "Length of valid labels:1088\n",
      "Number of batches:1100\n",
      "Repeat:0\n",
      "Epoch:0\n",
      "training cost:16.0048484802 and training accuracy:0.492773383856\n",
      "validation cost:16.1366081238 and validation accuracy:0.48713234067\n",
      "Testing accuracy on :set0 while training :set1 is :0.999527215958\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.03537201881\n",
      "Epoch:1\n",
      "training cost:0.522401034832 and training accuracy:0.921734392643\n",
      "validation cost:0.520421087742 and validation accuracy:0.931985318661\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.6945309639\n",
      "Epoch:2\n",
      "training cost:0.285562843084 and training accuracy:0.932915210724\n",
      "validation cost:0.275567322969 and validation accuracy:0.942095577717\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:3.98339295387\n",
      "Epoch:3\n",
      "training cost:0.177541181445 and training accuracy:0.939460039139\n",
      "validation cost:0.16042740643 and validation accuracy:0.948529422283\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:3.99607300758\n",
      "Epoch:4\n",
      "training cost:0.145892202854 and training accuracy:0.945186793804\n",
      "validation cost:0.126242607832 and validation accuracy:0.952205896378\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.06859517097\n",
      "Epoch:5\n",
      "training cost:0.133774712682 and training accuracy:0.949731826782\n",
      "validation cost:0.113683536649 and validation accuracy:0.955882370472\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.00370192528\n",
      "Epoch:6\n",
      "training cost:0.127572879195 and training accuracy:0.95218616724\n",
      "validation cost:0.107895925641 and validation accuracy:0.957720577717\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch time:3.98265600204\n",
      "Epoch:7\n",
      "training cost:0.123237885535 and training accuracy:0.955458581448\n",
      "validation cost:0.104166850448 and validation accuracy:0.962316155434\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:3.99961209297\n",
      "Epoch:8\n",
      "training cost:0.12029927969 and training accuracy:0.956822097301\n",
      "validation cost:0.10199008137 and validation accuracy:0.963235318661\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.18824100494\n",
      "Epoch:9\n",
      "training cost:0.117877289653 and training accuracy:0.958640098572\n",
      "validation cost:0.100777059793 and validation accuracy:0.964154422283\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.33308196068\n",
      "Epoch:10\n",
      "training cost:0.116018503904 and training accuracy:0.961548924446\n",
      "validation cost:0.0996416211128 and validation accuracy:0.967830896378\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.02160811424\n",
      "Epoch:11\n",
      "training cost:0.114541299641 and training accuracy:0.962185263634\n",
      "validation cost:0.0991107299924 and validation accuracy:0.967830896378\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.17916703224\n",
      "Epoch:12\n",
      "training cost:0.113295309246 and training accuracy:0.963276088238\n",
      "validation cost:0.0986129641533 and validation accuracy:0.969669103622\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.03546905518\n",
      "Epoch:13\n",
      "training cost:0.112140960991 and training accuracy:0.963912367821\n",
      "validation cost:0.0985041260719 and validation accuracy:0.967830896378\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:3.99489212036\n",
      "Epoch:14\n",
      "training cost:0.111265711486 and training accuracy:0.965184986591\n",
      "validation cost:0.0982914790511 and validation accuracy:0.969669103622\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.00105786324\n",
      "Epoch:15\n",
      "training cost:0.110727086663 and training accuracy:0.965094089508\n",
      "validation cost:0.0989242941141 and validation accuracy:0.969669103622\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.06030893326\n",
      "Epoch:16\n",
      "training cost:0.110119208694 and training accuracy:0.965639472008\n",
      "validation cost:0.0982997789979 and validation accuracy:0.96875\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.63841104507\n",
      "Epoch:17\n",
      "training cost:0.109395205975 and training accuracy:0.965821266174\n",
      "validation cost:0.0985329821706 and validation accuracy:0.970588207245\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.01039099693\n",
      "Epoch:18\n",
      "training cost:0.108686752617 and training accuracy:0.966639399529\n",
      "validation cost:0.0989426895976 and validation accuracy:0.970588207245\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:3.99835181236\n",
      "Epoch:19\n",
      "training cost:0.108275294304 and training accuracy:0.967457532883\n",
      "validation cost:0.099455691874 and validation accuracy:0.970588207245\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.12085103989\n",
      "Epoch:20\n",
      "training cost:0.107766106725 and training accuracy:0.967730224133\n",
      "validation cost:0.0991719141603 and validation accuracy:0.969669103622\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.13606786728\n",
      "Epoch:21\n",
      "training cost:0.107243701816 and training accuracy:0.968002915382\n",
      "validation cost:0.0993026718497 and validation accuracy:0.96875\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.34082984924\n",
      "Epoch:22\n",
      "training cost:0.106806233525 and training accuracy:0.968457400799\n",
      "validation cost:0.0994900390506 and validation accuracy:0.96875\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.01104784012\n",
      "Epoch:23\n",
      "training cost:0.106378257275 and training accuracy:0.96891194582\n",
      "validation cost:0.0998647660017 and validation accuracy:0.96875\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.69327688217\n",
      "Epoch:24\n",
      "training cost:0.106072463095 and training accuracy:0.968820989132\n",
      "validation cost:0.099361717701 and validation accuracy:0.96875\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.00972008705\n",
      "Epoch:25\n",
      "training cost:0.105744071305 and training accuracy:0.96891194582\n",
      "validation cost:0.099892526865 and validation accuracy:0.96875\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.1345448494\n",
      "Epoch:26\n",
      "training cost:0.105276428163 and training accuracy:0.96918463707\n",
      "validation cost:0.0999683588743 and validation accuracy:0.969669103622\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.00847601891\n",
      "Epoch:27\n",
      "training cost:0.105030782521 and training accuracy:0.969548225403\n",
      "validation cost:0.0993424877524 and validation accuracy:0.969669103622\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:5.04516100883\n",
      "Epoch:28\n",
      "training cost:0.104645162821 and training accuracy:0.969730019569\n",
      "validation cost:0.100188612938 and validation accuracy:0.970588207245\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.10786700249\n",
      "Epoch:29\n",
      "training cost:0.104520186782 and training accuracy:0.969366431236\n",
      "validation cost:0.101293720305 and validation accuracy:0.969669103622\n",
      "Testing accuracy on :set0 while training :set1 is :0.999054372311\n",
      "Training on :(2, 3)\n",
      "Epoch time:4.19746994972\n",
      "Final test accuracy is:0.975024461746\n",
      "Test accuracy corresp to best val acc:0.96963763237\n",
      "Time taken:127.242748022\n",
      "Testing accuracy on :set0 after training :set1 is :0.999054372311\n",
      "MAXIMUM omegW2:0.0, MEAN omegW2:0.0\n",
      "MAXIMUM omegb2:0.0, MEAN omegb2:0.0\n",
      "MAXIMUM omegW3:0.0, MEAN omegW3:0.0\n",
      "MAXIMUM omegb3:0.0, MEAN omegb3:0.0\n",
      "Test features:(1874, 784)\n",
      "Length of test labels:1874\n",
      "Train features:(10250, 784)\n",
      "Length of train labels:10250\n",
      "Valid features:(1013, 784)\n",
      "Length of valid labels:1013\n",
      "Number of batches:1025\n",
      "Repeat:0\n",
      "Epoch:0\n",
      "training cost:39.2545433044 and training accuracy:0.514439046383\n",
      "validation cost:39.0209541321 and validation accuracy:0.506416559219\n",
      "Testing accuracy on :set0 while training :set2 is :0.999054372311\n",
      "Testing accuracy on :set1 while training :set2 is :0.975024461746\n",
      "Training on :(4, 5)\n",
      "Epoch time:4.50597405434\n",
      "Epoch:1\n",
      "training cost:0.438284099102 and training accuracy:0.791121959686\n",
      "validation cost:0.451113075018 and validation accuracy:0.779861807823\n",
      "Testing accuracy on :set0 while training :set2 is :0.998108744621\n",
      "Testing accuracy on :set1 while training :set2 is :0.969147920609\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.80202698708\n",
      "Epoch:2\n",
      "training cost:0.335016220808 and training accuracy:0.846048772335\n",
      "validation cost:0.347252130508 and validation accuracy:0.831194460392\n",
      "Testing accuracy on :set0 while training :set2 is :0.998108744621\n",
      "Testing accuracy on :set1 while training :set2 is :0.965230166912\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.71633315086\n",
      "Epoch:3\n",
      "training cost:0.253426522017 and training accuracy:0.887902438641\n",
      "validation cost:0.260784596205 and validation accuracy:0.879565656185\n",
      "Testing accuracy on :set0 while training :set2 is :0.998108744621\n",
      "Testing accuracy on :set1 while training :set2 is :0.95935356617\n",
      "Training on :(4, 5)\n",
      "Epoch time:4.00788998604\n",
      "Epoch:4\n",
      "training cost:0.19498051703 and training accuracy:0.914634168148\n",
      "validation cost:0.195362076163 and validation accuracy:0.912142157555\n",
      "Testing accuracy on :set0 while training :set2 is :0.998108744621\n",
      "Testing accuracy on :set1 while training :set2 is :0.952987253666\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.72284007072\n",
      "Epoch:5\n",
      "training cost:0.155904918909 and training accuracy:0.935024380684\n",
      "validation cost:0.152566567063 and validation accuracy:0.931885480881\n",
      "Testing accuracy on :set0 while training :set2 is :0.997635960579\n",
      "Testing accuracy on :set1 while training :set2 is :0.95102840662\n",
      "Training on :(4, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch time:3.74225497246\n",
      "Epoch:6\n",
      "training cost:0.125871092081 and training accuracy:0.949658513069\n",
      "validation cost:0.117127843201 and validation accuracy:0.955577492714\n",
      "Testing accuracy on :set0 while training :set2 is :0.997635960579\n",
      "Testing accuracy on :set1 while training :set2 is :0.943682670593\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.72079491615\n",
      "Epoch:7\n",
      "training cost:0.107397034764 and training accuracy:0.959317088127\n",
      "validation cost:0.0960451737046 and validation accuracy:0.966436326504\n",
      "Testing accuracy on :set0 while training :set2 is :0.997163116932\n",
      "Testing accuracy on :set1 while training :set2 is :0.938295781612\n",
      "Training on :(4, 5)\n",
      "Epoch time:4.53310680389\n",
      "Epoch:8\n",
      "training cost:0.0934083983302 and training accuracy:0.965170741081\n",
      "validation cost:0.080514088273 and validation accuracy:0.970385015011\n",
      "Testing accuracy on :set0 while training :set2 is :0.997163116932\n",
      "Testing accuracy on :set1 while training :set2 is :0.933888316154\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.73484802246\n",
      "Epoch:9\n",
      "training cost:0.0837828889489 and training accuracy:0.9696585536\n",
      "validation cost:0.0702533647418 and validation accuracy:0.974333643913\n",
      "Testing accuracy on :set0 while training :set2 is :0.997163116932\n",
      "Testing accuracy on :set1 while training :set2 is :0.930460333824\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.70565605164\n",
      "Epoch:10\n",
      "training cost:0.0766604319215 and training accuracy:0.972097575665\n",
      "validation cost:0.0627391338348 and validation accuracy:0.976307988167\n",
      "Testing accuracy on :set0 while training :set2 is :0.997163116932\n",
      "Testing accuracy on :set1 while training :set2 is :0.927522063255\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.89379405975\n",
      "Epoch:11\n",
      "training cost:0.0712838321924 and training accuracy:0.973756074905\n",
      "validation cost:0.0571344830096 and validation accuracy:0.980256676674\n",
      "Testing accuracy on :set0 while training :set2 is :0.997163116932\n",
      "Testing accuracy on :set1 while training :set2 is :0.923604309559\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.77406692505\n",
      "Epoch:12\n",
      "training cost:0.0657944083214 and training accuracy:0.976097583771\n",
      "validation cost:0.0508094094694 and validation accuracy:0.981243848801\n",
      "Testing accuracy on :set0 while training :set2 is :0.997163116932\n",
      "Testing accuracy on :set1 while training :set2 is :0.920176327229\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.75300312042\n",
      "Epoch:13\n",
      "training cost:0.0622677989304 and training accuracy:0.977268278599\n",
      "validation cost:0.0471492372453 and validation accuracy:0.981243848801\n",
      "Testing accuracy on :set0 while training :set2 is :0.997163116932\n",
      "Testing accuracy on :set1 while training :set2 is :0.917237997055\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.73929595947\n",
      "Epoch:14\n",
      "training cost:0.0596268288791 and training accuracy:0.978926837444\n",
      "validation cost:0.0444927513599 and validation accuracy:0.985192477703\n",
      "Testing accuracy on :set0 while training :set2 is :0.997163116932\n",
      "Testing accuracy on :set1 while training :set2 is :0.915768861771\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.74778389931\n",
      "Epoch:15\n",
      "training cost:0.0568853542209 and training accuracy:0.980487823486\n",
      "validation cost:0.0408966876566 and validation accuracy:0.984205305576\n",
      "Testing accuracy on :set0 while training :set2 is :0.997163116932\n",
      "Testing accuracy on :set1 while training :set2 is :0.915279150009\n",
      "Training on :(4, 5)\n",
      "Epoch time:4.63119697571\n",
      "Epoch:16\n",
      "training cost:0.0552952177823 and training accuracy:0.981170713902\n",
      "validation cost:0.0394350625575 and validation accuracy:0.985192477703\n",
      "Testing accuracy on :set0 while training :set2 is :0.99669033289\n",
      "Testing accuracy on :set1 while training :set2 is :0.914299726486\n",
      "Training on :(4, 5)\n",
      "Epoch time:4.00215315819\n",
      "Epoch:17\n",
      "training cost:0.0535377524793 and training accuracy:0.982243895531\n",
      "validation cost:0.0373076163232 and validation accuracy:0.987166821957\n",
      "Testing accuracy on :set0 while training :set2 is :0.99669033289\n",
      "Testing accuracy on :set1 while training :set2 is :0.912830531597\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.82247781754\n",
      "Epoch:18\n",
      "training cost:0.0524797849357 and training accuracy:0.982926845551\n",
      "validation cost:0.0364013686776 and validation accuracy:0.98617964983\n",
      "Testing accuracy on :set0 while training :set2 is :0.99669033289\n",
      "Testing accuracy on :set1 while training :set2 is :0.911851108074\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.90066695213\n",
      "Epoch:19\n",
      "training cost:0.0514341406524 and training accuracy:0.983804881573\n",
      "validation cost:0.0352669991553 and validation accuracy:0.98617964983\n",
      "Testing accuracy on :set0 while training :set2 is :0.99669033289\n",
      "Testing accuracy on :set1 while training :set2 is :0.91038197279\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.73216795921\n",
      "Epoch:20\n",
      "training cost:0.0503914356232 and training accuracy:0.984390258789\n",
      "validation cost:0.0341208837926 and validation accuracy:0.987166821957\n",
      "Testing accuracy on :set0 while training :set2 is :0.99669033289\n",
      "Testing accuracy on :set1 while training :set2 is :0.908912837505\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.74117207527\n",
      "Epoch:21\n",
      "training cost:0.0495360530913 and training accuracy:0.984975636005\n",
      "validation cost:0.0330336727202 and validation accuracy:0.987166821957\n",
      "Testing accuracy on :set0 while training :set2 is :0.99669033289\n",
      "Testing accuracy on :set1 while training :set2 is :0.908912837505\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.72569203377\n",
      "Epoch:22\n",
      "training cost:0.0487998686731 and training accuracy:0.985365867615\n",
      "validation cost:0.0317547619343 and validation accuracy:0.990128338337\n",
      "Testing accuracy on :set0 while training :set2 is :0.99669033289\n",
      "Testing accuracy on :set1 while training :set2 is :0.908423125744\n",
      "Training on :(4, 5)\n",
      "Epoch time:4.37350296974\n",
      "Epoch:23\n",
      "training cost:0.0482749305665 and training accuracy:0.985756099224\n",
      "validation cost:0.0315318293869 and validation accuracy:0.990128338337\n",
      "Testing accuracy on :set0 while training :set2 is :0.99669033289\n",
      "Testing accuracy on :set1 while training :set2 is :0.907933413982\n",
      "Training on :(4, 5)\n",
      "Epoch time:4.76062488556\n",
      "Epoch:24\n",
      "training cost:0.0479739531875 and training accuracy:0.985756099224\n",
      "validation cost:0.0317185297608 and validation accuracy:0.98914116621\n",
      "Testing accuracy on :set0 while training :set2 is :0.99669033289\n",
      "Testing accuracy on :set1 while training :set2 is :0.906953990459\n",
      "Training on :(4, 5)\n",
      "Epoch time:4.40458512306\n",
      "Epoch:25\n",
      "training cost:0.0472260527313 and training accuracy:0.985853672028\n",
      "validation cost:0.0305415429175 and validation accuracy:0.991115510464\n",
      "Testing accuracy on :set0 while training :set2 is :0.99669033289\n",
      "Testing accuracy on :set1 while training :set2 is :0.905974507332\n",
      "Training on :(4, 5)\n",
      "Epoch time:4.66948795319\n",
      "Epoch:26\n",
      "training cost:0.0467565916479 and training accuracy:0.98604875803\n",
      "validation cost:0.0299255698919 and validation accuracy:0.99210268259\n",
      "Testing accuracy on :set0 while training :set2 is :0.99669033289\n",
      "Testing accuracy on :set1 while training :set2 is :0.90548479557\n",
      "Training on :(4, 5)\n",
      "Epoch time:4.07737898827\n",
      "Epoch:27\n",
      "training cost:0.0463638007641 and training accuracy:0.986146330833\n",
      "validation cost:0.0292649753392 and validation accuracy:0.99210268259\n",
      "Testing accuracy on :set0 while training :set2 is :0.99669033289\n",
      "Testing accuracy on :set1 while training :set2 is :0.904015660286\n",
      "Training on :(4, 5)\n",
      "Epoch time:4.10930609703\n",
      "Epoch:28\n",
      "training cost:0.0460075996816 and training accuracy:0.98634147644\n",
      "validation cost:0.0291413012892 and validation accuracy:0.99210268259\n",
      "Testing accuracy on :set0 while training :set2 is :0.99669033289\n",
      "Testing accuracy on :set1 while training :set2 is :0.904015660286\n",
      "Training on :(4, 5)\n",
      "Epoch time:3.78026914597\n",
      "Epoch:29\n",
      "training cost:0.0456841289997 and training accuracy:0.986634135246\n",
      "validation cost:0.0289026349783 and validation accuracy:0.99210268259\n",
      "Testing accuracy on :set0 while training :set2 is :0.99669033289\n",
      "Testing accuracy on :set1 while training :set2 is :0.903036236763\n",
      "Training on :(4, 5)\n",
      "Epoch time:4.79482507706\n",
      "Final test accuracy is:0.988794028759\n",
      "Test accuracy corresp to best val acc:0.988260388374\n",
      "Time taken:122.350553989\n",
      "Testing accuracy on :set0 after training :set2 is :0.99669033289\n",
      "Testing accuracy on :set1 after training :set2 is :0.903036236763\n",
      "MAXIMUM omegW2:0.0, MEAN omegW2:0.0\n",
      "MAXIMUM omegb2:0.0, MEAN omegb2:0.0\n",
      "MAXIMUM omegW3:0.0, MEAN omegW3:0.0\n",
      "MAXIMUM omegb3:0.0, MEAN omegb3:0.0\n",
      "Test features:(1986, 784)\n",
      "Length of test labels:1986\n",
      "Train features:(11087, 784)\n",
      "Length of train labels:11087\n",
      "Valid features:(1096, 784)\n",
      "Length of valid labels:1096\n",
      "Number of batches:1108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat:0\n",
      "Epoch:0\n",
      "training cost:80.889175415 and training accuracy:0.404888600111\n",
      "validation cost:83.1206054688 and validation accuracy:0.372262775898\n",
      "Testing accuracy on :set0 while training :set3 is :0.99669033289\n",
      "Testing accuracy on :set1 while training :set3 is :0.903036236763\n",
      "Testing accuracy on :set2 while training :set3 is :0.988794028759\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.13732409477\n",
      "Epoch:1\n",
      "training cost:0.177095934749 and training accuracy:0.964282512665\n",
      "validation cost:0.164534538984 and validation accuracy:0.97445255518\n",
      "Testing accuracy on :set0 while training :set3 is :0.987706840038\n",
      "Testing accuracy on :set1 while training :set3 is :0.920176327229\n",
      "Testing accuracy on :set2 while training :set3 is :0.98505872488\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.31781196594\n",
      "Epoch:2\n",
      "training cost:0.0636144280434 and training accuracy:0.986560821533\n",
      "validation cost:0.0549878105521 and validation accuracy:0.989963531494\n",
      "Testing accuracy on :set0 while training :set3 is :0.982978701591\n",
      "Testing accuracy on :set1 while training :set3 is :0.925073444843\n",
      "Testing accuracy on :set2 while training :set3 is :0.986125946045\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.25214099884\n",
      "Epoch:3\n",
      "training cost:0.0350508876145 and training accuracy:0.990709841251\n",
      "validation cost:0.0297107864171 and validation accuracy:0.989963531494\n",
      "Testing accuracy on :set0 while training :set3 is :0.979196190834\n",
      "Testing accuracy on :set1 while training :set3 is :0.929480910301\n",
      "Testing accuracy on :set2 while training :set3 is :0.98559230566\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.05387091637\n",
      "Epoch:4\n",
      "training cost:0.0243821498007 and training accuracy:0.992423534393\n",
      "validation cost:0.0210200473666 and validation accuracy:0.990875899792\n",
      "Testing accuracy on :set0 while training :set3 is :0.979196190834\n",
      "Testing accuracy on :set1 while training :set3 is :0.930950045586\n",
      "Testing accuracy on :set2 while training :set3 is :0.98559230566\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.08004593849\n",
      "Epoch:5\n",
      "training cost:0.0189732573926 and training accuracy:0.993686318398\n",
      "validation cost:0.0166965108365 and validation accuracy:0.993613123894\n",
      "Testing accuracy on :set0 while training :set3 is :0.976832151413\n",
      "Testing accuracy on :set1 while training :set3 is :0.93241918087\n",
      "Testing accuracy on :set2 while training :set3 is :0.98559230566\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.05348491669\n",
      "Epoch:6\n",
      "training cost:0.0160271432251 and training accuracy:0.994407892227\n",
      "validation cost:0.0143380118534 and validation accuracy:0.993613123894\n",
      "Testing accuracy on :set0 while training :set3 is :0.976359367371\n",
      "Testing accuracy on :set1 while training :set3 is :0.93241918087\n",
      "Testing accuracy on :set2 while training :set3 is :0.98559230566\n",
      "Training on :(6, 7)\n",
      "Epoch time:5.01253509521\n",
      "Epoch:7\n",
      "training cost:0.0140036037192 and training accuracy:0.995400011539\n",
      "validation cost:0.01265532244 and validation accuracy:0.993613123894\n",
      "Testing accuracy on :set0 while training :set3 is :0.974940896034\n",
      "Testing accuracy on :set1 while training :set3 is :0.931439757347\n",
      "Testing accuracy on :set2 while training :set3 is :0.98559230566\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.05398201942\n",
      "Epoch:8\n",
      "training cost:0.0133915217593 and training accuracy:0.995580434799\n",
      "validation cost:0.0124311260879 and validation accuracy:0.993613123894\n",
      "Testing accuracy on :set0 while training :set3 is :0.973522484303\n",
      "Testing accuracy on :set1 while training :set3 is :0.931929469109\n",
      "Testing accuracy on :set2 while training :set3 is :0.98559230566\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.09726595879\n",
      "Epoch:9\n",
      "training cost:0.0118348579854 and training accuracy:0.996301949024\n",
      "validation cost:0.0108625600114 and validation accuracy:0.995437979698\n",
      "Testing accuracy on :set0 while training :set3 is :0.973522484303\n",
      "Testing accuracy on :set1 while training :set3 is :0.931929469109\n",
      "Testing accuracy on :set2 while training :set3 is :0.98559230566\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.21385383606\n",
      "Epoch:10\n",
      "training cost:0.0113112423569 and training accuracy:0.996301949024\n",
      "validation cost:0.0105156349018 and validation accuracy:0.995437979698\n",
      "Testing accuracy on :set0 while training :set3 is :0.973049640656\n",
      "Testing accuracy on :set1 while training :set3 is :0.931439757347\n",
      "Testing accuracy on :set2 while training :set3 is :0.98559230566\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.07724118233\n",
      "Epoch:11\n",
      "training cost:0.0100452098995 and training accuracy:0.996482372284\n",
      "validation cost:0.00901363790035 and validation accuracy:0.995437979698\n",
      "Testing accuracy on :set0 while training :set3 is :0.971631228924\n",
      "Testing accuracy on :set1 while training :set3 is :0.931929469109\n",
      "Testing accuracy on :set2 while training :set3 is :0.986125946045\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.07201099396\n",
      "Epoch:12\n",
      "training cost:0.00973887275904 and training accuracy:0.996392190456\n",
      "validation cost:0.0088074747473 and validation accuracy:0.995437979698\n",
      "Testing accuracy on :set0 while training :set3 is :0.971631228924\n",
      "Testing accuracy on :set1 while training :set3 is :0.930460333824\n",
      "Testing accuracy on :set2 while training :set3 is :0.986125946045\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.33342385292\n",
      "Epoch:13\n",
      "training cost:0.00908535905182 and training accuracy:0.996572554111\n",
      "validation cost:0.00804344937205 and validation accuracy:0.995437979698\n",
      "Testing accuracy on :set0 while training :set3 is :0.971631228924\n",
      "Testing accuracy on :set1 while training :set3 is :0.930460333824\n",
      "Testing accuracy on :set2 while training :set3 is :0.986125946045\n",
      "Training on :(6, 7)\n",
      "Epoch time:5.02719402313\n",
      "Epoch:14\n",
      "training cost:0.00873828493059 and training accuracy:0.996752977371\n",
      "validation cost:0.00769081432372 and validation accuracy:0.995437979698\n",
      "Testing accuracy on :set0 while training :set3 is :0.970685601234\n",
      "Testing accuracy on :set1 while training :set3 is :0.931929469109\n",
      "Testing accuracy on :set2 while training :set3 is :0.98559230566\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.09805011749\n",
      "Epoch:15\n",
      "training cost:0.00867715850472 and training accuracy:0.996752977371\n",
      "validation cost:0.00774039933458 and validation accuracy:0.995437979698\n",
      "Testing accuracy on :set0 while training :set3 is :0.970685601234\n",
      "Testing accuracy on :set1 while training :set3 is :0.931439757347\n",
      "Testing accuracy on :set2 while training :set3 is :0.98559230566\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.07620692253\n",
      "Epoch:16\n",
      "training cost:0.00833881087601 and training accuracy:0.996843159199\n",
      "validation cost:0.00734378118068 and validation accuracy:0.995437979698\n",
      "Testing accuracy on :set0 while training :set3 is :0.970212757587\n",
      "Testing accuracy on :set1 while training :set3 is :0.930950045586\n",
      "Testing accuracy on :set2 while training :set3 is :0.98559230566\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.34171414375\n",
      "Epoch:17\n",
      "training cost:0.00806495547295 and training accuracy:0.997113764286\n",
      "validation cost:0.00702781975269 and validation accuracy:0.995437979698\n",
      "Testing accuracy on :set0 while training :set3 is :0.970212757587\n",
      "Testing accuracy on :set1 while training :set3 is :0.930950045586\n",
      "Testing accuracy on :set2 while training :set3 is :0.98559230566\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.10154390335\n",
      "Epoch:18\n",
      "training cost:0.0076138372533 and training accuracy:0.997654914856\n",
      "validation cost:0.00641290238127 and validation accuracy:0.996350347996\n",
      "Testing accuracy on :set0 while training :set3 is :0.970212757587\n",
      "Testing accuracy on :set1 while training :set3 is :0.930460333824\n",
      "Testing accuracy on :set2 while training :set3 is :0.98559230566\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.08802914619\n",
      "Epoch:19\n",
      "training cost:0.00735574029386 and training accuracy:0.997745096684\n",
      "validation cost:0.0060777538456 and validation accuracy:0.996350347996\n",
      "Testing accuracy on :set0 while training :set3 is :0.970212757587\n",
      "Testing accuracy on :set1 while training :set3 is :0.930460333824\n",
      "Testing accuracy on :set2 while training :set3 is :0.98505872488\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.08304595947\n",
      "Epoch:20\n",
      "training cost:0.00769071467221 and training accuracy:0.997384309769\n",
      "validation cost:0.00664747692645 and validation accuracy:0.995437979698\n",
      "Testing accuracy on :set0 while training :set3 is :0.970212757587\n",
      "Testing accuracy on :set1 while training :set3 is :0.928501486778\n",
      "Testing accuracy on :set2 while training :set3 is :0.98505872488\n",
      "Training on :(6, 7)\n",
      "Epoch time:5.08813118935\n",
      "Epoch:21\n",
      "training cost:0.00703050894663 and training accuracy:0.998015701771\n",
      "validation cost:0.00567815685645 and validation accuracy:0.996350347996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy on :set0 while training :set3 is :0.970212757587\n",
      "Testing accuracy on :set1 while training :set3 is :0.92899119854\n",
      "Testing accuracy on :set2 while training :set3 is :0.98505872488\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.06374311447\n",
      "Epoch:22\n",
      "training cost:0.00695542711765 and training accuracy:0.998015701771\n",
      "validation cost:0.00562358926982 and validation accuracy:0.996350347996\n",
      "Testing accuracy on :set0 while training :set3 is :0.970212757587\n",
      "Testing accuracy on :set1 while training :set3 is :0.928011775017\n",
      "Testing accuracy on :set2 while training :set3 is :0.98505872488\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.19493508339\n",
      "Epoch:23\n",
      "training cost:0.00651582237333 and training accuracy:0.997925519943\n",
      "validation cost:0.00495749665424 and validation accuracy:0.996350347996\n",
      "Testing accuracy on :set0 while training :set3 is :0.970212757587\n",
      "Testing accuracy on :set1 while training :set3 is :0.927522063255\n",
      "Testing accuracy on :set2 while training :set3 is :0.98505872488\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.06816005707\n",
      "Epoch:24\n",
      "training cost:0.0067094177939 and training accuracy:0.998015701771\n",
      "validation cost:0.00532768620178 and validation accuracy:0.996350347996\n",
      "Testing accuracy on :set0 while training :set3 is :0.970212757587\n",
      "Testing accuracy on :set1 while training :set3 is :0.927522063255\n",
      "Testing accuracy on :set2 while training :set3 is :0.98505872488\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.22761797905\n",
      "Epoch:25\n",
      "training cost:0.00644880719483 and training accuracy:0.998015701771\n",
      "validation cost:0.00495757767931 and validation accuracy:0.996350347996\n",
      "Testing accuracy on :set0 while training :set3 is :0.970212757587\n",
      "Testing accuracy on :set1 while training :set3 is :0.927522063255\n",
      "Testing accuracy on :set2 while training :set3 is :0.98505872488\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.10501599312\n",
      "Epoch:26\n",
      "training cost:0.00626414641738 and training accuracy:0.998015701771\n",
      "validation cost:0.0046885558404 and validation accuracy:0.996350347996\n",
      "Testing accuracy on :set0 while training :set3 is :0.969739973545\n",
      "Testing accuracy on :set1 while training :set3 is :0.927522063255\n",
      "Testing accuracy on :set2 while training :set3 is :0.98505872488\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.05445814133\n",
      "Epoch:27\n",
      "training cost:0.00645169755444 and training accuracy:0.998105883598\n",
      "validation cost:0.00503995828331 and validation accuracy:0.996350347996\n",
      "Testing accuracy on :set0 while training :set3 is :0.969739973545\n",
      "Testing accuracy on :set1 while training :set3 is :0.927522063255\n",
      "Testing accuracy on :set2 while training :set3 is :0.98505872488\n",
      "Training on :(6, 7)\n",
      "Epoch time:5.04589796066\n",
      "Epoch:28\n",
      "training cost:0.00635500298813 and training accuracy:0.998105883598\n",
      "validation cost:0.00490607134998 and validation accuracy:0.996350347996\n",
      "Testing accuracy on :set0 while training :set3 is :0.969267129898\n",
      "Testing accuracy on :set1 while training :set3 is :0.927522063255\n",
      "Testing accuracy on :set2 while training :set3 is :0.98505872488\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.1058139801\n",
      "Epoch:29\n",
      "training cost:0.00625389162451 and training accuracy:0.998105883598\n",
      "validation cost:0.00475595099851 and validation accuracy:0.996350347996\n",
      "Testing accuracy on :set0 while training :set3 is :0.969267129898\n",
      "Testing accuracy on :set1 while training :set3 is :0.927522063255\n",
      "Testing accuracy on :set2 while training :set3 is :0.98505872488\n",
      "Training on :(6, 7)\n",
      "Epoch time:4.11121702194\n",
      "Final test accuracy is:0.994964778423\n",
      "Test accuracy corresp to best val acc:0.993957698345\n",
      "Time taken:129.769325018\n",
      "Testing accuracy on :set0 after training :set3 is :0.969267129898\n",
      "Testing accuracy on :set1 after training :set3 is :0.927032291889\n",
      "Testing accuracy on :set2 after training :set3 is :0.98505872488\n",
      "MAXIMUM omegW2:0.0, MEAN omegW2:0.0\n",
      "MAXIMUM omegb2:0.0, MEAN omegb2:0.0\n",
      "MAXIMUM omegW3:0.0, MEAN omegW3:0.0\n",
      "MAXIMUM omegb3:0.0, MEAN omegb3:0.0\n",
      "Test features:(1983, 784)\n",
      "Length of test labels:1983\n",
      "Train features:(10738, 784)\n",
      "Length of train labels:10738\n",
      "Valid features:(1062, 784)\n",
      "Length of valid labels:1062\n",
      "Number of batches:1073\n",
      "Repeat:0\n",
      "Epoch:0\n",
      "training cost:149.104003906 and training accuracy:0.0143415909261\n",
      "validation cost:151.782363892 and validation accuracy:0.0112994350493\n",
      "Testing accuracy on :set0 while training :set4 is :0.969267129898\n",
      "Testing accuracy on :set1 while training :set4 is :0.927032291889\n",
      "Testing accuracy on :set2 while training :set4 is :0.98505872488\n",
      "Testing accuracy on :set3 while training :set4 is :0.994964778423\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.1026301384\n",
      "Epoch:1\n",
      "training cost:0.171828612685 and training accuracy:0.94347178936\n",
      "validation cost:0.150283515453 and validation accuracy:0.952919006348\n",
      "Testing accuracy on :set0 while training :set4 is :0.807565033436\n",
      "Testing accuracy on :set1 while training :set4 is :0.639569044113\n",
      "Testing accuracy on :set2 while training :set4 is :0.983991444111\n",
      "Testing accuracy on :set3 while training :set4 is :0.993957698345\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.96257400513\n",
      "Epoch:2\n",
      "training cost:0.159795865417 and training accuracy:0.94002610445\n",
      "validation cost:0.132025852799 and validation accuracy:0.951035797596\n",
      "Testing accuracy on :set0 while training :set4 is :0.793380618095\n",
      "Testing accuracy on :set1 while training :set4 is :0.599412322044\n",
      "Testing accuracy on :set2 while training :set4 is :0.983991444111\n",
      "Testing accuracy on :set3 while training :set4 is :0.993454158306\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.93467998505\n",
      "Epoch:3\n",
      "training cost:0.141433522105 and training accuracy:0.950642585754\n",
      "validation cost:0.111360937357 and validation accuracy:0.963276863098\n",
      "Testing accuracy on :set0 while training :set4 is :0.782978713512\n",
      "Testing accuracy on :set1 while training :set4 is :0.57100880146\n",
      "Testing accuracy on :set2 while training :set4 is :0.982924222946\n",
      "Testing accuracy on :set3 while training :set4 is :0.992447137833\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.95213198662\n",
      "Epoch:4\n",
      "training cost:0.137358039618 and training accuracy:0.953063905239\n",
      "validation cost:0.106222659349 and validation accuracy:0.96516007185\n",
      "Testing accuracy on :set0 while training :set4 is :0.777304947376\n",
      "Testing accuracy on :set1 while training :set4 is :0.555827617645\n",
      "Testing accuracy on :set2 while training :set4 is :0.983991444111\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.89104914665\n",
      "Epoch:5\n",
      "training cost:0.129848316312 and training accuracy:0.957534015179\n",
      "validation cost:0.0986002832651 and validation accuracy:0.967043340206\n",
      "Testing accuracy on :set0 while training :set4 is :0.771158397198\n",
      "Testing accuracy on :set1 while training :set4 is :0.540156722069\n",
      "Testing accuracy on :set2 while training :set4 is :0.983991444111\n",
      "Testing accuracy on :set3 while training :set4 is :0.993454158306\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.216547966\n",
      "Epoch:6\n",
      "training cost:0.129744827747 and training accuracy:0.957254588604\n",
      "validation cost:0.0982728824019 and validation accuracy:0.967043340206\n",
      "Testing accuracy on :set0 while training :set4 is :0.76832151413\n",
      "Testing accuracy on :set1 while training :set4 is :0.533300697803\n",
      "Testing accuracy on :set2 while training :set4 is :0.984525084496\n",
      "Testing accuracy on :set3 while training :set4 is :0.993454158306\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.09389615059\n",
      "Epoch:7\n",
      "training cost:0.126239284873 and training accuracy:0.958837747574\n",
      "validation cost:0.0948461145163 and validation accuracy:0.967043340206\n",
      "Testing accuracy on :set0 while training :set4 is :0.762174963951\n",
      "Testing accuracy on :set1 while training :set4 is :0.522526919842\n",
      "Testing accuracy on :set2 while training :set4 is :0.983457863331\n",
      "Testing accuracy on :set3 while training :set4 is :0.993454158306\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.98827290535\n",
      "Epoch:8\n",
      "training cost:0.125211209059 and training accuracy:0.959862172604\n",
      "validation cost:0.0936283841729 and validation accuracy:0.96798491478\n",
      "Testing accuracy on :set0 while training :set4 is :0.761702120304\n",
      "Testing accuracy on :set1 while training :set4 is :0.513712048531\n",
      "Testing accuracy on :set2 while training :set4 is :0.983457863331\n",
      "Testing accuracy on :set3 while training :set4 is :0.993454158306\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.94921398163\n",
      "Epoch:9\n",
      "training cost:0.120938561857 and training accuracy:0.961445331573\n",
      "validation cost:0.0892938300967 and validation accuracy:0.968926548958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy on :set0 while training :set4 is :0.757919609547\n",
      "Testing accuracy on :set1 while training :set4 is :0.507345736027\n",
      "Testing accuracy on :set2 while training :set4 is :0.983991444111\n",
      "Testing accuracy on :set3 while training :set4 is :0.993454158306\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.98204016685\n",
      "Epoch:10\n",
      "training cost:0.115256279707 and training accuracy:0.963866651058\n",
      "validation cost:0.08367908746 and validation accuracy:0.971751391888\n",
      "Testing accuracy on :set0 while training :set4 is :0.755555570126\n",
      "Testing accuracy on :set1 while training :set4 is :0.499020576477\n",
      "Testing accuracy on :set2 while training :set4 is :0.983991444111\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.97174596786\n",
      "Epoch:11\n",
      "training cost:0.115139551461 and training accuracy:0.964052915573\n",
      "validation cost:0.0835602134466 and validation accuracy:0.968926548958\n",
      "Testing accuracy on :set0 while training :set4 is :0.755555570126\n",
      "Testing accuracy on :set1 while training :set4 is :0.498530864716\n",
      "Testing accuracy on :set2 while training :set4 is :0.983457863331\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.9886610508\n",
      "Epoch:12\n",
      "training cost:0.111915707588 and training accuracy:0.965077280998\n",
      "validation cost:0.0801483914256 and validation accuracy:0.970809817314\n",
      "Testing accuracy on :set0 while training :set4 is :0.752718687057\n",
      "Testing accuracy on :set1 while training :set4 is :0.494123399258\n",
      "Testing accuracy on :set2 while training :set4 is :0.982924222946\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.96738100052\n",
      "Epoch:13\n",
      "training cost:0.10978166014 and training accuracy:0.966287970543\n",
      "validation cost:0.0779216811061 and validation accuracy:0.972693026066\n",
      "Testing accuracy on :set0 while training :set4 is :0.751773059368\n",
      "Testing accuracy on :set1 while training :set4 is :0.489226251841\n",
      "Testing accuracy on :set2 while training :set4 is :0.982924222946\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.98665904999\n",
      "Epoch:14\n",
      "training cost:0.106790341437 and training accuracy:0.967126071453\n",
      "validation cost:0.0748628973961 and validation accuracy:0.972693026066\n",
      "Testing accuracy on :set0 while training :set4 is :0.749408960342\n",
      "Testing accuracy on :set1 while training :set4 is :0.485308527946\n",
      "Testing accuracy on :set2 while training :set4 is :0.982924222946\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.15067005157\n",
      "Epoch:15\n",
      "training cost:0.105170384049 and training accuracy:0.967777967453\n",
      "validation cost:0.0730186998844 and validation accuracy:0.974576294422\n",
      "Testing accuracy on :set0 while training :set4 is :0.749408960342\n",
      "Testing accuracy on :set1 while training :set4 is :0.484329074621\n",
      "Testing accuracy on :set2 while training :set4 is :0.982924222946\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.9853720665\n",
      "Epoch:16\n",
      "training cost:0.102306984365 and training accuracy:0.969268023968\n",
      "validation cost:0.069791637361 and validation accuracy:0.973634660244\n",
      "Testing accuracy on :set0 while training :set4 is :0.748463332653\n",
      "Testing accuracy on :set1 while training :set4 is :0.480901062489\n",
      "Testing accuracy on :set2 while training :set4 is :0.982924222946\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.99820709229\n",
      "Epoch:17\n",
      "training cost:0.102193087339 and training accuracy:0.969454288483\n",
      "validation cost:0.06991199404 and validation accuracy:0.976459503174\n",
      "Testing accuracy on :set0 while training :set4 is :0.748463332653\n",
      "Testing accuracy on :set1 while training :set4 is :0.482370227575\n",
      "Testing accuracy on :set2 while training :set4 is :0.982924222946\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.93365502357\n",
      "Epoch:18\n",
      "training cost:0.0995300263166 and training accuracy:0.970478653908\n",
      "validation cost:0.0671604499221 and validation accuracy:0.976459503174\n",
      "Testing accuracy on :set0 while training :set4 is :0.747517704964\n",
      "Testing accuracy on :set1 while training :set4 is :0.479921638966\n",
      "Testing accuracy on :set2 while training :set4 is :0.982924222946\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:5.01992583275\n",
      "Epoch:19\n",
      "training cost:0.097312182188 and training accuracy:0.970478653908\n",
      "validation cost:0.0648213326931 and validation accuracy:0.974576294422\n",
      "Testing accuracy on :set0 while training :set4 is :0.745626449585\n",
      "Testing accuracy on :set1 while training :set4 is :0.475024491549\n",
      "Testing accuracy on :set2 while training :set4 is :0.982924222946\n",
      "Testing accuracy on :set3 while training :set4 is :0.992950677872\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.96320199966\n",
      "Epoch:20\n",
      "training cost:0.0961276292801 and training accuracy:0.971316814423\n",
      "validation cost:0.0632451996207 and validation accuracy:0.977401137352\n",
      "Testing accuracy on :set0 while training :set4 is :0.745626449585\n",
      "Testing accuracy on :set1 while training :set4 is :0.474045068026\n",
      "Testing accuracy on :set2 while training :set4 is :0.981857001781\n",
      "Testing accuracy on :set3 while training :set4 is :0.992447137833\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.97715592384\n",
      "Epoch:21\n",
      "training cost:0.0945800095797 and training accuracy:0.971503078938\n",
      "validation cost:0.0615921728313 and validation accuracy:0.977401137352\n",
      "Testing accuracy on :set0 while training :set4 is :0.743735253811\n",
      "Testing accuracy on :set1 while training :set4 is :0.472575902939\n",
      "Testing accuracy on :set2 while training :set4 is :0.981857001781\n",
      "Testing accuracy on :set3 while training :set4 is :0.992447137833\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.09708690643\n",
      "Epoch:22\n",
      "training cost:0.0930551737547 and training accuracy:0.971968710423\n",
      "validation cost:0.0600630007684 and validation accuracy:0.980225980282\n",
      "Testing accuracy on :set0 while training :set4 is :0.743262410164\n",
      "Testing accuracy on :set1 while training :set4 is :0.4730656147\n",
      "Testing accuracy on :set2 while training :set4 is :0.981323361397\n",
      "Testing accuracy on :set3 while training :set4 is :0.992447137833\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.95767998695\n",
      "Epoch:23\n",
      "training cost:0.0927252992988 and training accuracy:0.972806870937\n",
      "validation cost:0.0595514327288 and validation accuracy:0.980225980282\n",
      "Testing accuracy on :set0 while training :set4 is :0.744208037853\n",
      "Testing accuracy on :set1 while training :set4 is :0.472575902939\n",
      "Testing accuracy on :set2 while training :set4 is :0.981323361397\n",
      "Testing accuracy on :set3 while training :set4 is :0.992447137833\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.94514298439\n",
      "Epoch:24\n",
      "training cost:0.0911841616035 and training accuracy:0.973086237907\n",
      "validation cost:0.0579936876893 and validation accuracy:0.980225980282\n",
      "Testing accuracy on :set0 while training :set4 is :0.743262410164\n",
      "Testing accuracy on :set1 while training :set4 is :0.471596479416\n",
      "Testing accuracy on :set2 while training :set4 is :0.981323361397\n",
      "Testing accuracy on :set3 while training :set4 is :0.992447137833\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.98141908646\n",
      "Epoch:25\n",
      "training cost:0.0896475613117 and training accuracy:0.972713708878\n",
      "validation cost:0.0564424917102 and validation accuracy:0.980225980282\n",
      "Testing accuracy on :set0 while training :set4 is :0.743262410164\n",
      "Testing accuracy on :set1 while training :set4 is :0.468658179045\n",
      "Testing accuracy on :set2 while training :set4 is :0.981857001781\n",
      "Testing accuracy on :set3 while training :set4 is :0.992447137833\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.6940510273\n",
      "Epoch:26\n",
      "training cost:0.0887554883957 and training accuracy:0.973179340363\n",
      "validation cost:0.0555431991816 and validation accuracy:0.980225980282\n",
      "Testing accuracy on :set0 while training :set4 is :0.742789626122\n",
      "Testing accuracy on :set1 while training :set4 is :0.465719878674\n",
      "Testing accuracy on :set2 while training :set4 is :0.981857001781\n",
      "Testing accuracy on :set3 while training :set4 is :0.992447137833\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.14232397079\n",
      "Epoch:27\n",
      "training cost:0.0877579599619 and training accuracy:0.973738133907\n",
      "validation cost:0.0545011162758 and validation accuracy:0.980225980282\n",
      "Testing accuracy on :set0 while training :set4 is :0.742789626122\n",
      "Testing accuracy on :set1 while training :set4 is :0.466209590435\n",
      "Testing accuracy on :set2 while training :set4 is :0.981857001781\n",
      "Testing accuracy on :set3 while training :set4 is :0.992447137833\n",
      "Training on :(8, 9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch time:4.20186877251\n",
      "Epoch:28\n",
      "training cost:0.0869158580899 and training accuracy:0.974483132362\n",
      "validation cost:0.0534896552563 and validation accuracy:0.980225980282\n",
      "Testing accuracy on :set0 while training :set4 is :0.742789626122\n",
      "Testing accuracy on :set1 while training :set4 is :0.466209590435\n",
      "Testing accuracy on :set2 while training :set4 is :0.981857001781\n",
      "Testing accuracy on :set3 while training :set4 is :0.992447137833\n",
      "Training on :(8, 9)\n",
      "Epoch time:4.16803598404\n",
      "Epoch:29\n",
      "training cost:0.0858504325151 and training accuracy:0.974576294422\n",
      "validation cost:0.0526417084038 and validation accuracy:0.982109248638\n",
      "Testing accuracy on :set0 while training :set4 is :0.740898370743\n",
      "Testing accuracy on :set1 while training :set4 is :0.462291866541\n",
      "Testing accuracy on :set2 while training :set4 is :0.981857001781\n",
      "Testing accuracy on :set3 while training :set4 is :0.992447137833\n",
      "Training on :(8, 9)\n",
      "Epoch time:3.98538708687\n",
      "Final test accuracy is:0.970247089863\n",
      "Test accuracy corresp to best val acc:0.970751404762\n",
      "Time taken:126.22894001\n",
      "Testing accuracy on :set0 after training :set4 is :0.740898370743\n",
      "Testing accuracy on :set1 after training :set4 is :0.462291866541\n",
      "Testing accuracy on :set2 after training :set4 is :0.981857001781\n",
      "Testing accuracy on :set3 after training :set4 is :0.992447137833\n",
      "MAXIMUM omegW2:0.0, MEAN omegW2:0.0\n",
      "MAXIMUM omegb2:0.0, MEAN omegb2:0.0\n",
      "MAXIMUM omegW3:0.0, MEAN omegW3:0.0\n",
      "MAXIMUM omegb3:0.0, MEAN omegb3:0.0\n"
     ]
    }
   ],
   "source": [
    "#INITIALIZE THE NETWORK\n",
    "sess.run(init_op,options=run_options, run_metadata=run_metadata)\n",
    "zeta = 1e-3\n",
    "new_big_omeg_w2 = np.zeros(shape=[n_input,n_middle], dtype=np.float32)\n",
    "new_big_omeg_b2 = np.zeros(shape=[1,n_middle], dtype=np.float32)\n",
    "new_big_omeg_w3 = np.zeros(shape=[n_middle,n_out], dtype=np.float32)\n",
    "new_big_omeg_b3 = np.zeros(shape=[1,n_out], dtype=np.float32)\n",
    "\n",
    "reset_w2_grad_accum = np.zeros(shape=[n_input,n_middle], dtype=np.float32)\n",
    "reset_b2_grad_accum = np.zeros(shape=[1,n_middle], dtype=np.float32)\n",
    "reset_w3_grad_accum = np.zeros(shape=[n_middle,n_out], dtype=np.float32)\n",
    "reset_b3_grad_accum = np.zeros(shape=[1,n_out], dtype=np.float32)\n",
    "    \n",
    "start_w2 = None\n",
    "start_b2 = None\n",
    "start_w3 = None\n",
    "start_b3 = None\n",
    "\n",
    "end_w2 = None\n",
    "end_b2 = None\n",
    "end_w3 = None\n",
    "end_b3 = None\n",
    "\n",
    "old_test_data = []\n",
    "historical_cross_test_acc = {}\n",
    "historical_train_accuracies = {}\n",
    "historical_train_costs = {}\n",
    "historical_val_accuracies = {}\n",
    "historical_val_costs = {}\n",
    "sets = [(0,1), (2,3), (4,5), (6,7), (8,9)]\n",
    "#sets = [(0,4),(5,9)]\n",
    "test_labels_set = []\n",
    "logging_count = 0\n",
    "n_test_samples = []\n",
    "for a_set in range(len(sets)):\n",
    "    current_set = sets[a_set]\n",
    "    current_set_name = 'set'+str(a_set)\n",
    "    mask_val = [0]*num_classes\n",
    "    for i in range(current_set[0], current_set[1]+1):\n",
    "        mask_val[i]=1\n",
    "    set_mask_val = np.array(mask_val, dtype=np.float32)\n",
    "    train_data_set, valid_data_set, test_data_set = extract_class_data(start=current_set[0],\n",
    "                                                                  stop=current_set[1])\n",
    "    train_images_set, train_labels_set = train_data_set[0], train_data_set[1]\n",
    "    valid_images_set, valid_labels_set = valid_data_set[0], valid_data_set[1]\n",
    "    test_images_set, test_labels_set = test_data_set[0], test_data_set[1]\n",
    "    n_test_samples.append(len(test_labels_set))\n",
    "    train_total = len(train_images_set)\n",
    "    n_batches = len(train_images_set)/BATCH_SIZE\n",
    "    print('Number of batches:{}'.format(n_batches))\n",
    "\n",
    "\n",
    "    set_omegas = [tf.assign(big_omeg_w2, new_big_omeg_w2), tf.assign(big_omeg_b2, new_big_omeg_b2), \n",
    "                  tf.assign(big_omeg_w3, new_big_omeg_w3), tf.assign(big_omeg_b3, new_big_omeg_b3)]\n",
    "    sess.run(set_omegas)\n",
    "    \n",
    "    reset_grad_accums = [tf.assign(w2_grad_accum, reset_w2_grad_accum),\n",
    "                         tf.assign(b2_grad_accum, reset_b2_grad_accum),\n",
    "                         tf.assign(w3_grad_accum, reset_w3_grad_accum),\n",
    "                         tf.assign(b3_grad_accum, reset_b3_grad_accum)]\n",
    "    sess.run(reset_grad_accums)\n",
    "                                                                                  \n",
    "    epochs = 30\n",
    "    repeats = 1\n",
    "    \n",
    "    for repeat in range(repeats):\n",
    "        tf.set_random_seed(repeat)\n",
    "        print('Repeat:{}'.format(repeat))\n",
    "        train_accuracies = []\n",
    "        train_costs = []\n",
    "        val_accuracies = []\n",
    "        val_costs = []\n",
    "        best_val = 0\n",
    "        first_params_set = None\n",
    "        last_params_set = None\n",
    "        T1 = time.time()\n",
    "        for i in range(epochs):\n",
    "            if(i==0):\n",
    "                start_w2, start_b2, start_w3, start_b3 = w_2.eval(), b_2.eval(), w_3.eval(), b_3.eval()\n",
    "            sess.run(iter.initializer, feed_dict={a_1: train_images_set, y: train_labels_set,\n",
    "                                                  batch_size: len(train_images_set)})\n",
    "            print('Epoch:{}'.format((i)))\n",
    "            t1 = time.time()\n",
    "\n",
    "            ### CALCULATE TRAIN COSTS AND TRAIN ACCURACIES\n",
    "            train_cost, train_accuracy = sess.run([cost, acct_res] ,feed_dict = {drop_out : 0.0, \n",
    "                                                                                 set1_mask:set_mask_val})\n",
    "            train_costs.append(train_cost)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            #train_writer.add_summary(summary,logging_count)\n",
    "\n",
    "            print('training cost:{} and training accuracy:{}'.format(train_costs[i], train_accuracies[i]))\n",
    "\n",
    "            ### CALCULATE VALID COSTS AND VALID ACCURACIES\n",
    "            sess.run(iter.initializer, feed_dict={a_1: valid_images_set, y: valid_labels_set,\n",
    "                                                  batch_size: len(valid_images_set)})\n",
    "            _, _, val_acc, val_cost, _ = sess.run([predictions,acct_mat,acct_res, cost, a_3],\n",
    "                                                  feed_dict = {drop_out : 0.0,set1_mask:set_mask_val})\n",
    "            val_costs.append(val_cost)\n",
    "            val_accuracies.append(val_acc)\n",
    "\n",
    "            if(val_acc>best_val):\n",
    "                best_val = val_acc\n",
    "                best_params_set1 = [(w_2.eval(),b_2.eval()),(w_3.eval(),b_3.eval())]\n",
    "            print('validation cost:{} and validation accuracy:{}'.format(val_cost, val_acc))   \n",
    "            sess.run(iter.initializer, feed_dict={a_1: train_images_set, y: train_labels_set,\n",
    "                                                  batch_size: BATCH_SIZE})\n",
    "            \n",
    "            for d in range(len(old_test_data)):\n",
    "                previous_set_name = 'set'+str(d)           \n",
    "                prev_set = sets[d]\n",
    "                prev_mask_val = [0]*num_classes\n",
    "                for clas in range(prev_set[0], prev_set[1]+1):\n",
    "                    prev_mask_val[clas]=1\n",
    "                prev_set_mask_val = np.array(prev_mask_val, dtype=np.float32)\n",
    "                sess.run(iter.initializer, feed_dict={a_1: old_test_data[d][0], y: old_test_data[d][1],\n",
    "                                                  batch_size: len(old_test_data[d][0])})\n",
    "                _, _, hist_test_acc, _, _ = sess.run([predictions,acct_mat,acct_res, cost, a_3],\n",
    "                                                      feed_dict = {drop_out : 0.0,set1_mask:prev_set_mask_val})\n",
    "                \n",
    "                print('Testing accuracy on :{} while training :{} is :{}'.format(previous_set_name,\n",
    "                                                                          current_set_name,\n",
    "                                                                          hist_test_acc))\n",
    "                if(current_set_name+'-'+previous_set_name in historical_cross_test_acc.keys()):\n",
    "                    historical_cross_test_acc[current_set_name+'-'+previous_set_name].append(hist_test_acc)\n",
    "                else:\n",
    "                    historical_cross_test_acc[current_set_name+'-'+previous_set_name] = [hist_test_acc]\n",
    "            sess.run(iter.initializer, feed_dict={a_1: train_images_set, y: train_labels_set,\n",
    "                                              batch_size: BATCH_SIZE})\n",
    "            print('Training on :{}'.format(current_set))\n",
    "            for j in range(n_batches):\n",
    "                \n",
    "                if(not (np.isnan(w_2.eval().any() and np.isnan(w_3.eval()).any()))):\n",
    "                    #if(a_set==1):\n",
    "                    #    print(j, w_2.eval().sum(), w_3.eval().sum())\n",
    "                    if(((j)% 1000 ==0)):\n",
    "                        logging_count+=1\n",
    "                        summary,_,_ = sess.run([merged,step, omega_step], \n",
    "                                             feed_dict = {drop_out:0.5,batch_size: BATCH_SIZE, tau:0.5,\n",
    "                                                          set1_mask:set_mask_val, eta:0.001,\n",
    "                                                          lmbda:0.0e4,n_tot:train_total})\n",
    "                        #train_writer.add_summary(summary, (i+1)*j)\n",
    "                        train_writer.add_summary(summary, logging_count)\n",
    "                    else:\n",
    "                        sess.run([step, omega_step], feed_dict = {drop_out:0.5,batch_size: BATCH_SIZE, tau:0.5,\n",
    "                                                                 set1_mask:set_mask_val, eta:0.001,\n",
    "                                                                  lmbda:0.0e4,n_tot:train_total})\n",
    "                else:\n",
    "                    print('Nan encountered in epoch:{} and batch:{}'.format(i, j))\n",
    "            print('Epoch time:{}'.format(time.time()-t1))\n",
    "\n",
    "\n",
    "        sess.run(iter.initializer, feed_dict={a_1: test_images_set, y: test_labels_set,\n",
    "                                                  batch_size: len(test_images_set)})\n",
    "        _,final_test_acc,_ = sess.run([predictions, acct_res, a_3], \n",
    "                                                              feed_dict = {drop_out:0.0, \n",
    "                                                                           set1_mask:set_mask_val})\n",
    "        print('Final test accuracy is:{}'.format(final_test_acc))\n",
    "        end_w2, end_b2, end_w3, end_b3 = w_2.eval(), b_2.eval(), w_3.eval(), b_3.eval()\n",
    "        update_star_wbs = [tf.assign(star_w2,end_w2),tf.assign(star_b2,end_b2),tf.assign(star_w3,end_w3),\n",
    "                          tf.assign(star_b3,end_b3)]\n",
    "        sess.run(update_star_wbs)\n",
    "        #all_final_test_accs_set1.append(final_test_acc)\n",
    "\n",
    "\n",
    "        best_step = [tf.assign(w_2,best_params_set1[0][0]), tf.assign(b_2,best_params_set1[0][1]),\n",
    "                     tf.assign(w_3,best_params_set1[1][0]),tf.assign(b_3,best_params_set1[1][1])]\n",
    "        sess.run(best_step)\n",
    "        sess.run(iter.initializer, feed_dict={a_1: test_images_set, y: test_labels_set,\n",
    "                                                  batch_size: len(test_images_set)})\n",
    "        _,test_acc_corresp_best_val,_ = sess.run([predictions, acct_res, a_3],\n",
    "                                                 feed_dict = {drop_out:0.0,set1_mask:set_mask_val})\n",
    "\n",
    "        print('Test accuracy corresp to best val acc:{}'.format(test_acc_corresp_best_val))\n",
    "        print('Time taken:{}'.format(time.time()-T1))\n",
    "        if(i==epochs-1):\n",
    "            if(test_acc_corresp_best_val>final_test_acc):\n",
    "                end_w2, end_b2, end_w3, end_b3 = w_2.eval(), b_2.eval(), w_3.eval(), b_3.eval()\n",
    "                #all_final_test_accs_set1[-1] = test_acc_corresp_best_val\n",
    "                update_star_wbs = [tf.assign(star_w2,end_w2),tf.assign(star_b2,end_b2),tf.assign(star_w3,end_w3),\n",
    "                          tf.assign(star_b3,end_b3)]\n",
    "                sess.run(update_star_wbs)\n",
    "            \n",
    "            best_step = [tf.assign(w_2,end_w2), tf.assign(b_2,end_b2),\n",
    "                     tf.assign(w_3,end_w3),tf.assign(b_3,end_b3)]\n",
    "            sess.run(best_step)\n",
    "            \n",
    "            first_params_set = [(start_w2, start_b2), (start_w3, start_b3)]\n",
    "            last_params_set = [(end_w2, end_b2), (end_w3, end_b3)]\n",
    "            \n",
    "            small_omegas = [(w2_grad_accum.eval(), b2_grad_accum.eval()), (w3_grad_accum.eval(),\n",
    "                           b3_grad_accum.eval())]\n",
    "            \n",
    "            delta_ws = map(lambda x,y: np.square(x-y)+zeta,[item[0] for item in last_params_set],\n",
    "                       [item[0] for item in first_params_set])\n",
    "            \n",
    "            delta_bs = map(lambda x,y: np.square(x-y)+zeta,[item[1] for item in last_params_set],\n",
    "                       [item[1] for item in first_params_set])\n",
    "            delta_wbs = zip(delta_ws, delta_bs)\n",
    "            \n",
    "            big_omegas_ws = map(lambda x,y: (x/y),[item[0] for item in small_omegas],\n",
    "                       [item[0] for item in delta_wbs])\n",
    "            \n",
    "            big_omegas_bs = map(lambda x,y: (x/y),[item[1] for item in small_omegas],\n",
    "                       [item[1] for item in delta_wbs])\n",
    "            \n",
    "            big_omegas = zip(big_omegas_ws, big_omegas_bs)\n",
    "            if(a_set != len(sets)-1):     \n",
    "                new_big_omeg_w2 += big_omegas[0][0]\n",
    "                new_big_omeg_b2 += big_omegas[0][1]\n",
    "                new_big_omeg_w3 += big_omegas[1][0]\n",
    "                new_big_omeg_b3 += big_omegas[1][1]\n",
    "            \n",
    "            for d in range(len(old_test_data)):\n",
    "                previous_set_name = 'set'+str(d)\n",
    "                prev_set = sets[d]\n",
    "                prev_mask_val = [0]*num_classes\n",
    "                for clas in range(prev_set[0], prev_set[1]+1):\n",
    "                    prev_mask_val[clas]=1\n",
    "                prev_set_mask_val = np.array(prev_mask_val, dtype=np.float32)\n",
    "                sess.run(iter.initializer, feed_dict={a_1: old_test_data[d][0], y: old_test_data[d][1],\n",
    "                                                  batch_size: len(old_test_data[d][0])})\n",
    "                _, _, hist_test_acc, _, _ = sess.run([predictions,acct_mat,acct_res, cost, a_3],\n",
    "                                                      feed_dict = {drop_out : 0.0,set1_mask:prev_set_mask_val})\n",
    "                \n",
    "                historical_cross_test_acc[current_set_name+'-'+previous_set_name].append(hist_test_acc)\n",
    "                print('Testing accuracy on :{} after training :{} is :{}'.format(previous_set_name,\n",
    "                                                                          current_set_name,\n",
    "                                                                          hist_test_acc))\n",
    "                historical_cross_test_acc[current_set_name+'-'+current_set_name]=[test_acc_corresp_best_val]\n",
    "            old_test_data.append(test_data_set)\n",
    "            print('MAXIMUM omegW2:{}, MEAN omegW2:{}'.format(new_big_omeg_w2.max(), new_big_omeg_w2.mean()))\n",
    "            print('MAXIMUM omegb2:{}, MEAN omegb2:{}'.format(new_big_omeg_b2.max(), new_big_omeg_b2.mean()))\n",
    "            print('MAXIMUM omegW3:{}, MEAN omegW3:{}'.format(new_big_omeg_w3.max(), new_big_omeg_w3.mean()))\n",
    "            print('MAXIMUM omegb3:{}, MEAN omegb3:{}'.format(new_big_omeg_b3.max(), new_big_omeg_b3.mean()))\n",
    "            #sys.exit()\n",
    "    historical_train_accuracies[current_set_name]=train_accuracies\n",
    "    historical_train_costs[current_set_name]=train_costs\n",
    "    historical_val_accuracies[current_set_name]=val_accuracies\n",
    "    historical_val_costs[current_set_name]=val_costs\n",
    "            \n",
    "            \n",
    "train_writer.close()\n",
    "#valid_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on set 0:(0, 1) after training set 4:(4, 5) is:74.0898370743\n",
      "Accuracy on set 1:(2, 3) after training set 4:(4, 5) is:46.2291866541\n",
      "Accuracy on set 2:(4, 5) after training set 4:(4, 5) is:98.1857001781\n",
      "Accuracy on set 3:(6, 7) after training set 4:(4, 5) is:99.2447137833\n",
      "Accuracy on set 4:(8, 9) after training set 4:(4, 5) is:97.0751404762\n",
      "Final accuracy on all sets:82.4700011832\n"
     ]
    }
   ],
   "source": [
    "set_accs = []\n",
    "for i in range(0,num_classes/2):\n",
    "    set_acc =  historical_cross_test_acc['set4-set'+str(i)][-1]*100\n",
    "    print('Accuracy on set {}:{} after training set {}:{} is:{}'.format(i, sets[i],\\\n",
    "                                    4, sets[2], set_acc))\n",
    "    set_accs.append(set_acc)\n",
    "n_test_samples = np.array(n_test_samples)\n",
    "final_acc = (n_test_samples*set_accs).sum()/n_test_samples.sum()\n",
    "print('Final accuracy on all sets:{}'.format(final_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 270x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(w_2.eval().flatten(), 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Omega_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 270x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(new_big_omeg_w2.flatten(),bins=100,log=True)\n",
    "#plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 270x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(b_2.eval().flatten(), 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Omega_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 270x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(new_big_omeg_b2.flatten(),100,log=True)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 270x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(w_3.eval().flatten(), 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Omega_w3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 270x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(new_big_omeg_w3.flatten(),100,log=True)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 270x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(b_3.eval().flatten(), 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Omega_b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 270x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(new_big_omeg_b3.flatten(),10)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "199.767px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `spikeflow` tool was written in mind with interpretability and ease of examining the spiking network's key internal variables. Convolution and Pooling was implemented using `Tensorflow` and most of the code was written using `NumPy`. Spike accumulation, thresholding and lateral inhibition can be implemented in a single graph of `Tensorflow` leaving STDP competition to be handled by `NumPy`. This is an extra notebook that shows how to code lateral inhibition in `Tensorflow`. This can replace the `NumPy` based lateral inhibition in `spikeflow`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from copy import deepcopy\n",
    "from tensorflow.python.client import timeline\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow' from '/home/ruthvik/.local/lib/python2.7/site-packages/tensorflow/__init__.pyc'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess= tf.InteractiveSession()\n",
    "run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "run_metadata = tf.RunMetadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hide code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    "if (code_show){\n",
    "$('div.input').hide();\n",
    "} else {\n",
    "$('div.input').show();\n",
    "}\n",
    "code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pots_list = []\n",
    "SpikesPerNeuronAllowed_list = []\n",
    "np_pots_list = []\n",
    "nofMaps = 100\n",
    "x_dim = 25\n",
    "y_dim = 25\n",
    "for i in range(10):\n",
    "    pots = np.random.rand(nofMaps,x_dim,y_dim)\n",
    "    pots_list.append(pots)\n",
    "    temp = np.random.choice([0, 1], size=(int(x_dim*y_dim),), p=[0.1, 0.9])\n",
    "    SpikesPerNeuronAllowed = temp.reshape(x_dim,y_dim)\n",
    "    SpikesPerNeuronAllowed_list.append(SpikesPerNeuronAllowed)\n",
    "    np_pots_list.append(tf.transpose(pots_list[i],perm=[1,2,0]).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lateral inhibition in Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-d5c680ea2427>:7: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "#with tf.name_scope('placeholders'):\n",
    "voltages = tf.placeholder(dtype=tf.float64,shape=(nofMaps,x_dim,y_dim), name='voltages')\n",
    "SpikesPerNeuronAllowed_tf = tf.placeholder(dtype=tf.int64,shape=(x_dim,y_dim), name='spk_allowed')\n",
    "\n",
    "#with tf.name_scope('thresholding'):\n",
    "thresholding = tf.where(tf.greater_equal(voltages,0.5), tf.ones(shape=(nofMaps,x_dim,y_dim),dtype=tf.int64), \n",
    "                        tf.zeros(shape=(nofMaps,x_dim,y_dim),dtype=tf.int64), name='thresh_op')\n",
    "    \n",
    "#with tf.name_scope('lateral_inhibition'):\n",
    "########## TO KILL THE NEURONS THAT ALREADY SPIKED IN PREVIOUS TIMESTEPS ###############(METHOD 2)\n",
    "suppress_prev_spikes = tf.multiply(thresholding,SpikesPerNeuronAllowed_tf,name='stg1_compt.')\n",
    "\n",
    "########## TO FILTER SPIKES THAT ARE ALOWED TO SPIKES IN THIS TSTEP AND HAVE SPIKED THE EARLIEST\n",
    "max_voltages = tf.reduce_max(voltages, axis=0,keepdims=True,name='max_val_at_xy_loc')\n",
    "condition = tf.equal(voltages, max_voltages,name='max_xy_loc_indices')\n",
    "first_spikes = tf.where(condition, tf.ones_like(voltages,dtype=tf.int64),\n",
    "                        tf.zeros_like(voltages,dtype=tf.int64),name='1st_spk_calc')\n",
    "allowed_first_spikes = tf.multiply(first_spikes,suppress_prev_spikes,name='stg2_compt.')\n",
    "\n",
    "#with tf.name_scope('update_spksperneuronallowed'):\n",
    "#############UPDATE THE SPIKESPERNEURONALLOWED TENSOR (METHOD1)#######\n",
    "new_SpikesPerNeuronAllowed_graph = tf.multiply(SpikesPerNeuronAllowed_tf,(1-tf.reduce_sum(allowed_first_spikes,\n",
    "                                        axis=0,keepdims=True)),name='updt_spk_allowed')\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op,options=run_options, run_metadata=run_metadata)\n",
    "#sess.run(init_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken:0.014673948288\n",
      "(566, 566, 0)\n",
      "time taken:0.00195503234863\n",
      "(581, 581, 0)\n",
      "time taken:0.00211906433105\n",
      "(569, 569, 0)\n",
      "time taken:0.0044641494751\n",
      "(567, 567, 0)\n",
      "time taken:0.00220990180969\n",
      "(574, 574, 0)\n",
      "time taken:0.00200581550598\n",
      "(562, 562, 0)\n",
      "time taken:0.00174689292908\n",
      "(566, 566, 0)\n",
      "time taken:0.00165414810181\n",
      "(564, 564, 0)\n",
      "time taken:0.00165510177612\n",
      "(561, 561, 0)\n",
      "time taken:0.00178003311157\n",
      "(556, 556, 0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    pots = pots_list[i]\n",
    "    #SpikesPerNeuronAllowed = deepcopy(SpikesPerNeuronAllowed_list[i])\n",
    "    SpikesPerNeuronAllowed = SpikesPerNeuronAllowed_list[i]\n",
    "    \n",
    "#https://stackoverflow.com/questions/38619107/accessing-intermediate-results-from-a-tensorflow-graph\n",
    "    t2 = time.time()\n",
    "    new_SpikesPerNeuronAllowed,final_spikes=sess.run([new_SpikesPerNeuronAllowed_graph,allowed_first_spikes], \n",
    "       feed_dict={SpikesPerNeuronAllowed_tf:SpikesPerNeuronAllowed,voltages:pots},options=run_options, \n",
    "                                          run_metadata=run_metadata)\n",
    "    #new_SpikesPerNeuronAllowed,final_spikes=sess.run([new_SpikesPerNeuronAllowed_graph,allowed_first_spikes], \n",
    "    #    feed_dict={SpikesPerNeuronAllowed_tf:SpikesPerNeuronAllowed,voltages:pots})\n",
    "    print('time taken:{}'.format(time.time()-t2))\n",
    "        \n",
    "    print(SpikesPerNeuronAllowed.sum(),final_spikes.sum(),new_SpikesPerNeuronAllowed.sum())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10        # Number of loops\n",
    "r = 512     # Number of repetitions of each loop\n",
    "p = 3        # Display precision\n",
    "t1 = %timeit -n 10 -r 512 -p 6 -o pass; func = sess.run([new_SpikesPerNeuronAllowed_graph,allowed_first_spikes],\\\n",
    "                                                        feed_dict={SpikesPerNeuronAllowed_tf:SpikesPerNeuronAllowed,voltages:pots},options=run_options,\\\n",
    "                                                        run_metadata=run_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean of {} run times:{}'.format(len(t1.all_runs),np.mean(t1.all_runs)/n))\n",
    "print('std of {} run times:{}'.format(len(t1.all_runs),np.std(t1.all_runs)/n))\n",
    "print('max of {} run times:{}'.format(len(t1.all_runs),np.max(t1.all_runs)/n))\n",
    "print('min of {} run times:{}'.format(len(t1.all_runs),np.min(t1.all_runs)/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the graph and data\n",
    "* To run the Tensorboard `cd` into the `path` and then execute ` python -m tensorboard.main --logdir=./`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/ruthvik/Desktop/Summer 2017/tf_graph_outputs/lateral_inh/'\n",
    "writer = tf.summary.FileWriter(path, sess.graph,flush_secs=1)\n",
    "writer.flush()\n",
    "\n",
    "tl = timeline.Timeline(run_metadata.step_stats)\n",
    "ctf = tl.generate_chrome_trace_format()\n",
    "with open(path+'/timeline.json', 'w') as f:\n",
    "    f.write(ctf)\n",
    "\n",
    "\n",
    "writer.add_run_metadata(run_metadata, 'mysess')\n",
    "writer.flush()\n",
    "writer.close()\n",
    "#sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy (Lateral Inhibition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lateral_inhibition(pots,conv_spikes,spiked_neurons,SpikesPerNeuronAllowed):\n",
    "        vbn = np.where(SpikesPerNeuronAllowed==0)\n",
    "        conv_spikes[vbn[0],vbn[1],:]=0 #if a neuron in a position has spiked b4 don't let it spike \n",
    "        high_volts=np.zeros(pots.shape)\n",
    "        idx = pots.argmax(axis=-1)\n",
    "        high_volts[np.arange(pots.shape[0])[:,None],np.arange(pots.shape[1]),idx] = 1\n",
    "        bvc = np.where(conv_spikes*high_volts==1)\n",
    "        conv_spikes[bvc[0],bvc[1],bvc[2]]=1 #aross layers, only neurons with high pot get to keep spikes\n",
    "        bvc1 = np.where(conv_spikes*high_volts!=1)\n",
    "        conv_spikes[bvc1[0],bvc1[1],bvc1[2]]=0 #all other neurons that spiked with low pots dont get to spike\n",
    "        spiked_neurons = np.where(conv_spikes==1)\n",
    "        SpikesPerNeuronAllowed[spiked_neurons[0],spiked_neurons[1]]=0\n",
    "\n",
    "        return conv_spikes, SpikesPerNeuronAllowed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Numpy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    pots = deepcopy(np_pots_list[i])\n",
    "    SpikesPerNeuronAllowed = deepcopy(SpikesPerNeuronAllowed_list[i])\n",
    "    t2 = time.time()\n",
    "    final_spikes, new_SpikesPerNeuronAllowed = lateral_inhibition(pots,pots>=0.5,np.where(pots>=0.5),\n",
    "                                                    SpikesPerNeuronAllowed)\n",
    "    print('time taken:{}'.format(time.time()-t2))\n",
    "    \n",
    "    print(SpikesPerNeuronAllowed_list[i].sum(),final_spikes.sum(),new_SpikesPerNeuronAllowed.sum())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

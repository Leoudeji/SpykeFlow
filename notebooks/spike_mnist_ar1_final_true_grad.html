<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>spike_mnist_ar1_final_true_grad</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.7.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.7.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff2?v=4.7.0') format('woff2'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.7.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.7.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.7.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.fa-pull-left {
  float: left;
}
.fa-pull-right {
  float: right;
}
.fa.fa-pull-left {
  margin-right: .3em;
}
.fa.fa-pull-right {
  margin-left: .3em;
}
/* Deprecated as of 4.4.0 */
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
.fa-pulse {
  -webkit-animation: fa-spin 1s infinite steps(8);
  animation: fa-spin 1s infinite steps(8);
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook-f:before,
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-feed:before,
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before,
.fa-gratipay:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper-pp:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-resistance:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-y-combinator-square:before,
.fa-yc-square:before,
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
.fa-buysellads:before {
  content: "\f20d";
}
.fa-connectdevelop:before {
  content: "\f20e";
}
.fa-dashcube:before {
  content: "\f210";
}
.fa-forumbee:before {
  content: "\f211";
}
.fa-leanpub:before {
  content: "\f212";
}
.fa-sellsy:before {
  content: "\f213";
}
.fa-shirtsinbulk:before {
  content: "\f214";
}
.fa-simplybuilt:before {
  content: "\f215";
}
.fa-skyatlas:before {
  content: "\f216";
}
.fa-cart-plus:before {
  content: "\f217";
}
.fa-cart-arrow-down:before {
  content: "\f218";
}
.fa-diamond:before {
  content: "\f219";
}
.fa-ship:before {
  content: "\f21a";
}
.fa-user-secret:before {
  content: "\f21b";
}
.fa-motorcycle:before {
  content: "\f21c";
}
.fa-street-view:before {
  content: "\f21d";
}
.fa-heartbeat:before {
  content: "\f21e";
}
.fa-venus:before {
  content: "\f221";
}
.fa-mars:before {
  content: "\f222";
}
.fa-mercury:before {
  content: "\f223";
}
.fa-intersex:before,
.fa-transgender:before {
  content: "\f224";
}
.fa-transgender-alt:before {
  content: "\f225";
}
.fa-venus-double:before {
  content: "\f226";
}
.fa-mars-double:before {
  content: "\f227";
}
.fa-venus-mars:before {
  content: "\f228";
}
.fa-mars-stroke:before {
  content: "\f229";
}
.fa-mars-stroke-v:before {
  content: "\f22a";
}
.fa-mars-stroke-h:before {
  content: "\f22b";
}
.fa-neuter:before {
  content: "\f22c";
}
.fa-genderless:before {
  content: "\f22d";
}
.fa-facebook-official:before {
  content: "\f230";
}
.fa-pinterest-p:before {
  content: "\f231";
}
.fa-whatsapp:before {
  content: "\f232";
}
.fa-server:before {
  content: "\f233";
}
.fa-user-plus:before {
  content: "\f234";
}
.fa-user-times:before {
  content: "\f235";
}
.fa-hotel:before,
.fa-bed:before {
  content: "\f236";
}
.fa-viacoin:before {
  content: "\f237";
}
.fa-train:before {
  content: "\f238";
}
.fa-subway:before {
  content: "\f239";
}
.fa-medium:before {
  content: "\f23a";
}
.fa-yc:before,
.fa-y-combinator:before {
  content: "\f23b";
}
.fa-optin-monster:before {
  content: "\f23c";
}
.fa-opencart:before {
  content: "\f23d";
}
.fa-expeditedssl:before {
  content: "\f23e";
}
.fa-battery-4:before,
.fa-battery:before,
.fa-battery-full:before {
  content: "\f240";
}
.fa-battery-3:before,
.fa-battery-three-quarters:before {
  content: "\f241";
}
.fa-battery-2:before,
.fa-battery-half:before {
  content: "\f242";
}
.fa-battery-1:before,
.fa-battery-quarter:before {
  content: "\f243";
}
.fa-battery-0:before,
.fa-battery-empty:before {
  content: "\f244";
}
.fa-mouse-pointer:before {
  content: "\f245";
}
.fa-i-cursor:before {
  content: "\f246";
}
.fa-object-group:before {
  content: "\f247";
}
.fa-object-ungroup:before {
  content: "\f248";
}
.fa-sticky-note:before {
  content: "\f249";
}
.fa-sticky-note-o:before {
  content: "\f24a";
}
.fa-cc-jcb:before {
  content: "\f24b";
}
.fa-cc-diners-club:before {
  content: "\f24c";
}
.fa-clone:before {
  content: "\f24d";
}
.fa-balance-scale:before {
  content: "\f24e";
}
.fa-hourglass-o:before {
  content: "\f250";
}
.fa-hourglass-1:before,
.fa-hourglass-start:before {
  content: "\f251";
}
.fa-hourglass-2:before,
.fa-hourglass-half:before {
  content: "\f252";
}
.fa-hourglass-3:before,
.fa-hourglass-end:before {
  content: "\f253";
}
.fa-hourglass:before {
  content: "\f254";
}
.fa-hand-grab-o:before,
.fa-hand-rock-o:before {
  content: "\f255";
}
.fa-hand-stop-o:before,
.fa-hand-paper-o:before {
  content: "\f256";
}
.fa-hand-scissors-o:before {
  content: "\f257";
}
.fa-hand-lizard-o:before {
  content: "\f258";
}
.fa-hand-spock-o:before {
  content: "\f259";
}
.fa-hand-pointer-o:before {
  content: "\f25a";
}
.fa-hand-peace-o:before {
  content: "\f25b";
}
.fa-trademark:before {
  content: "\f25c";
}
.fa-registered:before {
  content: "\f25d";
}
.fa-creative-commons:before {
  content: "\f25e";
}
.fa-gg:before {
  content: "\f260";
}
.fa-gg-circle:before {
  content: "\f261";
}
.fa-tripadvisor:before {
  content: "\f262";
}
.fa-odnoklassniki:before {
  content: "\f263";
}
.fa-odnoklassniki-square:before {
  content: "\f264";
}
.fa-get-pocket:before {
  content: "\f265";
}
.fa-wikipedia-w:before {
  content: "\f266";
}
.fa-safari:before {
  content: "\f267";
}
.fa-chrome:before {
  content: "\f268";
}
.fa-firefox:before {
  content: "\f269";
}
.fa-opera:before {
  content: "\f26a";
}
.fa-internet-explorer:before {
  content: "\f26b";
}
.fa-tv:before,
.fa-television:before {
  content: "\f26c";
}
.fa-contao:before {
  content: "\f26d";
}
.fa-500px:before {
  content: "\f26e";
}
.fa-amazon:before {
  content: "\f270";
}
.fa-calendar-plus-o:before {
  content: "\f271";
}
.fa-calendar-minus-o:before {
  content: "\f272";
}
.fa-calendar-times-o:before {
  content: "\f273";
}
.fa-calendar-check-o:before {
  content: "\f274";
}
.fa-industry:before {
  content: "\f275";
}
.fa-map-pin:before {
  content: "\f276";
}
.fa-map-signs:before {
  content: "\f277";
}
.fa-map-o:before {
  content: "\f278";
}
.fa-map:before {
  content: "\f279";
}
.fa-commenting:before {
  content: "\f27a";
}
.fa-commenting-o:before {
  content: "\f27b";
}
.fa-houzz:before {
  content: "\f27c";
}
.fa-vimeo:before {
  content: "\f27d";
}
.fa-black-tie:before {
  content: "\f27e";
}
.fa-fonticons:before {
  content: "\f280";
}
.fa-reddit-alien:before {
  content: "\f281";
}
.fa-edge:before {
  content: "\f282";
}
.fa-credit-card-alt:before {
  content: "\f283";
}
.fa-codiepie:before {
  content: "\f284";
}
.fa-modx:before {
  content: "\f285";
}
.fa-fort-awesome:before {
  content: "\f286";
}
.fa-usb:before {
  content: "\f287";
}
.fa-product-hunt:before {
  content: "\f288";
}
.fa-mixcloud:before {
  content: "\f289";
}
.fa-scribd:before {
  content: "\f28a";
}
.fa-pause-circle:before {
  content: "\f28b";
}
.fa-pause-circle-o:before {
  content: "\f28c";
}
.fa-stop-circle:before {
  content: "\f28d";
}
.fa-stop-circle-o:before {
  content: "\f28e";
}
.fa-shopping-bag:before {
  content: "\f290";
}
.fa-shopping-basket:before {
  content: "\f291";
}
.fa-hashtag:before {
  content: "\f292";
}
.fa-bluetooth:before {
  content: "\f293";
}
.fa-bluetooth-b:before {
  content: "\f294";
}
.fa-percent:before {
  content: "\f295";
}
.fa-gitlab:before {
  content: "\f296";
}
.fa-wpbeginner:before {
  content: "\f297";
}
.fa-wpforms:before {
  content: "\f298";
}
.fa-envira:before {
  content: "\f299";
}
.fa-universal-access:before {
  content: "\f29a";
}
.fa-wheelchair-alt:before {
  content: "\f29b";
}
.fa-question-circle-o:before {
  content: "\f29c";
}
.fa-blind:before {
  content: "\f29d";
}
.fa-audio-description:before {
  content: "\f29e";
}
.fa-volume-control-phone:before {
  content: "\f2a0";
}
.fa-braille:before {
  content: "\f2a1";
}
.fa-assistive-listening-systems:before {
  content: "\f2a2";
}
.fa-asl-interpreting:before,
.fa-american-sign-language-interpreting:before {
  content: "\f2a3";
}
.fa-deafness:before,
.fa-hard-of-hearing:before,
.fa-deaf:before {
  content: "\f2a4";
}
.fa-glide:before {
  content: "\f2a5";
}
.fa-glide-g:before {
  content: "\f2a6";
}
.fa-signing:before,
.fa-sign-language:before {
  content: "\f2a7";
}
.fa-low-vision:before {
  content: "\f2a8";
}
.fa-viadeo:before {
  content: "\f2a9";
}
.fa-viadeo-square:before {
  content: "\f2aa";
}
.fa-snapchat:before {
  content: "\f2ab";
}
.fa-snapchat-ghost:before {
  content: "\f2ac";
}
.fa-snapchat-square:before {
  content: "\f2ad";
}
.fa-pied-piper:before {
  content: "\f2ae";
}
.fa-first-order:before {
  content: "\f2b0";
}
.fa-yoast:before {
  content: "\f2b1";
}
.fa-themeisle:before {
  content: "\f2b2";
}
.fa-google-plus-circle:before,
.fa-google-plus-official:before {
  content: "\f2b3";
}
.fa-fa:before,
.fa-font-awesome:before {
  content: "\f2b4";
}
.fa-handshake-o:before {
  content: "\f2b5";
}
.fa-envelope-open:before {
  content: "\f2b6";
}
.fa-envelope-open-o:before {
  content: "\f2b7";
}
.fa-linode:before {
  content: "\f2b8";
}
.fa-address-book:before {
  content: "\f2b9";
}
.fa-address-book-o:before {
  content: "\f2ba";
}
.fa-vcard:before,
.fa-address-card:before {
  content: "\f2bb";
}
.fa-vcard-o:before,
.fa-address-card-o:before {
  content: "\f2bc";
}
.fa-user-circle:before {
  content: "\f2bd";
}
.fa-user-circle-o:before {
  content: "\f2be";
}
.fa-user-o:before {
  content: "\f2c0";
}
.fa-id-badge:before {
  content: "\f2c1";
}
.fa-drivers-license:before,
.fa-id-card:before {
  content: "\f2c2";
}
.fa-drivers-license-o:before,
.fa-id-card-o:before {
  content: "\f2c3";
}
.fa-quora:before {
  content: "\f2c4";
}
.fa-free-code-camp:before {
  content: "\f2c5";
}
.fa-telegram:before {
  content: "\f2c6";
}
.fa-thermometer-4:before,
.fa-thermometer:before,
.fa-thermometer-full:before {
  content: "\f2c7";
}
.fa-thermometer-3:before,
.fa-thermometer-three-quarters:before {
  content: "\f2c8";
}
.fa-thermometer-2:before,
.fa-thermometer-half:before {
  content: "\f2c9";
}
.fa-thermometer-1:before,
.fa-thermometer-quarter:before {
  content: "\f2ca";
}
.fa-thermometer-0:before,
.fa-thermometer-empty:before {
  content: "\f2cb";
}
.fa-shower:before {
  content: "\f2cc";
}
.fa-bathtub:before,
.fa-s15:before,
.fa-bath:before {
  content: "\f2cd";
}
.fa-podcast:before {
  content: "\f2ce";
}
.fa-window-maximize:before {
  content: "\f2d0";
}
.fa-window-minimize:before {
  content: "\f2d1";
}
.fa-window-restore:before {
  content: "\f2d2";
}
.fa-times-rectangle:before,
.fa-window-close:before {
  content: "\f2d3";
}
.fa-times-rectangle-o:before,
.fa-window-close-o:before {
  content: "\f2d4";
}
.fa-bandcamp:before {
  content: "\f2d5";
}
.fa-grav:before {
  content: "\f2d6";
}
.fa-etsy:before {
  content: "\f2d7";
}
.fa-imdb:before {
  content: "\f2d8";
}
.fa-ravelry:before {
  content: "\f2d9";
}
.fa-eercast:before {
  content: "\f2da";
}
.fa-microchip:before {
  content: "\f2db";
}
.fa-snowflake-o:before {
  content: "\f2dc";
}
.fa-superpowers:before {
  content: "\f2dd";
}
.fa-wpexplorer:before {
  content: "\f2de";
}
.fa-meetup:before {
  content: "\f2e0";
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
div.traceback-wrapper pre.traceback {
  max-height: 600px;
  overflow: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  padding: 5px;
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
[dir="rtl"] #ipython_notebook {
  margin-right: 10px;
  margin-left: 0;
}
[dir="rtl"] #ipython_notebook.pull-left {
  float: right !important;
  float: right;
}
.flex-spacer {
  flex: 1;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#kernel_logo_widget {
  margin: 0 10px;
}
span#login_widget {
  float: right;
}
[dir="rtl"] span#login_widget {
  float: left;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
.modal-header {
  cursor: move;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
[dir="rtl"] .center-nav form.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] .center-nav .navbar-text {
  float: right;
}
[dir="rtl"] .navbar-inner {
  text-align: right;
}
[dir="rtl"] div.text-left {
  text-align: right;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  position: absolute;
  display: block;
  width: 100%;
  height: 100%;
  overflow: hidden;
  cursor: pointer;
  opacity: 0;
  z-index: 2;
}
.alternate_upload .btn-xs > input.fileinput {
  margin: -1px -5px;
}
.alternate_upload .btn-upload {
  position: relative;
  height: 22px;
}
::-webkit-file-upload-button {
  cursor: pointer;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
[dir="rtl"] ul#tabs.nav-tabs > li {
  float: right;
}
[dir="rtl"] ul#tabs.nav.nav-tabs {
  padding-right: 0;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons .pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .list_toolbar .col-sm-4,
[dir="rtl"] .list_toolbar .col-sm-8 {
  float: right;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: text-bottom;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
[dir="rtl"] .list_item > div input {
  margin-right: 0;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_modified {
  margin-right: 7px;
  margin-left: 7px;
}
[dir="rtl"] .item_modified.pull-right {
  float: left !important;
  float: left;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
[dir="rtl"] .item_buttons.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .item_buttons .kernel-name {
  margin-left: 7px;
  float: right;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
.sort_button {
  display: inline-block;
  padding-left: 7px;
}
[dir="rtl"] .sort_button.pull-right {
  float: left !important;
  float: left;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
[dir="rtl"] #button-select-all.btn {
  float: right ;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
  margin-top: 2px;
  height: 16px;
}
[dir="rtl"] #select-all.pull-left {
  float: right !important;
  float: right;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.fa-pull-left {
  margin-right: .3em;
}
.folder_icon:before.fa-pull-right {
  margin-left: .3em;
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.fa-pull-left {
  margin-right: .3em;
}
.file_icon:before.fa-pull-right {
  margin-left: .3em;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
#new-menu .dropdown-header {
  font-size: 10px;
  border-bottom: 1px solid #e5e5e5;
  padding: 0 0 3px;
  margin: -3px 20px 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.move-button {
  display: none;
}
.download-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
.CodeMirror-dialog {
  background-color: #fff;
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered .rendered_html td {
  max-width: none;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
.jupyter-keybindings {
  padding: 1px;
  line-height: 24px;
  border-bottom: 1px solid gray;
}
.jupyter-keybindings input {
  margin: 0;
  padding: 0;
  border: none;
}
.jupyter-keybindings i {
  padding: 6px;
}
.well code {
  background-color: #ffffff;
  border-color: #ababab;
  border-width: 1px;
  border-style: solid;
  padding: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.tags_button_container {
  width: 100%;
  display: flex;
}
.tag-container {
  display: flex;
  flex-direction: row;
  flex-grow: 1;
  overflow: hidden;
  position: relative;
}
.tag-container > * {
  margin: 0 4px;
}
.remove-tag-btn {
  margin-left: 4px;
}
.tags-input {
  display: flex;
}
.cell-tag:last-child:after {
  content: "";
  position: absolute;
  right: 0;
  width: 40px;
  height: 100%;
  /* Fade to background color of cell toolbar */
  background: linear-gradient(to right, rgba(0, 0, 0, 0), #EEE);
}
.tags-input > * {
  margin-left: 4px;
}
.cell-tag,
.tags-input input,
.tags-input button {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  box-shadow: none;
  width: inherit;
  font-size: inherit;
  height: 22px;
  line-height: 22px;
  padding: 0px 4px;
  display: inline-block;
}
.cell-tag:focus,
.tags-input input:focus,
.tags-input button:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.cell-tag::-moz-placeholder,
.tags-input input::-moz-placeholder,
.tags-input button::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.cell-tag:-ms-input-placeholder,
.tags-input input:-ms-input-placeholder,
.tags-input button:-ms-input-placeholder {
  color: #999;
}
.cell-tag::-webkit-input-placeholder,
.tags-input input::-webkit-input-placeholder,
.tags-input button::-webkit-input-placeholder {
  color: #999;
}
.cell-tag::-ms-expand,
.tags-input input::-ms-expand,
.tags-input button::-ms-expand {
  border: 0;
  background-color: transparent;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
.cell-tag[readonly],
.tags-input input[readonly],
.tags-input button[readonly],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  background-color: #eeeeee;
  opacity: 1;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  cursor: not-allowed;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button {
  height: auto;
}
select.cell-tag,
select.tags-input input,
select.tags-input button {
  height: 30px;
  line-height: 30px;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button,
select[multiple].cell-tag,
select[multiple].tags-input input,
select[multiple].tags-input button {
  height: auto;
}
.cell-tag,
.tags-input button {
  padding: 0px 4px;
}
.cell-tag {
  background-color: #fff;
  white-space: nowrap;
}
.tags-input input[type=text]:focus {
  outline: none;
  box-shadow: none;
  border-color: #ccc;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
[dir="rtl"] #kernel_logo_widget {
  float: left !important;
  float: left;
}
.modal .modal-body .move-path {
  display: flex;
  flex-direction: row;
  justify-content: space;
  align-items: center;
}
.modal .modal-body .move-path .server-root {
  padding-right: 20px;
}
.modal .modal-body .move-path .path-input {
  flex: 1;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
[dir="rtl"] #menubar .navbar-toggle {
  float: right;
}
[dir="rtl"] #menubar .navbar-collapse {
  clear: right;
}
[dir="rtl"] #menubar .navbar-nav {
  float: right;
}
[dir="rtl"] #menubar .nav {
  padding-right: 0px;
}
[dir="rtl"] #menubar .navbar-nav > li {
  float: right;
}
[dir="rtl"] #menubar .navbar-right {
  float: left !important;
}
[dir="rtl"] ul.dropdown-menu {
  text-align: right;
  left: auto;
}
[dir="rtl"] ul#new-menu.dropdown-menu {
  right: auto;
  left: 0;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
[dir="rtl"] i.menu-icon.pull-right {
  float: left !important;
  float: left;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
[dir="rtl"] ul#help_menu li a {
  padding-left: 2.2em;
}
[dir="rtl"] ul#help_menu li a i {
  margin-right: 0;
  margin-left: -1.2em;
}
[dir="rtl"] ul#help_menu li a i.pull-right {
  float: left !important;
  float: left;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
[dir="rtl"] .dropdown-submenu > .dropdown-menu {
  right: 100%;
  margin-right: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.fa-pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.fa-pull-right {
  margin-left: .3em;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
[dir="rtl"] .dropdown-submenu > a:after {
  float: left;
  content: "\f0d9";
  margin-right: 0;
  margin-left: -10px;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
[dir="rtl"] #notification_area {
  float: left !important;
  float: left;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] .indicator_area {
  float: left !important;
  float: left;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
[dir="rtl"] #kernel_indicator {
  float: left !important;
  float: left;
  border-left: 0;
  border-right: 1px solid;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] #modal_indicator {
  float: left !important;
  float: left;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  height: 30px;
  margin-top: 4px;
  display: flex;
  justify-content: flex-start;
  align-items: baseline;
  width: 50%;
  flex: 1;
}
span.save_widget span.filename {
  height: 100%;
  line-height: 1em;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
[dir="rtl"] span.save_widget.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] span.save_widget span.filename {
  margin-left: 0;
  margin-right: 16px;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
  white-space: nowrap;
  padding: 0 5px;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
    padding: 0 0 0 5px;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
.toolbar-btn-label {
  margin-left: 6px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
[dir="rtl"] .btn-group > .btn,
.btn-group-vertical > .btn {
  float: right;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
[dir="rtl"] ul.typeahead-list i {
  margin-left: 0;
  margin-right: -10px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
ul.typeahead-list  > li > a.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .typeahead-list {
  text-align: right;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  min-width: 20px;
  color: transparent;
}
[dir="rtl"] .no-shortcut.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .command-shortcut.pull-right {
  float: left !important;
  float: left;
}
.command-shortcut:before {
  content: "(command mode)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
[dir="rtl"] .edit-shortcut.pull-right {
  float: left !important;
  float: left;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
  border-left: none;
}
[dir="rtl"] #find-and-replace .input-group-btn + .form-control {
  border-right: none;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>

 <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/jquery-ui.css">

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.9.1/jquery-ui.min.js"></script>

<link rel="stylesheet" type="text/css" href="https://rawgit.com/ipython-contrib/jupyter_contrib_nbextensions/master/src/jupyter_contrib_nbextensions/nbextensions/toc2/main.css">

<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<script src="https://rawgit.com/ipython-contrib/jupyter_contrib_nbextensions/master/src/jupyter_contrib_nbextensions/nbextensions/toc2/toc2.js"></script>

<script>
$( document ).ready(function(){

            var cfg = {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": false, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {"height": "calc(100% - 180px)", "left": "10px", "top": "150px", "width": "428.8px"}, "toc_section_display": true, "toc_window_display": true};

            // fire the main function with these parameters
            require(['nbextensions/toc2/toc2'], function (toc2) {
                toc2.table_of_contents(cfg);
            });
    });
</script>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Notes">Notes<a class="anchor-link" href="#Notes">&#182;</a></h1><ul>
<li><p>This notebook has implementations of <code>Backprop</code> with binary spike feature vectors obtained from the <code>SPIKEFLOW</code>. Here, we will use tf.data API. Here the shape of the inputs is <code>[None, n_input]</code> instead of <code>[n_input, None]</code>. We had to do this because nested elements in <code>from_tensor_slices</code> must have the same dimension in 0th rank <a href="https://stackoverflow.com/questions/49579684/what-is-the-difference-between-dataset-from-tensors-and-dataset-from-tensor-slic">see</a>. Everytime an iterator <code>iter = dataset.make_initializable_iterator()</code> gets initialized, the dataset is randomly shuffled so we need not shuffle again, <a href="https://stackoverflow.com/questions/49579684/what-is-the-difference-between-dataset-from-tensors-and-dataset-from-tensor-slic">see</a>. We also use <code>z_3 = tf.floor(z_3)</code>. Surrogate gradients with one step is used. (one sided)</p>
</li>
<li><p>Here, error in the hidden layer, $\delta^{2}$ is implemented as:
$ \delta^{2} = W^{3T}\delta^{(3)}\odot\sigma^{'}(z^{(2)}) \tag{1}$</p>
</li>
<li>$\sigma^{'}(z^{(2)})$ is approximated with a surrogate. (See section 6)</li>
<li>It also takes care of catastrophic forgetting by using synaptic intelligence.</li>
<li>He initialization without AR1 gives lesser final accuracy than Trunc init because in He the gradients don't suffer from dimnishing.
## References</li>
<li><a href="http://neuralnetworksanddeeplearning.com/chap3.html">Neural Nets</a></li>
<li><a href="https://github.com/xuexue/randombp/blob/master/randombp.py">Randombackprop</a></li>
<li><a href="https://github.com/sangyi92/feedback_alignment/blob/master/RFA.ipynb">Randombackprop</a></li>
<li><a href="http://blog.aloni.org/posts/backprop-with-tensorflow/">Backprop</a></li>
<li><a href="https://towardsdatascience.com/hyper-parameters-in-action-part-ii-weight-initializers-35aee1a28404">Initializers</a></li>
<li><a href="https://github.com/pinae/TensorFlow-MNIST-example/blob/master/fully-connected.py">Dropout</a></li>
<li><a href="https://stackoverflow.com/questions/34240703/what-is-logits-softmax-and-softmax-cross-entropy-with-logits">Softmax</a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits">SoftmaxLogits</a></li>
<li><a href="https://github.com/tensorflow/tensorflow/issues/4151">TF memory leaks when  assigning in loop</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">time</span>
<span class="c1">#os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;]=&quot;-1&quot;</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="kn">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>
<span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v2</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow.examples.tutorials.mnist</span> <span class="kn">import</span> <span class="n">input_data</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.client</span> <span class="kn">import</span> <span class="n">timeline</span>
<span class="kn">import</span> <span class="nn">h5py</span><span class="o">,</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">keras.utils.np_utils</span> <span class="kn">import</span> <span class="n">to_categorical</span> 
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">DATA_Loader</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sb</span>
<span class="kn">import</span> <span class="nn">theano</span><span class="o">,</span> <span class="nn">random</span><span class="o">,</span> <span class="nn">sys</span><span class="o">,</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">shuffle</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;TF_CPP_MIN_LOG_LEVEL&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;3&#39;</span>
<span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="n">tf</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>1.14.0
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[2]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;module &#39;tensorflow&#39; from &#39;/home/ruthvik/.local/lib/python2.7/site-packages/tensorflow/__init__.pyc&#39;&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Hide-code">Hide code<a class="anchor-link" href="#Hide-code">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">HTML</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;&lt;script&gt;</span>
<span class="s1">code_show=true; </span>
<span class="s1">function code_toggle() {</span>
<span class="s1">if (code_show){</span>
<span class="s1">$(&#39;div.input&#39;).hide();</span>
<span class="s1">} else {</span>
<span class="s1">$(&#39;div.input&#39;).show();</span>
<span class="s1">}</span>
<span class="s1">code_show = !code_show</span>
<span class="s1">} </span>
<span class="s1">$( document ).ready(code_toggle);</span>
<span class="s1">&lt;/script&gt;</span>
<span class="s1">&lt;form action=&quot;javascript:code_toggle()&quot;&gt;&lt;input type=&quot;submit&quot; value=&quot;Click here to toggle on/off the raw code.&quot;&gt;&lt;/form&gt;&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[5]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<script>
code_show=true; 
function code_toggle() {
if (code_show){
$('div.input').hide();
} else {
$('div.input').show();
}
code_show = !code_show
} 
$( document ).ready(code_toggle);
</script>
<form action="javascript:code_toggle()"><input type="submit" value="Click here to toggle on/off the raw code."></form>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Plots">Plots<a class="anchor-link" href="#Plots">&#182;</a></h1><ul>
<li>FOR PRETTY IEEE PLOTS mpl.rcParams['figure.figsize'] = 4.5,2.5, all fonts 9-12</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Large">Large<a class="anchor-link" href="#Large">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span><span class="mi">10</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.titlesize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">24</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">25</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.linewidth&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.markersize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;xtick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;ytick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">22</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;legend.fontsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">25</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">22</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Small">Small<a class="anchor-link" href="#Small">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">4.5</span><span class="p">,</span><span class="mf">2.75</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.titlesize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.linewidth&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.markersize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;xtick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">13</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;ytick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;legend.fontsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Effect-of-$\lambda$s">Effect of $\lambda$s<a class="anchor-link" href="#Effect-of-$\lambda$s">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">prev_final_test_acc1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;spike_sh_14lmbdas_ar1_3lyrs_he1_75_10_non_spk_classify.csv&#39;</span><span class="p">,</span> 
                                  <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">prev_acc_grouped_by_lmbda1</span> <span class="o">=</span> <span class="n">prev_final_test_acc1</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;lambdas&#39;</span><span class="p">)</span>
<span class="n">prev_final_acc_grouped_by_lmbda1</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda1</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Method3&#39;</span><span class="p">:</span><span class="s1">&#39;Mean&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">prev_final_acc_grouped_by_lmbda1</span><span class="p">[</span><span class="s1">&#39;S.D&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda1</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda1</span><span class="p">[</span><span class="s1">&#39;Min&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda1</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda1</span><span class="p">[</span><span class="s1">&#39;Max&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda1</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda1</span><span class="p">[</span><span class="s1">&#39;MED&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda1</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda1</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1">#display(prev_final_acc_grouped_by_lmbda1)</span>
<span class="n">prev_final_test_acc2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;spike_sh_14lmbdas_ar1_3lyrs_he1_10_20_non_spk_classify.csv&#39;</span><span class="p">,</span> 
                                  <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">prev_acc_grouped_by_lmbda2</span> <span class="o">=</span> <span class="n">prev_final_test_acc2</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;lambdas&#39;</span><span class="p">)</span>
<span class="n">prev_final_acc_grouped_by_lmbda2</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda2</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda2</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Method3&#39;</span><span class="p">:</span><span class="s1">&#39;Mean&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">prev_final_acc_grouped_by_lmbda2</span><span class="p">[</span><span class="s1">&#39;S.D&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda2</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda2</span><span class="p">[</span><span class="s1">&#39;Min&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda2</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda2</span><span class="p">[</span><span class="s1">&#39;Max&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda2</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda2</span><span class="p">[</span><span class="s1">&#39;MED&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda2</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda2</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1">#display(prev_final_acc_grouped_by_lmbda2)</span>
<span class="n">prev_final_test_acc3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;spike_sh_14lmbdas_ar1_3lyrs_he1_20_45_non_spk_classify.csv&#39;</span><span class="p">,</span> 
                                  <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">prev_acc_grouped_by_lmbda3</span> <span class="o">=</span> <span class="n">prev_final_test_acc3</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;lambdas&#39;</span><span class="p">)</span>
<span class="n">prev_final_acc_grouped_by_lmbda3</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda3</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda3</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Method3&#39;</span><span class="p">:</span><span class="s1">&#39;Mean&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">prev_final_acc_grouped_by_lmbda3</span><span class="p">[</span><span class="s1">&#39;S.D&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda3</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda3</span><span class="p">[</span><span class="s1">&#39;Min&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda3</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda3</span><span class="p">[</span><span class="s1">&#39;Max&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda3</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda3</span><span class="p">[</span><span class="s1">&#39;MED&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda3</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda3</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1">#display(prev_final_acc_grouped_by_lmbda3)</span>
<span class="n">prev_final_test_acc4</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;spike_sh_14lmbdas_ar1_3lyrs_he1_45_65_non_spk_classify.csv&#39;</span><span class="p">,</span> 
                                  <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">prev_acc_grouped_by_lmbda4</span> <span class="o">=</span> <span class="n">prev_final_test_acc4</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;lambdas&#39;</span><span class="p">)</span>
<span class="n">prev_final_acc_grouped_by_lmbda4</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda4</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda4</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Method3&#39;</span><span class="p">:</span><span class="s1">&#39;Mean&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">prev_final_acc_grouped_by_lmbda4</span><span class="p">[</span><span class="s1">&#39;S.D&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda4</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda4</span><span class="p">[</span><span class="s1">&#39;Min&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda4</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda4</span><span class="p">[</span><span class="s1">&#39;Max&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda4</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda4</span><span class="p">[</span><span class="s1">&#39;MED&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_acc_grouped_by_lmbda4</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>
<span class="n">prev_final_acc_grouped_by_lmbda4</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1">#display(prev_final_acc_grouped_by_lmbda4)</span>
<span class="n">df4</span> <span class="o">=</span> <span class="n">prev_final_acc_grouped_by_lmbda4</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1">#df4.drop([0], inplace=True)</span>

<span class="n">df3</span> <span class="o">=</span> <span class="n">prev_final_acc_grouped_by_lmbda3</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1">#df3.drop([0], inplace=True)</span>

<span class="n">df2</span> <span class="o">=</span> <span class="n">prev_final_acc_grouped_by_lmbda2</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df2</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">df1</span> <span class="o">=</span> <span class="n">prev_final_acc_grouped_by_lmbda1</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1">#df1.drop([0], inplace=True)</span>

<span class="n">final_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df1</span><span class="p">,</span> <span class="n">df2</span><span class="p">,</span> <span class="n">df3</span><span class="p">,</span> <span class="n">df4</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">final_df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">final_df</span><span class="p">[</span><span class="s1">&#39;lambdas&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">final_df</span><span class="p">[</span><span class="s1">&#39;lambdas&#39;</span><span class="p">]</span><span class="o">*</span><span class="mi">30</span> <span class="c1">##saved wrongly scaled lambdas, so re-scale them</span>
<span class="c1">#display(final_df)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">4.75</span><span class="p">,</span><span class="mf">3.0</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.linewidth&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.markersize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;xtick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">13</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;ytick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;legend.fontsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">ax</span><span class="o">=</span><span class="n">final_df</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Mean&#39;</span><span class="p">,</span><span class="s1">&#39;Max&#39;</span><span class="p">,</span> <span class="s1">&#39;Min&#39;</span><span class="p">],</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;lambdas&#39;</span><span class="p">)</span>
<span class="c1">#ax=final_df.plot(y=[&#39;Mean&#39;],x=&#39;lambdas&#39;)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">b</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$\lambda$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ticklabel_format</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">&#39;sci&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">scilimits</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;../outputs/tg_mnist_results_cl/lambda_vs_acc2.pdf&#39;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;../outputs/tg_mnist_results_cl/lambda_vs_acc2.png&#39;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;../outputs/tg_mnist_results_cl/lambda_vs_acc2.eps&#39;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Load-data">Load data<a class="anchor-link" href="#Load-data">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;../../spiking_networks/train_pool1_spike_features_inh_False_conv1maps_30.h5&#39;</span>
<span class="k">with</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">hf</span><span class="p">:</span>
    <span class="n">emnist_train_images</span> <span class="o">=</span> <span class="n">hf</span><span class="p">[</span><span class="s1">&#39;pool1_spike_features&#39;</span><span class="p">][:]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1">#@@emnist_train_images[np.where(emnist_train_images&gt;=1)] = 1</span>

<span class="n">filehandle</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;../../spiking_networks/train_y.pkl&#39;</span><span class="p">,</span><span class="s1">&#39;rb&#39;</span><span class="p">)</span>
<span class="n">emnist_train_labels</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filehandle</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">filehandle</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">emnist_train_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">emnist_train_labels</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Total train features:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">emnist_train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

<span class="c1">#### LOAD TEST IMAGES AND LABELS</span>
<span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;../../spiking_networks/test_pool1_spike_features_inh_False_conv1maps_30.h5&#39;</span>
<span class="k">with</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">hf</span><span class="p">:</span>
    <span class="n">emnist_test_images</span> <span class="o">=</span> <span class="n">hf</span><span class="p">[</span><span class="s1">&#39;pool1_spike_features&#39;</span><span class="p">][:]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1">#@@emnist_test_images[np.where(emnist_test_images&gt;=1)] = 1</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Total test features:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">emnist_test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

<span class="n">filehandle</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;../../spiking_networks/test_y.pkl&#39;</span><span class="p">,</span><span class="s1">&#39;rb&#39;</span><span class="p">)</span>
<span class="n">emnist_test_labels</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filehandle</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">filehandle</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">emnist_test_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">emnist_test_labels</span><span class="p">)</span>

<span class="c1">#### LOAD TRAIN AND VALIDATION DATA AND LABELS</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">emnist_train_images</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">emnist_train_labels</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">emnist_test_images</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">emnist_test_labels</span>
<span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Total train features:60000
Total test features:10000
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">labels_map</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="s1">&#39;0&#39;</span><span class="p">,</span><span class="mi">1</span><span class="p">:</span><span class="s1">&#39;1&#39;</span><span class="p">,</span><span class="mi">2</span><span class="p">:</span><span class="s1">&#39;2&#39;</span><span class="p">,</span><span class="mi">3</span><span class="p">:</span><span class="s1">&#39;3&#39;</span><span class="p">,</span><span class="mi">4</span><span class="p">:</span><span class="s1">&#39;4&#39;</span><span class="p">,</span><span class="mi">5</span><span class="p">:</span><span class="s1">&#39;5&#39;</span><span class="p">,</span><span class="mi">6</span><span class="p">:</span><span class="s1">&#39;6&#39;</span><span class="p">,</span><span class="mi">7</span><span class="p">:</span><span class="s1">&#39;7&#39;</span><span class="p">,</span><span class="mi">8</span><span class="p">:</span><span class="s1">&#39;8&#39;</span><span class="p">,</span><span class="mi">9</span><span class="p">:</span><span class="s1">&#39;9&#39;</span><span class="p">,</span><span class="mi">10</span><span class="p">:</span><span class="s1">&#39;A&#39;</span><span class="p">,</span><span class="mi">11</span><span class="p">:</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="mi">12</span><span class="p">:</span><span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="mi">13</span><span class="p">:</span><span class="s1">&#39;D&#39;</span><span class="p">,</span><span class="mi">14</span><span class="p">:</span><span class="s1">&#39;E&#39;</span><span class="p">,</span><span class="mi">15</span><span class="p">:</span><span class="s1">&#39;F&#39;</span><span class="p">,</span>
              <span class="mi">16</span><span class="p">:</span><span class="s1">&#39;G&#39;</span><span class="p">,</span><span class="mi">17</span><span class="p">:</span><span class="s1">&#39;H&#39;</span><span class="p">,</span><span class="mi">18</span><span class="p">:</span><span class="s1">&#39;I&#39;</span><span class="p">,</span><span class="mi">19</span><span class="p">:</span><span class="s1">&#39;J&#39;</span><span class="p">,</span><span class="mi">20</span><span class="p">:</span><span class="s1">&#39;K&#39;</span><span class="p">,</span><span class="mi">21</span><span class="p">:</span><span class="s1">&#39;L&#39;</span><span class="p">,</span><span class="mi">22</span><span class="p">:</span><span class="s1">&#39;M&#39;</span><span class="p">,</span><span class="mi">23</span><span class="p">:</span><span class="s1">&#39;N&#39;</span><span class="p">,</span><span class="mi">24</span><span class="p">:</span><span class="s1">&#39;O&#39;</span><span class="p">,</span><span class="mi">25</span><span class="p">:</span><span class="s1">&#39;P&#39;</span><span class="p">,</span><span class="mi">26</span><span class="p">:</span><span class="s1">&#39;Q&#39;</span><span class="p">,</span><span class="mi">27</span><span class="p">:</span><span class="s1">&#39;R&#39;</span><span class="p">,</span><span class="mi">28</span><span class="p">:</span><span class="s1">&#39;S&#39;</span><span class="p">,</span><span class="mi">29</span><span class="p">:</span><span class="s1">&#39;T&#39;</span><span class="p">,</span><span class="mi">30</span><span class="p">:</span><span class="s1">&#39;U&#39;</span><span class="p">,</span>
             <span class="mi">31</span><span class="p">:</span><span class="s1">&#39;V&#39;</span><span class="p">,</span><span class="mi">32</span><span class="p">:</span><span class="s1">&#39;W&#39;</span><span class="p">,</span><span class="mi">33</span><span class="p">:</span><span class="s1">&#39;X&#39;</span><span class="p">,</span><span class="mi">34</span><span class="p">:</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span><span class="mi">35</span><span class="p">:</span><span class="s1">&#39;Z&#39;</span><span class="p">,</span><span class="mi">36</span><span class="p">:</span><span class="s1">&#39;a&#39;</span><span class="p">,</span><span class="mi">37</span><span class="p">:</span><span class="s1">&#39;b&#39;</span><span class="p">,</span><span class="mi">38</span><span class="p">:</span><span class="s1">&#39;d&#39;</span><span class="p">,</span><span class="mi">39</span><span class="p">:</span><span class="s1">&#39;e&#39;</span><span class="p">,</span><span class="mi">40</span><span class="p">:</span><span class="s1">&#39;f&#39;</span><span class="p">,</span><span class="mi">41</span><span class="p">:</span><span class="s1">&#39;g&#39;</span><span class="p">,</span><span class="mi">42</span><span class="p">:</span><span class="s1">&#39;h&#39;</span><span class="p">,</span><span class="mi">43</span><span class="p">:</span><span class="s1">&#39;n&#39;</span><span class="p">,</span><span class="mi">44</span><span class="p">:</span><span class="s1">&#39;q&#39;</span><span class="p">,</span><span class="mi">45</span><span class="p">:</span><span class="s1">&#39;r&#39;</span><span class="p">,</span>
             <span class="mi">46</span><span class="p">:</span><span class="s1">&#39;t&#39;</span><span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1">#### EXTRACT REQUIRED LOCATIONS OF 0 TO 5 FOR TRAIN DATA</span>
<span class="k">def</span> <span class="nf">extract_class_data</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">set1_locs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">train_labels</span><span class="o">&gt;=</span><span class="n">start</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">train_labels</span><span class="o">&lt;=</span><span class="n">stop</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">train_labels_set1</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">train_labels</span><span class="p">[</span><span class="n">set1_locs</span><span class="p">],</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>
    <span class="n">train_images_set1</span> <span class="o">=</span> <span class="n">train_images</span><span class="p">[</span><span class="n">set1_locs</span><span class="p">,:]</span>
    <span class="n">n_images</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_images_set1</span><span class="p">)</span>

    <span class="c1">#### EXTRACT REQUIRED LOCATIONS OF 0 TO 5 FOR TEST DATA</span>
    <span class="n">set1_locs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">test_labels</span><span class="o">&gt;=</span><span class="n">start</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">test_labels</span><span class="o">&lt;=</span><span class="n">stop</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">test_labels_set1</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">test_labels</span><span class="p">[</span><span class="n">set1_locs</span><span class="p">],</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>
    <span class="n">test_images_set1</span> <span class="o">=</span> <span class="n">test_images</span><span class="p">[</span><span class="n">set1_locs</span><span class="p">,:]</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Test features:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_images_set1</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Length of test labels:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_labels_set1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">test_data_set1</span> <span class="o">=</span> <span class="p">(</span><span class="n">test_images_set1</span><span class="p">,</span> <span class="n">test_labels_set1</span><span class="p">)</span>
    


    <span class="n">train_images_set1</span> <span class="o">=</span> <span class="n">train_images_set1</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.09</span><span class="o">*</span><span class="n">n_images</span><span class="p">):]</span>
    <span class="n">train_labels_set1</span> <span class="o">=</span> <span class="n">train_labels_set1</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.09</span><span class="o">*</span><span class="n">n_images</span><span class="p">):]</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Train features:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_images_set1</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Length of train labels:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_labels_set1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">train_data_set1</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_images_set1</span><span class="p">,</span> <span class="n">train_labels_set1</span><span class="p">)</span>

    <span class="n">valid_labels_set1</span> <span class="o">=</span> <span class="n">train_labels_set1</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.09</span><span class="o">*</span><span class="n">n_images</span><span class="p">)]</span>
    <span class="n">valid_images_set1</span> <span class="o">=</span> <span class="n">train_images_set1</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.09</span><span class="o">*</span><span class="n">n_images</span><span class="p">)]</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Valid features:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">valid_images_set1</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Length of valid labels:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">valid_labels_set1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">valid_data_set1</span> <span class="o">=</span> <span class="p">(</span><span class="n">valid_images_set1</span><span class="p">,</span> <span class="n">valid_labels_set1</span><span class="p">)</span>
    
    <span class="n">n_train_set1</span> <span class="o">=</span> <span class="n">train_labels_set1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n_test_set1</span> <span class="o">=</span> <span class="n">test_labels_set1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n_valid_set1</span> <span class="o">=</span> <span class="n">valid_labels_set1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">train_data_set1</span><span class="p">,</span> <span class="n">valid_data_set1</span><span class="p">,</span> <span class="n">test_data_set1</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Start-a-session">Start a session<a class="anchor-link" href="#Start-a-session">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">()</span>
<span class="n">config</span><span class="o">.</span><span class="n">gpu_options</span><span class="o">.</span><span class="n">allow_growth</span><span class="o">=</span><span class="bp">True</span>
<span class="n">sess</span><span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">InteractiveSession</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
<span class="n">run_options</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RunOptions</span><span class="p">(</span><span class="n">trace_level</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">RunOptions</span><span class="o">.</span><span class="n">FULL_TRACE</span><span class="p">)</span>
<span class="n">run_metadata</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RunMetadata</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Setup-the-network">Setup the network<a class="anchor-link" href="#Setup-the-network">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">n_input</span> <span class="o">=</span> <span class="mi">3630</span>
<span class="n">n_middle</span> <span class="o">=</span> <span class="mi">1500</span>
<span class="n">n_out</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;batch_size&#39;</span><span class="p">)</span> 
<span class="n">gradient_gate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;gradient_gate&#39;</span><span class="p">)</span> 
<span class="n">a_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_input</span><span class="p">],</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;Input_batch&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_out</span><span class="p">],</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;output_batch&#39;</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">a_1</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="c1">#dataset = dataset.shuffle(buffer_size=len(all_train_labels), reshuffle_each_iteration=True)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
<span class="nb">iter</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">make_initializable_iterator</span><span class="p">()</span>
<span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">iter</span><span class="o">.</span><span class="n">get_next</span><span class="p">()</span>

<span class="n">drop_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">tau</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">set1_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;mask&#39;</span><span class="p">)</span>
<span class="n">eta</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">n_tot</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">lmbda</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;lambda&#39;</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;hid_lyr_w_b&#39;</span><span class="p">):</span>  <span class="c1">###havier or glorot initialization</span>
    <span class="n">low</span> <span class="o">=</span> <span class="o">-</span><span class="mi">4</span><span class="o">*</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">6.0</span><span class="o">/</span><span class="p">(</span><span class="n">n_input</span> <span class="o">+</span> <span class="n">n_middle</span><span class="p">))</span> <span class="c1"># use 4 for sigmoid, 1 for tanh activation </span>
    <span class="n">high</span> <span class="o">=</span> <span class="mi">4</span><span class="o">*</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">6.0</span><span class="o">/</span><span class="p">(</span><span class="n">n_input</span> <span class="o">+</span> <span class="n">n_middle</span><span class="p">))</span>
    
    <span class="n">low</span> <span class="o">=</span> <span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="o">/</span><span class="p">(</span><span class="n">n_input</span><span class="p">))</span> <span class="c1"># use 4 for sigmoid, 1 for tanh activation </span>
    <span class="n">high</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="o">/</span><span class="p">(</span><span class="n">n_input</span><span class="p">))</span>
    
    <span class="n">w_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_input</span><span class="p">,</span><span class="n">n_middle</span><span class="p">],</span><span class="n">minval</span><span class="o">=</span><span class="n">low</span><span class="p">,</span><span class="n">maxval</span><span class="o">=</span><span class="n">high</span><span class="p">),</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;W_2&#39;</span><span class="p">)</span>
    <span class="c1">#w_2 = tf.Variable(tf.truncated_normal(shape=[n_input,n_middle], stddev=0.01),name = &#39;W_2&#39;)</span>
    <span class="n">w_2_update_placeholder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">w_2</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">w_2</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;update_w2&#39;</span><span class="p">)</span>
    <span class="n">w_2_update_op</span> <span class="o">=</span> <span class="n">w_2</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">w_2_update_placeholder</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;w_2&#39;</span><span class="p">,</span> <span class="n">w_2</span><span class="p">)</span>
    
    <span class="n">b_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="n">n_middle</span><span class="p">]),</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;b_2&#39;</span><span class="p">)</span>
    <span class="n">b_2_update_placeholder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">b_2</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">b_2</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;update_b2&#39;</span><span class="p">)</span>
    <span class="n">b_2_update_op</span> <span class="o">=</span> <span class="n">b_2</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">b_2_update_placeholder</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;b_2&#39;</span><span class="p">,</span> <span class="n">b_2</span><span class="p">)</span>
    
    
    <span class="n">w2_grad_accum</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_input</span><span class="p">,</span><span class="n">n_middle</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;w2_grad_accum&#39;</span><span class="p">)</span>
    <span class="n">w2_grad_accum_update_placeholder</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">w2_grad_accum</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">w2_grad_accum</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span>
                                            <span class="n">name</span><span class="o">=</span><span class="s1">&#39;update_w2_grad_accum&#39;</span><span class="p">)</span>
    <span class="n">w2_grad_accum_update_op</span> <span class="o">=</span> <span class="n">w2_grad_accum</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">w2_grad_accum_update_placeholder</span><span class="p">)</span>
    
    
    <span class="n">b2_grad_accum</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">n_middle</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;b2_grad_accum&#39;</span><span class="p">)</span>
    <span class="n">b2_grad_accum_update_placeholder</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">b2_grad_accum</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span><span class="n">shape</span><span class="o">=</span><span class="n">b2_grad_accum</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span>
                                            <span class="n">name</span><span class="o">=</span><span class="s1">&#39;update_b2_grad_accum&#39;</span><span class="p">)</span>
    <span class="n">b2_grad_accum_update_op</span> <span class="o">=</span> <span class="n">b2_grad_accum</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">b2_grad_accum_update_placeholder</span><span class="p">)</span>
    
    
    <span class="n">big_omeg_w2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_input</span><span class="p">,</span><span class="n">n_middle</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;omeg_w2&#39;</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;big_omeg_w2&#39;</span><span class="p">,</span> <span class="n">big_omeg_w2</span><span class="p">)</span>
    <span class="n">big_omeg_w2_update_placeholder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">big_omeg_w2</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">big_omeg_w2</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span>
                                                    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;update_big_omeg_w2&#39;</span><span class="p">)</span>
    <span class="n">big_omeg_w2_update_op</span> <span class="o">=</span> <span class="n">big_omeg_w2</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">big_omeg_w2_update_placeholder</span><span class="p">)</span>
    
    
    <span class="n">big_omeg_b2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">n_middle</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;omeg_b2&#39;</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;big_omeg_b2&#39;</span><span class="p">,</span> <span class="n">big_omeg_b2</span><span class="p">)</span>
    <span class="n">big_omeg_b2_update_placeholder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">big_omeg_b2</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">big_omeg_b2</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span>
                                                    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;update_big_omeg_b2&#39;</span><span class="p">)</span>
    <span class="n">big_omeg_b2_update_op</span> <span class="o">=</span> <span class="n">big_omeg_b2</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">big_omeg_b2_update_placeholder</span><span class="p">)</span>
    
    
    <span class="n">star_w2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_input</span><span class="p">,</span><span class="n">n_middle</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;star_w2&#39;</span><span class="p">)</span>
    <span class="n">star_w2_update_placeholder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">star_w2</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">star_w2</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span>
                                                <span class="n">name</span><span class="o">=</span><span class="s1">&#39;update_star_w2&#39;</span><span class="p">)</span>
    <span class="n">star_w2_update_op</span> <span class="o">=</span> <span class="n">star_w2</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">star_w2_update_placeholder</span><span class="p">)</span>
    
    
    <span class="n">star_b2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">n_middle</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;star_b2&#39;</span><span class="p">)</span>
    <span class="n">star_b2_update_placeholder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">star_b2</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">star_b2</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span>
                                                <span class="n">name</span><span class="o">=</span><span class="s1">&#39;update_star_b2&#39;</span><span class="p">)</span>
    <span class="n">star_b2_update_op</span> <span class="o">=</span> <span class="n">star_b2</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">star_b2_update_placeholder</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;op_lyr_w_b&#39;</span><span class="p">):</span>
    
    <span class="n">low</span> <span class="o">=</span> <span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="o">/</span><span class="p">(</span><span class="n">n_middle</span><span class="p">))</span>
    <span class="n">high</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="o">/</span><span class="p">(</span><span class="n">n_middle</span><span class="p">))</span>
    <span class="c1">#w_3 = tf.Variable(tf.random_uniform(shape=[n_middle,10],minval=low,maxval=high), name = &#39;W_3&#39;)</span>
    <span class="c1">#w_3 = tf.Variable(tf.truncated_normal(shape=[n_middle,n_out], stddev=0.01),name = &#39;W_3&#39;)</span>
    <span class="n">w_3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_middle</span><span class="p">,</span><span class="n">n_out</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;W_3&#39;</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;w_3&#39;</span><span class="p">,</span> <span class="n">w_3</span><span class="p">)</span>
    <span class="n">w_3_update_placeholder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">w_3</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">w_3</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;update_w3&#39;</span><span class="p">)</span>
    <span class="n">w_3_update_op</span> <span class="o">=</span> <span class="n">w_3</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">w_3_update_placeholder</span><span class="p">)</span>
    
    <span class="n">b_3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="n">n_out</span><span class="p">]),</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;b_3&#39;</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;b_3&#39;</span><span class="p">,</span> <span class="n">b_3</span><span class="p">)</span>
    <span class="n">b_3_update_placeholder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">b_3</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">b_3</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;update_b3&#39;</span><span class="p">)</span>
    <span class="n">b_3_update_op</span> <span class="o">=</span> <span class="n">b_3</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">b_3_update_placeholder</span><span class="p">)</span>
    
    <span class="n">w3_grad_accum</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_middle</span><span class="p">,</span><span class="n">n_out</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;w3_grad_accum&#39;</span><span class="p">)</span>
    <span class="n">b3_grad_accum</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">n_out</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;b3_grad_accum&#39;</span><span class="p">)</span>
    
    <span class="n">big_omeg_w3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_middle</span><span class="p">,</span><span class="n">n_out</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;omeg_w3&#39;</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;big_omeg_w3&#39;</span><span class="p">,</span> <span class="n">big_omeg_w3</span><span class="p">)</span>
    <span class="n">big_omeg_b3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">n_out</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;omeg_b3&#39;</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;big_omeg_b3&#39;</span><span class="p">,</span> <span class="n">big_omeg_b3</span><span class="p">)</span>
    
    <span class="n">star_w3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_middle</span><span class="p">,</span><span class="n">n_out</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;star_w3&#39;</span><span class="p">)</span>
    <span class="n">star_b3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">n_out</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;star_b3&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">sigma</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span>
                  <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">negative</span><span class="p">(</span><span class="n">x</span><span class="p">))))</span>
<span class="k">def</span> <span class="nf">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">negative</span><span class="p">(</span><span class="n">x</span><span class="p">))),</span> 
                          <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">negative</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span> <span class="p">)</span>

<span class="k">def</span> <span class="nf">sigmaprime</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">sigma</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">sigma</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>

<span class="k">def</span> <span class="nf">tanhprime</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>

<span class="k">def</span> <span class="nf">spkNeuron</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mf">0.0</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> 
                        <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">ReLU</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">ReLUprime</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mf">0.0</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> 
                        <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">spkPrime1</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">l1_bound_higher</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="o">-</span><span class="mi">0</span><span class="o">/</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">r1_bound_lesser</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">less_equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">tau</span><span class="o">/</span><span class="mi">4</span><span class="p">)</span> 
    <span class="n">grad_one</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">l1_bound_higher</span><span class="p">,</span><span class="n">r1_bound_lesser</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">grad_one</span>

<span class="k">def</span> <span class="nf">firstLyrSpks</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> 
                        <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

    
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;hid_lyr_acti&#39;</span><span class="p">):</span>
    <span class="n">z_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">features</span><span class="p">,</span><span class="n">w_2</span><span class="p">,</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;w_2xa_1&#39;</span><span class="p">),</span> <span class="n">b_2</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;z_2&#39;</span><span class="p">)</span>
    <span class="n">locs_to_drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">categorical</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">([[</span><span class="mf">1.0</span><span class="o">-</span><span class="n">drop_out</span><span class="p">,</span> <span class="n">drop_out</span><span class="p">]]),</span> <span class="n">tf</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">z_2</span><span class="p">))</span>
    <span class="n">locs_to_drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">locs_to_drop</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">z_2</span><span class="p">))</span>
    <span class="n">z_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">locs_to_drop</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">z_2</span><span class="p">),</span><span class="n">z_2</span><span class="p">,</span> <span class="s1">&#39;drop_out_app&#39;</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;z_2&#39;</span><span class="p">,</span> <span class="n">z_2</span><span class="p">)</span>
    <span class="n">a_2</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">z_2</span><span class="p">)</span>
    <span class="c1">#@@a_2 = spkNeuron(z_2)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;a_2&#39;</span><span class="p">,</span> <span class="n">a_2</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;op_lyr_acti&#39;</span><span class="p">):</span>
    <span class="n">z_3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">a_2</span><span class="p">,</span><span class="n">w_3</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;w_3xa_2&#39;</span><span class="p">),</span><span class="n">b_3</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;z_3&#39;</span><span class="p">)</span>
    <span class="c1">#@@z_3 = tf.floor(z_3)</span>
    <span class="c1">#z_3 = tf.subtract(tf.reduce_max(z_3),z_3, name = &#39;inhibition&#39;)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;z_3&#39;</span><span class="p">,</span> <span class="n">z_3</span><span class="p">)</span>
    <span class="n">a_3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">z_3</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">a_3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">a_3</span><span class="p">,</span> <span class="n">set1_mask</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;masking&#39;</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;a_3&#39;</span><span class="p">,</span> <span class="n">a_3</span><span class="p">)</span>
    <span class="c1">##COMMENT THE ABOVE LINE AND UNCOMMENT BELOW LINE IF YOU WANT SOFTMAX</span>
    <span class="c1">#a_3 = tf.nn.softmax(z_3,axis=1) ##AXIS IS VERY IMPORTANT!!! axis=1 INDICATES THE CLASSES AS y IS [None,10]</span>

<span class="c1">#cost = tf.reduce_mean(-tf.reduce_sum((y*tf.log(a_3) +tf.log(1-a_3)*(1-y)) ,axis=0), name = &#39;cost_calc&#39;) WORKS, USE BELOW</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;cost_calc&#39;</span><span class="p">):</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits_v2</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span><span class="n">logits</span><span class="o">=</span><span class="n">z_3</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                          <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;cost_calc&#39;</span><span class="p">)</span><span class="c1">#WORKS</span>
        <span class="c1">##COMMENT BELOW LINES IF YOU WANT quadratic</span>
    <span class="c1">#@dc_da = tf.multiply(-tf.subtract(labels,a_3, name = &#39;y_minus_a_3&#39;), mask)</span>
    <span class="c1">#@cost = tf.reduce_mean(tf.reduce_sum((1/2.0)*tf.square(dc_da),axis=1), name = &#39;cost_calc&#39;)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;cost&#39;</span><span class="p">,</span> <span class="n">cost</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;op_lyr_grad&#39;</span><span class="p">):</span>
    <span class="c1">#@d_z_3 = tf.multiply(-tf.subtract(labels,a_3, name = &#39;delta3&#39;), mask, name=&#39;masking&#39;)</span>
    <span class="n">d_z_3</span> <span class="o">=</span> <span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span><span class="n">a_3</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;delta3&#39;</span><span class="p">)</span>
    <span class="c1">#d_z_3 = tf.multiply(dc_da,a_3, name = &#39;delta3&#39;)</span>
    <span class="n">d_b_3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">d_z_3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;d_b_3&#39;</span><span class="p">,</span> <span class="n">d_b_3</span><span class="p">)</span>
    <span class="n">d_w_3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">a_2</span><span class="p">),</span><span class="n">d_z_3</span><span class="p">),</span> 
                        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;delta_w3&#39;</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;d_w_3&#39;</span><span class="p">,</span> <span class="n">d_w_3</span><span class="p">)</span>
    
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;hid_lyr_grad&#39;</span><span class="p">):</span>
    <span class="n">d_z_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">d_z_3</span><span class="p">,</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">w_3</span><span class="p">),</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;w_3Txdelta3&#39;</span><span class="p">),</span> <span class="n">ReLUprime</span><span class="p">(</span><span class="n">z_2</span><span class="p">),</span>
                        <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;delta2&#39;</span><span class="p">)</span>
    <span class="c1">#@@d_z_2 = tf.multiply(tf.matmul(d_z_3,tf.transpose(w_3), name = &#39;w_3Txdelta3&#39;), spkPrime1(z_2),</span>
    <span class="c1">#@@                    name = &#39;delta2&#39;)</span>
    <span class="c1">#d_z_2 = tf.matmul(d_z_3,tf.transpose(w_3), name = &#39;delta2&#39;)</span>
    <span class="n">d_b_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">d_z_2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">d_b_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">gradient_gate</span><span class="p">,</span> <span class="n">d_b_2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;gradient_gating_b2&#39;</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;d_b_2&#39;</span><span class="p">,</span> <span class="n">d_b_2</span><span class="p">)</span>
    <span class="n">d_w_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">features</span><span class="p">),</span><span class="n">d_z_2</span><span class="p">),</span> 
                        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;delta_w2&#39;</span><span class="p">)</span>
    <span class="n">d_w_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">gradient_gate</span><span class="p">,</span> <span class="n">d_w_2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;gradient_gating_w2&#39;</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;d_w_2&#39;</span><span class="p">,</span> <span class="n">d_w_2</span><span class="p">)</span>
    
<span class="n">omega_step</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">w2_grad_accum</span><span class="p">,</span>
                      <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">w2_grad_accum</span><span class="p">,</span><span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">eta</span><span class="o">*</span><span class="n">eta</span><span class="o">*</span><span class="n">lmbda</span><span class="o">/</span><span class="n">n_tot</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">d_w_2</span><span class="p">))),</span>
                     <span class="n">name</span><span class="o">=</span><span class="s1">&#39;update_omeg_w2&#39;</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">b2_grad_accum</span><span class="p">,</span>
                      <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">b2_grad_accum</span><span class="p">,</span><span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">eta</span><span class="o">*</span><span class="n">eta</span><span class="o">*</span><span class="n">lmbda</span><span class="o">/</span><span class="n">n_tot</span><span class="p">,</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">d_b_2</span><span class="p">))),</span>
                     <span class="n">name</span><span class="o">=</span><span class="s1">&#39;update_omeg_b2&#39;</span><span class="p">)</span>
<span class="p">]</span>

<span class="n">step</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">w_2</span><span class="p">,</span>
                  <span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">w_2</span><span class="p">,</span> <span class="p">(</span><span class="n">eta</span><span class="o">*</span><span class="n">d_w_2</span><span class="o">+</span><span class="n">big_omeg_w2</span><span class="o">*</span><span class="p">(</span><span class="n">w_2</span><span class="o">-</span><span class="n">star_w2</span><span class="p">))),</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;update_w_2&#39;</span><span class="p">),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">b_2</span><span class="p">,</span>
                  <span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">b_2</span><span class="p">,(</span><span class="n">eta</span><span class="o">*</span><span class="n">d_b_2</span><span class="o">+</span><span class="n">big_omeg_b2</span><span class="o">*</span><span class="p">(</span><span class="n">b_2</span><span class="o">-</span><span class="n">star_b2</span><span class="p">))),</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;update_b_2&#39;</span><span class="p">),</span>
        
        <span class="n">tf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">w_3</span><span class="p">,</span>
                  <span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">w_3</span><span class="p">,</span> <span class="p">(</span><span class="n">eta</span><span class="o">*</span><span class="n">d_w_3</span><span class="o">+</span><span class="n">big_omeg_w3</span><span class="o">*</span><span class="p">(</span><span class="n">w_3</span><span class="o">-</span><span class="n">star_w3</span><span class="p">))),</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;update_w_3&#39;</span><span class="p">),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">b_3</span><span class="p">,</span>
                  <span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">b_3</span><span class="p">,(</span><span class="n">eta</span><span class="o">*</span><span class="n">d_b_3</span><span class="o">+</span><span class="n">big_omeg_b3</span><span class="o">*</span><span class="p">(</span><span class="n">b_3</span><span class="o">-</span><span class="n">star_b3</span><span class="p">))),</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;update_b_3&#39;</span><span class="p">)</span>    
<span class="p">]</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;acc_calc&#39;</span><span class="p">):</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">a_3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">acct_mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">a_3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">acct_res</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">acct_mat</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">acct_res</span><span class="p">)</span>
    
    <span class="c1">#test_accuracy_summary = tf.summary.scalar(&#39;test_accuracy&#39;, acct_res)</span>
    
<span class="n">init_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Init-the-writer-with-three-best-$\lambda$s">Init the writer with three best $\lambda$s<a class="anchor-link" href="#Init-the-writer-with-three-best-$\lambda$s">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;/home/ruthvik/Desktop/Summer 2017/tf_graph_outputs/mnist/continual_learning/original_mnist_5sets&#39;</span>
<span class="n">merged</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">merge_all</span><span class="p">()</span>
<span class="n">train_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="s1">&#39;/spike_mnist_ar1_final&#39;</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Generate-$\lambda$s">Generate $\lambda$s<a class="anchor-link" href="#Generate-$\lambda$s">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">n_lmbdas</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mf">111.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">220</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_lmbdas</span><span class="p">,))</span>
<span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="k">print</span><span class="p">()</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">*</span><span class="mf">1.0e5</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">a</span><span class="p">)]</span>
<span class="n">a</span><span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">:]</span>
<span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="n">a</span>
<span class="k">print</span><span class="p">()</span>
<span class="n">n_reps</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1">#a = ([0]+a.tolist())*n_reps</span>
<span class="c1">#n_lmbdas+=1</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span><span class="o">*</span><span class="n">n_reps</span>
<span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[170.23113866 141.34226298 157.27241739 203.08059842 111.51435532
 124.25103417]
()
[15727241.73916555 17023113.86552152 20308059.84228695]
()
([15727241.73916555, 17023113.865521524, 20308059.84228695, 15727241.73916555, 17023113.865521524, 20308059.84228695, 15727241.73916555, 17023113.865521524, 20308059.84228695, 15727241.73916555, 17023113.865521524, 20308059.84228695, 15727241.73916555, 17023113.865521524, 20308059.84228695, 15727241.73916555, 17023113.865521524, 20308059.84228695, 15727241.73916555, 17023113.865521524, 20308059.84228695, 15727241.73916555, 17023113.865521524, 20308059.84228695, 15727241.73916555, 17023113.865521524, 20308059.84228695, 15727241.73916555, 17023113.865521524, 20308059.84228695], 30)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Generate-random-weights">Generate random weights<a class="anchor-link" href="#Generate-random-weights">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">lmbdas</span> <span class="o">=</span> <span class="n">a</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">np_weights</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">n_lmbdas</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">low</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="o">/</span><span class="p">(</span><span class="n">n_input</span><span class="p">))</span> <span class="c1"># use 4 for sigmoid, 1 for tanh activation </span>
<span class="n">high</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="o">/</span><span class="p">(</span><span class="n">n_input</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_reps</span><span class="p">):</span>
    <span class="n">np_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">low</span><span class="p">,</span><span class="n">high</span><span class="o">=</span><span class="n">high</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_input</span><span class="p">,</span><span class="n">n_middle</span><span class="p">)))</span>

<span class="n">np_weights</span><span class="o">=</span><span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">np_weights</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_lmbdas</span><span class="p">)]</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">np_weights</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">lmbdas</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(30, 30)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">np_weights</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">np_weights</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[17]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>True</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">np_weights</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">np_weights</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[18]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>False</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Commence-training">Commence training<a class="anchor-link" href="#Commence-training">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">START_TIME</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">method3_test_accs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1">#INITIALIZE THE NETWORK</span>
<span class="n">logging_count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init_op</span><span class="p">,</span><span class="n">options</span><span class="o">=</span><span class="n">run_options</span><span class="p">,</span> <span class="n">run_metadata</span><span class="o">=</span><span class="n">run_metadata</span><span class="p">)</span>
<span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">finalize</span><span class="p">()</span>
<span class="n">all_prev_task_test_accs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_prev_task_test_activs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lmbdas</span><span class="p">)):</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Training with lmbda:{}, {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lmbdas</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">l</span><span class="p">))</span>
    <span class="c1">#sess.run(init_op,options=run_options, run_metadata=run_metadata)</span>
    <span class="n">zeta</span> <span class="o">=</span> <span class="mf">1e-3</span>
    <span class="n">new_big_omeg_w2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_input</span><span class="p">,</span><span class="n">n_middle</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">new_big_omeg_b2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">n_middle</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">w3_zeros</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_middle</span><span class="p">,</span><span class="n">n_out</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">b3_zeros</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">n_out</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">w3_accum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_middle</span><span class="p">,</span><span class="n">n_out</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">w3_accum</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">b3_accum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">n_out</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">b3_accum</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">reset_w2_grad_accum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_input</span><span class="p">,</span><span class="n">n_middle</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">reset_b2_grad_accum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">n_middle</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">start_w2</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">start_b2</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w_2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">w_2_update_placeholder</span><span class="p">:</span><span class="n">np_weights</span><span class="p">[</span><span class="n">l</span><span class="p">]})</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b_2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">b_2_update_placeholder</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">n_middle</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)})</span>
    <span class="n">end_w2</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">end_b2</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="n">old_test_data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">frac_old_train_images</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">frac_old_train_labels</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">historical_cross_test_acc</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">historical_train_accuracies</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">historical_train_costs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">historical_val_accuracies</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">historical_val_costs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">sets</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">)]</span>
    <span class="c1">#sets = [(0,4),(5,9)]</span>
    <span class="n">test_labels_set</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">prev_task_test_accs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">prev_task_test_activs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_test_samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">a_set</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sets</span><span class="p">)):</span>
        <span class="n">current_set</span> <span class="o">=</span> <span class="n">sets</span><span class="p">[</span><span class="n">a_set</span><span class="p">]</span>
        <span class="n">current_set_name</span> <span class="o">=</span> <span class="s1">&#39;set&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">a_set</span><span class="p">)</span>
        <span class="n">mask_val</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">num_classes</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">current_set</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">mask_val</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>
        <span class="n">set_mask_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">mask_val</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Current mask:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">set_mask_val</span><span class="p">))</span>
        <span class="n">train_data_set</span><span class="p">,</span> <span class="n">valid_data_set</span><span class="p">,</span> <span class="n">test_data_set</span> <span class="o">=</span> <span class="n">extract_class_data</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="n">current_set</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                                                      <span class="n">stop</span><span class="o">=</span><span class="n">current_set</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">train_images_set</span><span class="p">,</span> <span class="n">train_labels_set</span> <span class="o">=</span> <span class="n">train_data_set</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_data_set</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">valid_images_set</span><span class="p">,</span> <span class="n">valid_labels_set</span> <span class="o">=</span> <span class="n">valid_data_set</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">valid_data_set</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">test_images_set</span><span class="p">,</span> <span class="n">test_labels_set</span> <span class="o">=</span> <span class="n">test_data_set</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">test_data_set</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">n_test_samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_labels_set</span><span class="p">))</span>
        <span class="n">train_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_images_set</span><span class="p">)</span>
        <span class="n">n_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_images_set</span><span class="p">)</span><span class="o">/</span><span class="n">BATCH_SIZE</span>
        <span class="c1">#@@print(&#39;Number of batches:{}&#39;.format(n_batches))</span>


        <span class="c1">#@@set_omegas = [tf.assign(big_omeg_w2, new_big_omeg_w2), tf.assign(big_omeg_b2, new_big_omeg_b2)]</span>
        <span class="c1">#@@sess.run(set_omegas)</span>
        
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">big_omeg_w2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">big_omeg_w2_update_placeholder</span><span class="p">:</span><span class="n">new_big_omeg_w2</span><span class="p">})</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">big_omeg_b2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">big_omeg_b2_update_placeholder</span><span class="p">:</span><span class="n">new_big_omeg_b2</span><span class="p">})</span>

        <span class="c1">#@@reset_grad_accums = [tf.assign(w2_grad_accum, reset_w2_grad_accum),</span>
        <span class="c1">#@@                     tf.assign(b2_grad_accum, reset_b2_grad_accum)]</span>
        <span class="c1">#@@sess.run(reset_grad_accums)</span>
        
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w2_grad_accum_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">w2_grad_accum_update_placeholder</span><span class="p">:</span><span class="n">reset_w2_grad_accum</span><span class="p">})</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b2_grad_accum_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">b2_grad_accum_update_placeholder</span><span class="p">:</span><span class="n">reset_b2_grad_accum</span><span class="p">})</span>

        
        <span class="c1">#@@reset_w3 = [tf.assign(w_3, w3_zeros), tf.assign(b_3, b3_zeros)]</span>
        <span class="c1">#@@sess.run(reset_w3)</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w_3_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">w_3_update_placeholder</span><span class="p">:</span><span class="n">w3_zeros</span><span class="p">})</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b_3_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">b_3_update_placeholder</span><span class="p">:</span><span class="n">b3_zeros</span><span class="p">})</span>
    
        <span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="n">repeats</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">for</span> <span class="n">repeat</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">repeats</span><span class="p">):</span>
            <span class="c1">#tf.set_random_seed(l)</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Repeat:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">repeat</span><span class="p">))</span>
            <span class="n">train_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">train_costs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">val_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">val_costs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">best_val</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">first_params_set</span> <span class="o">=</span> <span class="bp">None</span>
            <span class="n">last_params_set</span> <span class="o">=</span> <span class="bp">None</span>
            <span class="n">T1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
                <span class="k">if</span><span class="p">(</span><span class="n">i</span><span class="o">==</span><span class="n">epochs</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                    <span class="n">start_w2</span><span class="p">,</span> <span class="n">start_b2</span> <span class="o">=</span> <span class="n">w_2</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">b_2</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="nb">iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">a_1</span><span class="p">:</span> <span class="n">train_images_set</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">train_labels_set</span><span class="p">,</span>
                                                      <span class="n">batch_size</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_images_set</span><span class="p">)})</span>
                <span class="c1">#@@print(&#39;Epoch:{}&#39;.format((i)))</span>
                <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

                <span class="c1">### CALCULATE TRAIN COSTS AND TRAIN ACCURACIES</span>
                <span class="n">train_cost</span><span class="p">,</span> <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">cost</span><span class="p">,</span> <span class="n">acct_res</span><span class="p">]</span> <span class="p">,</span><span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span> <span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> 
                                                                                     <span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">})</span>
                <span class="n">train_costs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_cost</span><span class="p">)</span>
                <span class="n">train_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_accuracy</span><span class="p">)</span>
                <span class="c1">#train_writer.add_summary(summary,logging_count)</span>

                <span class="k">print</span><span class="p">(</span><span class="s1">&#39;training cost:{} and training accuracy:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_costs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">train_accuracies</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

                <span class="c1">### CALCULATE VALID COSTS AND VALID ACCURACIES</span>
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="nb">iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">a_1</span><span class="p">:</span> <span class="n">valid_images_set</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">valid_labels_set</span><span class="p">,</span>
                                                      <span class="n">batch_size</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_images_set</span><span class="p">)})</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="n">val_cost</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">predictions</span><span class="p">,</span><span class="n">acct_mat</span><span class="p">,</span><span class="n">acct_res</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">a_3</span><span class="p">],</span>
                                                      <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span> <span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span><span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">})</span>
                <span class="n">val_costs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_cost</span><span class="p">)</span>
                <span class="n">val_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_acc</span><span class="p">)</span>

                <span class="k">if</span><span class="p">(</span><span class="n">val_acc</span><span class="o">&gt;</span><span class="n">best_val</span><span class="p">):</span>
                    <span class="n">best_val</span> <span class="o">=</span> <span class="n">val_acc</span>
                    <span class="n">best_params_set1</span> <span class="o">=</span> <span class="p">[(</span><span class="n">w_2</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span><span class="n">b_2</span><span class="o">.</span><span class="n">eval</span><span class="p">()),(</span><span class="n">w_3</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span><span class="n">b_3</span><span class="o">.</span><span class="n">eval</span><span class="p">())]</span>
                <span class="k">print</span><span class="p">(</span><span class="s1">&#39;validation cost:{} and validation accuracy:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">val_cost</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">))</span>   
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="nb">iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">a_1</span><span class="p">:</span> <span class="n">train_images_set</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">train_labels_set</span><span class="p">,</span>
                                                      <span class="n">batch_size</span><span class="p">:</span> <span class="n">BATCH_SIZE</span><span class="p">})</span>


                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="nb">iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">a_1</span><span class="p">:</span> <span class="n">train_images_set</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">train_labels_set</span><span class="p">,</span>
                                                  <span class="n">batch_size</span><span class="p">:</span> <span class="n">BATCH_SIZE</span><span class="p">})</span>
                <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Training on :{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">current_set</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_batches</span><span class="p">):</span>

                    <span class="k">if</span><span class="p">(</span><span class="ow">not</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">w_2</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">w_3</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span><span class="o">.</span><span class="n">any</span><span class="p">()))):</span>
                        <span class="c1">#if(a_set==1):</span>
                        <span class="c1">#    print(j, w_2.eval().sum(), w_3.eval().sum())</span>
                        <span class="k">if</span><span class="p">(((</span><span class="n">j</span><span class="p">)</span><span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span><span class="mi">0</span><span class="p">)):</span>
                            <span class="n">logging_count</span><span class="o">+=</span><span class="mi">1</span>
                            <span class="k">if</span><span class="p">(</span><span class="n">i</span><span class="o">==</span><span class="n">epochs</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>   
                                <span class="n">summary</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">merged</span><span class="p">,</span><span class="n">step</span><span class="p">,</span> <span class="n">omega_step</span><span class="p">],</span> 
                                                     <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span><span class="n">batch_size</span><span class="p">:</span> <span class="n">BATCH_SIZE</span><span class="p">,</span><span class="n">tau</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span>
                                                                  <span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">,</span><span class="n">eta</span><span class="p">:</span><span class="mf">0.001</span><span class="p">,</span>
                                                                  <span class="n">lmbda</span><span class="p">:</span><span class="n">lmbdas</span><span class="p">[</span><span class="n">l</span><span class="p">],</span><span class="n">n_tot</span><span class="p">:</span><span class="n">train_total</span><span class="p">})</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">summary</span><span class="p">,</span><span class="n">_</span><span class="p">,</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">merged</span><span class="p">,</span><span class="n">step</span><span class="p">],</span> 
                                                     <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span><span class="n">batch_size</span><span class="p">:</span> <span class="n">BATCH_SIZE</span><span class="p">,</span><span class="n">tau</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span>
                                                                  <span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">,</span><span class="n">eta</span><span class="p">:</span><span class="mf">0.001</span><span class="p">,</span>
                                                                  <span class="n">lmbda</span><span class="p">:</span><span class="n">lmbdas</span><span class="p">[</span><span class="n">l</span><span class="p">],</span><span class="n">n_tot</span><span class="p">:</span><span class="n">train_total</span><span class="p">})</span>
                            <span class="c1">#train_writer.add_summary(summary, (i+1)*j)</span>
                            <span class="n">train_writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="n">logging_count</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">if</span><span class="p">(</span><span class="n">i</span><span class="o">==</span><span class="n">epochs</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">step</span><span class="p">,</span> <span class="n">omega_step</span><span class="p">],</span><span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span><span class="n">batch_size</span><span class="p">:</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                                                                         <span class="n">tau</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span><span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">,</span>
                                                                         <span class="n">eta</span><span class="p">:</span><span class="mf">0.001</span><span class="p">,</span><span class="n">lmbda</span><span class="p">:</span><span class="n">lmbdas</span><span class="p">[</span><span class="n">l</span><span class="p">],</span>
                                                                         <span class="n">n_tot</span><span class="p">:</span><span class="n">train_total</span><span class="p">})</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">step</span><span class="p">],</span><span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span><span class="n">batch_size</span><span class="p">:</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                                                                     <span class="n">tau</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span><span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">,</span>
                                                                     <span class="n">eta</span><span class="p">:</span><span class="mf">0.001</span><span class="p">,</span><span class="n">lmbda</span><span class="p">:</span><span class="n">lmbdas</span><span class="p">[</span><span class="n">l</span><span class="p">],</span>
                                                                     <span class="n">n_tot</span><span class="p">:</span><span class="n">train_total</span><span class="p">})</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Nan encountered in epoch:{} and batch:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">))</span>
                <span class="c1">#@@print(&#39;Epoch time:{}&#39;.format(time.time()-t1))</span>


            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="nb">iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">a_1</span><span class="p">:</span> <span class="n">test_images_set</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">test_labels_set</span><span class="p">,</span>
                                                      <span class="n">batch_size</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_images_set</span><span class="p">)})</span>
            <span class="n">_</span><span class="p">,</span><span class="n">final_test_acc</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">predictions</span><span class="p">,</span> <span class="n">acct_res</span><span class="p">,</span> <span class="n">a_3</span><span class="p">],</span> 
                                                                  <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span> 
                                                                               <span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">})</span>
            <span class="c1">#@@print(&#39;Final test accuracy is:{}&#39;.format(final_test_acc))</span>
            <span class="n">end_w2</span><span class="p">,</span> <span class="n">end_b2</span><span class="p">,</span> <span class="n">end_w3</span><span class="p">,</span> <span class="n">end_b3</span> <span class="o">=</span> <span class="n">w_2</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">b_2</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">w_3</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">b_3</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="c1">#@@update_star_wbs = [tf.assign(star_w2,end_w2),tf.assign(star_b2,end_b2)]</span>
            <span class="c1">#@@sess.run(update_star_wbs)</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">star_w2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">star_w2_update_placeholder</span><span class="p">:</span><span class="n">end_w2</span><span class="p">})</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">star_b2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">star_b2_update_placeholder</span><span class="p">:</span><span class="n">end_b2</span><span class="p">})</span>
            
            
            <span class="c1">#all_final_test_accs_set1.append(final_test_acc)</span>


            <span class="c1">#@@best_step = [tf.assign(w_2,best_params_set1[0][0]), tf.assign(b_2,best_params_set1[0][1]),</span>
            <span class="c1">#@@             tf.assign(w_3,best_params_set1[1][0]),tf.assign(b_3,best_params_set1[1][1])]</span>
            <span class="c1">#@@sess.run(best_step)</span>
            
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w_2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">w_2_update_placeholder</span><span class="p">:</span><span class="n">best_params_set1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]})</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b_2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">b_2_update_placeholder</span><span class="p">:</span><span class="n">best_params_set1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]})</span>
            
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w_3_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">w_3_update_placeholder</span><span class="p">:</span><span class="n">best_params_set1</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]})</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b_3_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">b_3_update_placeholder</span><span class="p">:</span><span class="n">best_params_set1</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]})</span>
            
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="nb">iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">a_1</span><span class="p">:</span> <span class="n">test_images_set</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">test_labels_set</span><span class="p">,</span>
                                                      <span class="n">batch_size</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_images_set</span><span class="p">)})</span>
            <span class="n">_</span><span class="p">,</span><span class="n">test_acc_corresp_best_val</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">predictions</span><span class="p">,</span> <span class="n">acct_res</span><span class="p">,</span> <span class="n">a_3</span><span class="p">],</span>
                                                     <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span><span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">})</span>

            <span class="c1">#@@print(&#39;Test accuracy corresp to best val acc:{}&#39;.format(test_acc_corresp_best_val))</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Time taken:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">T1</span><span class="p">))</span>
            <span class="c1">#w3_list.append(w_3.eval())</span>
            <span class="n">w3_accum</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w_3</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span>
            <span class="c1">#b3_list.append(b_3.eval())</span>
            <span class="n">b3_accum</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">b_3</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span>
            <span class="k">if</span><span class="p">(</span><span class="n">i</span><span class="o">==</span><span class="n">epochs</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="k">if</span><span class="p">(</span><span class="n">test_acc_corresp_best_val</span><span class="o">&gt;</span><span class="n">final_test_acc</span><span class="p">):</span>
                    <span class="n">end_w2</span><span class="p">,</span> <span class="n">end_b2</span><span class="p">,</span> <span class="n">end_w3</span><span class="p">,</span> <span class="n">end_b3</span> <span class="o">=</span> <span class="n">w_2</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">b_2</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">w_3</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">b_3</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
                    <span class="c1">#all_final_test_accs_set1[-1] = test_acc_corresp_best_val</span>
                    <span class="c1">#@@update_star_wbs = [tf.assign(star_w2,end_w2),tf.assign(star_b2,end_b2)]</span>
                    <span class="c1">#@@sess.run(update_star_wbs)</span>
                    
                    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">star_w2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">star_w2_update_placeholder</span><span class="p">:</span><span class="n">end_w2</span><span class="p">})</span>
                    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">star_b2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">star_b2_update_placeholder</span><span class="p">:</span><span class="n">end_b2</span><span class="p">})</span>
                    

                <span class="c1">#@@best_step = [tf.assign(w_2,end_w2), tf.assign(b_2,end_b2),</span>
                <span class="c1">#@@         tf.assign(w_3,end_w3),tf.assign(b_3,end_b3)]</span>
                <span class="c1">#@@sess.run(best_step)</span>
                
                
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w_2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">w_2_update_placeholder</span><span class="p">:</span><span class="n">end_w2</span><span class="p">})</span>
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b_2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">b_2_update_placeholder</span><span class="p">:</span><span class="n">end_b2</span><span class="p">})</span>
                
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w_3_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">w_3_update_placeholder</span><span class="p">:</span><span class="n">end_w3</span><span class="p">})</span>
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b_3_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">b_3_update_placeholder</span><span class="p">:</span><span class="n">end_b3</span><span class="p">})</span>

                <span class="n">first_params_set</span> <span class="o">=</span> <span class="p">[(</span><span class="n">start_w2</span><span class="p">,</span> <span class="n">start_b2</span><span class="p">)]</span>
                <span class="n">last_params_set</span> <span class="o">=</span> <span class="p">[(</span><span class="n">end_w2</span><span class="p">,</span> <span class="n">end_b2</span><span class="p">)]</span>

                <span class="n">small_omegas</span> <span class="o">=</span> <span class="p">[(</span><span class="n">w2_grad_accum</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span><span class="n">b2_grad_accum</span><span class="o">.</span><span class="n">eval</span><span class="p">())]</span>

                <span class="n">delta_ws</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">+</span><span class="n">zeta</span><span class="p">,[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">last_params_set</span><span class="p">],</span>
                           <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">first_params_set</span><span class="p">])</span>

                <span class="n">delta_bs</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">+</span><span class="n">zeta</span><span class="p">,[</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">last_params_set</span><span class="p">],</span>
                           <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">first_params_set</span><span class="p">])</span>
                <span class="n">delta_wbs</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">delta_ws</span><span class="p">,</span> <span class="n">delta_bs</span><span class="p">)</span>

                <span class="n">big_omegas_ws</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="o">/</span><span class="n">y</span><span class="p">),[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">small_omegas</span><span class="p">],</span>
                           <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">delta_wbs</span><span class="p">])</span>            
                <span class="n">big_omegas_bs</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="o">/</span><span class="n">y</span><span class="p">),[</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">small_omegas</span><span class="p">],</span>
                           <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">delta_wbs</span><span class="p">])</span>

                <span class="n">big_omegas</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">big_omegas_ws</span><span class="p">,</span> <span class="n">big_omegas_bs</span><span class="p">)</span>
                <span class="n">new_big_omeg_w2</span> <span class="o">+=</span> <span class="n">big_omegas</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">new_big_omeg_b2</span> <span class="o">+=</span> <span class="n">big_omegas</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
                <span class="c1">#@@print(&#39;omegW2-MAXIMUM:{},MEAN:{},STD:{}&#39;.format(new_big_omeg_w2.max(),</span>
                <span class="c1">#@@                                                new_big_omeg_w2.mean(),</span>
                <span class="c1">#@@                                                new_big_omeg_w2.std()))</span>
                <span class="c1">#@@print(&#39;omegb2-MAXIMUM:{},MEAN:{},STD:{}&#39;.format(new_big_omeg_b2.max(),</span>
                <span class="c1">#@@                                                new_big_omeg_b2.mean(),</span>
                <span class="c1">#@@                                                new_big_omeg_b2.std()))</span>

        <span class="n">historical_train_accuracies</span><span class="p">[</span><span class="n">current_set_name</span><span class="p">]</span><span class="o">=</span><span class="n">train_accuracies</span>
        <span class="n">historical_train_costs</span><span class="p">[</span><span class="n">current_set_name</span><span class="p">]</span><span class="o">=</span><span class="n">train_costs</span>
        <span class="n">historical_val_accuracies</span><span class="p">[</span><span class="n">current_set_name</span><span class="p">]</span><span class="o">=</span><span class="n">val_accuracies</span>
        <span class="n">historical_val_costs</span><span class="p">[</span><span class="n">current_set_name</span><span class="p">]</span><span class="o">=</span><span class="n">val_costs</span>
        
        <span class="n">old_test_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_data_set</span><span class="p">)</span>
        <span class="c1">#######Method 3 ###########</span>
        <span class="n">w3_set_rows</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">offset</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">w3_accum</span><span class="p">:</span>
            <span class="n">w3_set_rows</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">[:,</span><span class="n">offset</span><span class="p">:</span><span class="n">offset</span><span class="o">+</span><span class="mi">2</span><span class="p">])</span>
            <span class="n">offset</span><span class="o">+=</span><span class="mi">2</span>


        <span class="n">w3_set_row_avgs</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">w3_set_rows</span><span class="p">]</span>
        <span class="n">final_w3</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">,</span><span class="n">w3_set_rows</span><span class="p">,</span> <span class="n">w3_set_row_avgs</span><span class="p">)</span>
        <span class="c1">#final_w3 = np.concatenate(final_w3, axis=1)</span>
        <span class="n">final_w3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">final_w3</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1500</span><span class="p">,</span><span class="mi">10</span><span class="o">-</span><span class="n">offset</span><span class="p">))],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">b3_set_rows</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">offset</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">b3_accum</span><span class="p">:</span>
            <span class="n">b3_set_rows</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">[:,</span><span class="n">offset</span><span class="p">:</span><span class="n">offset</span><span class="o">+</span><span class="mi">2</span><span class="p">])</span>
            <span class="n">offset</span><span class="o">+=</span><span class="mi">2</span>
        <span class="n">b3_set_row_avgs</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">b3_set_rows</span><span class="p">]</span>
        <span class="n">final_b3</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">,</span><span class="n">b3_set_rows</span><span class="p">,</span> <span class="n">b3_set_row_avgs</span><span class="p">)</span>
        <span class="c1">#final_b3 = np.concatenate(final_b3, axis=1)</span>
        <span class="n">final_b3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">final_b3</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="o">-</span><span class="n">offset</span><span class="p">))],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1">#@@set_w3 = [tf.assign(w_3, final_w3), tf.assign(b_3, final_b3)]</span>
        <span class="c1">#@@sess.run(set_w3)</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w_3_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">w_3_update_placeholder</span><span class="p">:</span><span class="n">final_w3</span><span class="p">})</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b_3_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">b_3_update_placeholder</span><span class="p">:</span><span class="n">final_b3</span><span class="p">})</span>
        
        <span class="k">for</span> <span class="n">items</span> <span class="ow">in</span> <span class="n">old_test_data</span><span class="p">:</span>
            <span class="n">test_images_set</span><span class="p">,</span> <span class="n">test_labels_set</span> <span class="o">=</span> <span class="n">items</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">items</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="nb">iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">a_1</span><span class="p">:</span> <span class="n">test_images_set</span><span class="p">,</span> 
                                                  <span class="n">y</span><span class="p">:</span><span class="n">test_labels_set</span><span class="p">,</span>
                                                  <span class="n">batch_size</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_images_set</span><span class="p">)})</span>
            <span class="n">_</span><span class="p">,</span><span class="n">final_test_acc</span><span class="p">,</span><span class="n">final_test_activ</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">predictions</span><span class="p">,</span> <span class="n">acct_res</span><span class="p">,</span> <span class="n">a_3</span><span class="p">],</span>
                                      <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span><span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">})</span>
            <span class="n">prev_task_test_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_test_acc</span><span class="p">)</span>
            <span class="n">prev_task_test_activs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_test_activ</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Method 3 test accuracy:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">final_test_acc</span><span class="p">))</span>
    
    <span class="n">all_prev_task_test_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prev_task_test_accs</span><span class="p">)</span>
    <span class="n">all_prev_task_test_activs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prev_task_test_activs</span><span class="p">)</span>
    
    
<span class="n">train_writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Total time:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">START_TIME</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training with lmbda:15727241.7392, 0
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.179362744093 and training accuracy:0.997657477856
validation cost:0.177786141634 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0546306855977 and training accuracy:0.998178005219
validation cost:0.0556919276714 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0317249856889 and training accuracy:0.998611807823
validation cost:0.0331957191229 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226408895105 and training accuracy:0.998785376549
validation cost:0.0242020450532 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0177846886218 and training accuracy:0.998785376549
validation cost:0.0193497706205 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0147487148643 and training accuracy:0.998872101307
validation cost:0.016287503764 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0126585103571 and training accuracy:0.998872101307
validation cost:0.0141587248072 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0111239394173 and training accuracy:0.998872101307
validation cost:0.0125813987106 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.00994451157749 and training accuracy:0.998785376549
validation cost:0.011357604526 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:195.94667387
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.350082755089 and training accuracy:0.945186793804
validation cost:0.357370167971 and validation accuracy:0.945772051811
Training on :(2, 3)
training cost:0.175536066294 and training accuracy:0.963276088238
validation cost:0.182559236884 and validation accuracy:0.961397051811
Training on :(2, 3)
training cost:0.122003093362 and training accuracy:0.97127532959
validation cost:0.129577755928 and validation accuracy:0.965073525906
Training on :(2, 3)
training cost:0.0960330590606 and training accuracy:0.976820290089
validation cost:0.103611946106 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0803925022483 and training accuracy:0.980183601379
validation cost:0.0876025781035 and validation accuracy:0.973345577717
Training on :(2, 3)
training cost:0.0697875469923 and training accuracy:0.983456075191
validation cost:0.0764818489552 and validation accuracy:0.978860318661
Training on :(2, 3)
training cost:0.0620259940624 and training accuracy:0.985001385212
validation cost:0.0681645199656 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0560464002192 and training accuracy:0.986455798149
validation cost:0.0616366006434 and validation accuracy:0.984375
Training on :(2, 3)
training cost:0.0512671582401 and training accuracy:0.987273871899
validation cost:0.0563444234431 and validation accuracy:0.984375
Training on :(2, 3)
Time taken:184.064366817
Method 3 test accuracy:0.986761212349
Method 3 test accuracy:0.925073444843
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.250798672438 and training accuracy:0.981756091118
validation cost:0.252236098051 and validation accuracy:0.988153994083
Training on :(4, 5)
training cost:0.127915754914 and training accuracy:0.991414606571
validation cost:0.123422518373 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0870471149683 and training accuracy:0.994146347046
validation cost:0.0806915909052 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.066904887557 and training accuracy:0.994926810265
validation cost:0.059982009232 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.054896697402 and training accuracy:0.995609760284
validation cost:0.0478564277291 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0468868799508 and training accuracy:0.99590241909
validation cost:0.0399068892002 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0411388538778 and training accuracy:0.996097564697
validation cost:0.0342935919762 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0367951132357 and training accuracy:0.99658536911
validation cost:0.0301148872823 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0333850942552 and training accuracy:0.99658536911
validation cost:0.0268803834915 and validation accuracy:1.0
Training on :(4, 5)
Time taken:172.336547136
Method 3 test accuracy:0.982978701591
Method 3 test accuracy:0.917727708817
Method 3 test accuracy:0.689434349537
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.186826422811 and training accuracy:0.992152988911
validation cost:0.181656658649 and validation accuracy:0.989051103592
Training on :(6, 7)
training cost:0.0907825902104 and training accuracy:0.995580434799
validation cost:0.0886963531375 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0621076412499 and training accuracy:0.996752977371
validation cost:0.0609870813787 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0482602678239 and training accuracy:0.997384309769
validation cost:0.0475459806621 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0399992726743 and training accuracy:0.997745096684
validation cost:0.0394872277975 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0344560444355 and training accuracy:0.998286306858
validation cost:0.0340562053025 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0304497499019 and training accuracy:0.9987372756
validation cost:0.030117187649 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0274000186473 and training accuracy:0.999007821083
validation cost:0.0271116085351 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0249904617667 and training accuracy:0.999188244343
validation cost:0.0247322004288 and validation accuracy:1.0
Training on :(6, 7)
Time taken:180.505481005
Method 3 test accuracy:0.98061466217
Method 3 test accuracy:0.903036236763
Method 3 test accuracy:0.68036288023
Method 3 test accuracy:0.890231609344
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.250799119473 and training accuracy:0.959024012089
validation cost:0.251634836197 and validation accuracy:0.955743908882
Training on :(8, 9)
training cost:0.157944366336 and training accuracy:0.967964231968
validation cost:0.159411624074 and validation accuracy:0.967043340206
Training on :(8, 9)
training cost:0.124502383173 and training accuracy:0.971130549908
validation cost:0.126106098294 and validation accuracy:0.970809817314
Training on :(8, 9)
training cost:0.106157198548 and training accuracy:0.974110662937
validation cost:0.107667319477 and validation accuracy:0.974576294422
Training on :(8, 9)
training cost:0.094076320529 and training accuracy:0.977090716362
validation cost:0.0954104885459 and validation accuracy:0.977401137352
Training on :(8, 9)
training cost:0.0853007212281 and training accuracy:0.978860139847
validation cost:0.0864376649261 and validation accuracy:0.98399245739
Training on :(8, 9)
training cost:0.0785308629274 and training accuracy:0.980815768242
validation cost:0.0794739723206 and validation accuracy:0.985875725746
Training on :(8, 9)
training cost:0.073092199862 and training accuracy:0.982585191727
validation cost:0.073853969574 and validation accuracy:0.985875725746
Training on :(8, 9)
training cost:0.0685961470008 and training accuracy:0.983795881271
validation cost:0.0691948980093 and validation accuracy:0.98681730032
Training on :(8, 9)
Time taken:174.674751043
Method 3 test accuracy:0.979669034481
Method 3 test accuracy:0.874143004417
Method 3 test accuracy:0.61099255085
Method 3 test accuracy:0.859013080597
Method 3 test accuracy:0.741301059723
Training with lmbda:17023113.8655, 1
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.179362744093 and training accuracy:0.997657477856
validation cost:0.177786141634 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0546306855977 and training accuracy:0.998178005219
validation cost:0.0556919276714 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0317249856889 and training accuracy:0.998611807823
validation cost:0.0331957191229 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226408895105 and training accuracy:0.998785376549
validation cost:0.0242020450532 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0177846886218 and training accuracy:0.998785376549
validation cost:0.0193497706205 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0147487148643 and training accuracy:0.998872101307
validation cost:0.016287503764 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0126585103571 and training accuracy:0.998872101307
validation cost:0.0141587248072 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0111239394173 and training accuracy:0.998872101307
validation cost:0.0125813987106 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.00994451157749 and training accuracy:0.998785376549
validation cost:0.011357604526 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:189.200062037
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.350404471159 and training accuracy:0.945186793804
validation cost:0.357693940401 and validation accuracy:0.945772051811
Training on :(2, 3)
training cost:0.175839781761 and training accuracy:0.963276088238
validation cost:0.182861208916 and validation accuracy:0.961397051811
Training on :(2, 3)
training cost:0.122268684208 and training accuracy:0.971366226673
validation cost:0.129837960005 and validation accuracy:0.965073525906
Training on :(2, 3)
training cost:0.0962754711509 and training accuracy:0.976820290089
validation cost:0.103849828243 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0806177705526 and training accuracy:0.980183601379
validation cost:0.0878247097135 and validation accuracy:0.973345577717
Training on :(2, 3)
training cost:0.0699988305569 and training accuracy:0.983456075191
validation cost:0.0766929686069 and validation accuracy:0.978860318661
Training on :(2, 3)
training cost:0.062225677073 and training accuracy:0.985001385212
validation cost:0.0683661922812 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0562355779111 and training accuracy:0.986364901066
validation cost:0.0618299730122 and validation accuracy:0.983455896378
Training on :(2, 3)
training cost:0.0514473728836 and training accuracy:0.987273871899
validation cost:0.0565297417343 and validation accuracy:0.984375
Training on :(2, 3)
Time taken:179.283198118
Method 3 test accuracy:0.982505917549
Method 3 test accuracy:0.929970622063
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.252478659153 and training accuracy:0.981756091118
validation cost:0.253980070353 and validation accuracy:0.988153994083
Training on :(4, 5)
training cost:0.129099875689 and training accuracy:0.991317093372
validation cost:0.12466609478 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0879387184978 and training accuracy:0.994146347046
validation cost:0.0816240757704 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.0676149576902 and training accuracy:0.994926810265
validation cost:0.0607204735279 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0554859749973 and training accuracy:0.995512187481
validation cost:0.0484660714865 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0473912172019 and training accuracy:0.99590241909
validation cost:0.0404265411198 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.04157904163 and training accuracy:0.996097564697
validation cost:0.0347453765571 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0371859893203 and training accuracy:0.99658536911
validation cost:0.0305145289749 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0337367877364 and training accuracy:0.99658536911
validation cost:0.0272383410484 and validation accuracy:1.0
Training on :(4, 5)
Time taken:168.176113129
Method 3 test accuracy:0.982033073902
Method 3 test accuracy:0.923604309559
Method 3 test accuracy:0.659551739693
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.188832595944 and training accuracy:0.992152988911
validation cost:0.183663055301 and validation accuracy:0.989051103592
Training on :(6, 7)
training cost:0.0920726060867 and training accuracy:0.995580434799
validation cost:0.0899917855859 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0630697235465 and training accuracy:0.996662735939
validation cost:0.061962634325 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.049037925899 and training accuracy:0.997294127941
validation cost:0.0483420044184 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0406591668725 and training accuracy:0.997745096684
validation cost:0.0401678495109 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0350340493023 and training accuracy:0.998196065426
validation cost:0.0346562713385 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0309652984142 and training accuracy:0.9987372756
validation cost:0.0306559726596 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0278671365231 and training accuracy:0.999007821083
validation cost:0.0276022274047 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0254179630429 and training accuracy:0.999188244343
validation cost:0.0251827277243 and validation accuracy:1.0
Training on :(6, 7)
Time taken:181.405064106
Method 3 test accuracy:0.978723406792
Method 3 test accuracy:0.909892261028
Method 3 test accuracy:0.648879408836
Method 3 test accuracy:0.887210488319
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.25309073925 and training accuracy:0.959210276604
validation cost:0.253914475441 and validation accuracy:0.954802274704
Training on :(8, 9)
training cost:0.159636408091 and training accuracy:0.967871129513
validation cost:0.161089792848 and validation accuracy:0.967043340206
Training on :(8, 9)
training cost:0.125941336155 and training accuracy:0.971037447453
validation cost:0.127538517118 and validation accuracy:0.969868183136
Training on :(8, 9)
training cost:0.107463084161 and training accuracy:0.974017500877
validation cost:0.108976505697 and validation accuracy:0.974576294422
Training on :(8, 9)
training cost:0.0952972769737 and training accuracy:0.976811349392
validation cost:0.0966434404254 and validation accuracy:0.977401137352
Training on :(8, 9)
training cost:0.0864601358771 and training accuracy:0.978580713272
validation cost:0.0876179635525 and validation accuracy:0.983050823212
Training on :(8, 9)
training cost:0.0796416774392 and training accuracy:0.980163931847
validation cost:0.0806121230125 and validation accuracy:0.985875725746
Training on :(8, 9)
training cost:0.0741605907679 and training accuracy:0.982305824757
validation cost:0.0749545991421 and validation accuracy:0.985875725746
Training on :(8, 9)
training cost:0.0696257129312 and training accuracy:0.983423352242
validation cost:0.0702602490783 and validation accuracy:0.98681730032
Training on :(8, 9)
Time taken:175.500885963
Method 3 test accuracy:0.978250563145
Method 3 test accuracy:0.885896205902
Method 3 test accuracy:0.575773775578
Method 3 test accuracy:0.853474318981
Method 3 test accuracy:0.737266778946
Training with lmbda:20308059.8423, 2
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.179362744093 and training accuracy:0.997657477856
validation cost:0.177786141634 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0546306855977 and training accuracy:0.998178005219
validation cost:0.0556919276714 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0317249856889 and training accuracy:0.998611807823
validation cost:0.0331957191229 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226408895105 and training accuracy:0.998785376549
validation cost:0.0242020450532 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0177846886218 and training accuracy:0.998785376549
validation cost:0.0193497706205 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0147487148643 and training accuracy:0.998872101307
validation cost:0.016287503764 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0126585103571 and training accuracy:0.998872101307
validation cost:0.0141587248072 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0111239394173 and training accuracy:0.998872101307
validation cost:0.0125813987106 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.00994451157749 and training accuracy:0.998785376549
validation cost:0.011357604526 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:188.545428038
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.351184874773 and training accuracy:0.945186793804
validation cost:0.358478605747 and validation accuracy:0.945772051811
Training on :(2, 3)
training cost:0.176571547985 and training accuracy:0.963276088238
validation cost:0.183588907123 and validation accuracy:0.961397051811
Training on :(2, 3)
training cost:0.122901089489 and training accuracy:0.971457123756
validation cost:0.130458503962 and validation accuracy:0.965073525906
Training on :(2, 3)
training cost:0.096849180758 and training accuracy:0.976547598839
validation cost:0.104414269328 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.08114823699 and training accuracy:0.980092704296
validation cost:0.0883492827415 and validation accuracy:0.973345577717
Training on :(2, 3)
training cost:0.0704940259457 and training accuracy:0.983546972275
validation cost:0.077187359333 and validation accuracy:0.978860318661
Training on :(2, 3)
training cost:0.0626921355724 and training accuracy:0.984910488129
validation cost:0.0688367187977 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0566770769656 and training accuracy:0.986364901066
validation cost:0.0622794963419 and validation accuracy:0.983455896378
Training on :(2, 3)
training cost:0.0518674366176 and training accuracy:0.987273871899
validation cost:0.0569615662098 and validation accuracy:0.984375
Training on :(2, 3)
Time taken:179.791432858
Method 3 test accuracy:0.982505917549
Method 3 test accuracy:0.929480910301
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.256367176771 and training accuracy:0.981463432312
validation cost:0.258012205362 and validation accuracy:0.988153994083
Training on :(4, 5)
training cost:0.131829321384 and training accuracy:0.991317093372
validation cost:0.12753303349 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0899893864989 and training accuracy:0.994146347046
validation cost:0.0837713330984 and validation accuracy:0.99703848362
Training on :(4, 5)
training cost:0.0692449957132 and training accuracy:0.994926810265
validation cost:0.0624186322093 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0568375587463 and training accuracy:0.995512187481
validation cost:0.0498677045107 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0485452674329 and training accuracy:0.99590241909
validation cost:0.0416184961796 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0425850264728 and training accuracy:0.996097564697
validation cost:0.035780467093 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0380779318511 and training accuracy:0.99658536911
validation cost:0.0314286164939 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0345378443599 and training accuracy:0.99658536911
validation cost:0.02805605717 and validation accuracy:1.0
Training on :(4, 5)
Time taken:168.11879015
Method 3 test accuracy:0.982033073902
Method 3 test accuracy:0.923604309559
Method 3 test accuracy:0.661152601242
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.193551510572 and training accuracy:0.991972565651
validation cost:0.188383430243 and validation accuracy:0.989051103592
Training on :(6, 7)
training cost:0.095094576478 and training accuracy:0.995670616627
validation cost:0.0930287018418 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0653166025877 and training accuracy:0.996662735939
validation cost:0.0642426237464 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0508543401957 and training accuracy:0.997294127941
validation cost:0.0502023473382 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0421987175941 and training accuracy:0.997745096684
validation cost:0.0417569167912 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0363784655929 and training accuracy:0.998105883598
validation cost:0.0360529460013 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0321631319821 and training accuracy:0.9987372756
validation cost:0.0319074839354 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.02895113267 and training accuracy:0.999007821083
validation cost:0.0287393517792 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0264089982957 and training accuracy:0.999188244343
validation cost:0.0262265540659 and validation accuracy:1.0
Training on :(6, 7)
Time taken:182.605041981
Method 3 test accuracy:0.978723406792
Method 3 test accuracy:0.909892261028
Method 3 test accuracy:0.651013851166
Method 3 test accuracy:0.88670694828
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.258546739817 and training accuracy:0.958837747574
validation cost:0.259349495173 and validation accuracy:0.953860640526
Training on :(8, 9)
training cost:0.163678646088 and training accuracy:0.967777967453
validation cost:0.165106624365 and validation accuracy:0.966101706028
Training on :(8, 9)
training cost:0.129363268614 and training accuracy:0.970851182938
validation cost:0.130945414305 and validation accuracy:0.969868183136
Training on :(8, 9)
training cost:0.110549926758 and training accuracy:0.973086237907
validation cost:0.112069815397 and validation accuracy:0.974576294422
Training on :(8, 9)
training cost:0.0981688126922 and training accuracy:0.975973188877
validation cost:0.0995424091816 and validation accuracy:0.974576294422
Training on :(8, 9)
training cost:0.0891750007868 and training accuracy:0.978301346302
validation cost:0.0903782397509 and validation accuracy:0.983050823212
Training on :(8, 9)
training cost:0.0822302252054 and training accuracy:0.979418873787
validation cost:0.0832620561123 and validation accuracy:0.98399245739
Training on :(8, 9)
training cost:0.0766431465745 and training accuracy:0.981467664242
validation cost:0.0775108411908 and validation accuracy:0.985875725746
Training on :(8, 9)
training cost:0.0720151737332 and training accuracy:0.982771456242
validation cost:0.0727312639356 and validation accuracy:0.985875725746
Training on :(8, 9)
Time taken:144.687289953
Method 3 test accuracy:0.978723406792
Method 3 test accuracy:0.887855052948
Method 3 test accuracy:0.586446106434
Method 3 test accuracy:0.862537741661
Method 3 test accuracy:0.709026753902
Training with lmbda:15727241.7392, 3
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.185739651322 and training accuracy:0.997744202614
validation cost:0.182639792562 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0555005222559 and training accuracy:0.998004496098
validation cost:0.0558135248721 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0318333655596 and training accuracy:0.998178005219
validation cost:0.0327127352357 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0225480105728 and training accuracy:0.998525083065
validation cost:0.0235897265375 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0176233183593 and training accuracy:0.998611807823
validation cost:0.0187160409987 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0145617239177 and training accuracy:0.998698592186
validation cost:0.0156639441848 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0124643230811 and training accuracy:0.998785376549
validation cost:0.0135588338599 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0109299588948 and training accuracy:0.998872101307
validation cost:0.0120089538395 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.00975448638201 and training accuracy:0.99895888567
validation cost:0.0108137615025 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:147.392947912
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.351016551256 and training accuracy:0.943186998367
validation cost:0.356324464083 and validation accuracy:0.945772051811
Training on :(2, 3)
training cost:0.17663615942 and training accuracy:0.96136713028
validation cost:0.182125836611 and validation accuracy:0.959558844566
Training on :(2, 3)
training cost:0.123235441744 and training accuracy:0.969911813736
validation cost:0.129492998123 and validation accuracy:0.967830896378
Training on :(2, 3)
training cost:0.0971069857478 and training accuracy:0.975365877151
validation cost:0.103561073542 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0812628790736 and training accuracy:0.97909283638
validation cost:0.0875119194388 and validation accuracy:0.976102948189
Training on :(2, 3)
training cost:0.0704702734947 and training accuracy:0.982365250587
validation cost:0.0763326585293 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0625614151359 and training accuracy:0.984365046024
validation cost:0.0679749026895 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0564707405865 and training accuracy:0.985819458961
validation cost:0.0614278391004 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0516067072749 and training accuracy:0.98772841692
validation cost:0.0561283566058 and validation accuracy:0.984375
Training on :(2, 3)
Time taken:141.310881853
Method 3 test accuracy:0.987234055996
Method 3 test accuracy:0.931929469109
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.255829423666 and training accuracy:0.979121923447
validation cost:0.256895810366 and validation accuracy:0.985192477703
Training on :(4, 5)
training cost:0.130765512586 and training accuracy:0.989853680134
validation cost:0.125823646784 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0888562500477 and training accuracy:0.993365824223
validation cost:0.0821330323815 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.0681548044086 and training accuracy:0.994926810265
validation cost:0.060954015702 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0558069013059 and training accuracy:0.995317101479
validation cost:0.048561822623 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0475746877491 and training accuracy:0.995707333088
validation cost:0.0404448546469 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0416698865592 and training accuracy:0.996195137501
validation cost:0.0347174964845 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.037211406976 and training accuracy:0.996682941914
validation cost:0.0304580740631 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0337132848799 and training accuracy:0.996780514717
validation cost:0.027163837105 and validation accuracy:1.0
Training on :(4, 5)
Time taken:131.590862036
Method 3 test accuracy:0.984397172928
Method 3 test accuracy:0.927522063255
Method 3 test accuracy:0.657417297363
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.179398223758 and training accuracy:0.991160809994
validation cost:0.172895118594 and validation accuracy:0.990875899792
Training on :(6, 7)
training cost:0.0890664979815 and training accuracy:0.994949042797
validation cost:0.0854333862662 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0617225915194 and training accuracy:0.996572554111
validation cost:0.0590639188886 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0483686476946 and training accuracy:0.996933341026
validation cost:0.0461549758911 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0403307192028 and training accuracy:0.997474491596
validation cost:0.0383658669889 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0348987579346 and training accuracy:0.998105883598
validation cost:0.0330905281007 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0309489704669 and training accuracy:0.998286306858
validation cost:0.0292492583394 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0279273055494 and training accuracy:0.9987372756
validation cost:0.0263099838048 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0255289357156 and training accuracy:0.998827457428
validation cost:0.0239776037633 and validation accuracy:1.0
Training on :(6, 7)
Time taken:143.136659145
Method 3 test accuracy:0.981087446213
Method 3 test accuracy:0.913810014725
Method 3 test accuracy:0.639274299145
Method 3 test accuracy:0.888217508793
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.25337177515 and training accuracy:0.958465278149
validation cost:0.252489477396 and validation accuracy:0.956685483456
Training on :(8, 9)
training cost:0.159409433603 and training accuracy:0.966846704483
validation cost:0.159200236201 and validation accuracy:0.96516007185
Training on :(8, 9)
training cost:0.125625148416 and training accuracy:0.971409916878
validation cost:0.125807985663 and validation accuracy:0.974576294422
Training on :(8, 9)
training cost:0.107147313654 and training accuracy:0.975041925907
validation cost:0.107453398407 and validation accuracy:0.97834277153
Training on :(8, 9)
training cost:0.0949845463037 and training accuracy:0.977742612362
validation cost:0.0952717885375 and validation accuracy:0.98116761446
Training on :(8, 9)
training cost:0.086134403944 and training accuracy:0.979139506817
validation cost:0.0863321349025 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.0792874917388 and training accuracy:0.980815768242
validation cost:0.079363308847 and validation accuracy:0.98399245739
Training on :(8, 9)
training cost:0.0737678781152 and training accuracy:0.982119560242
validation cost:0.0737082138658 and validation accuracy:0.984934091568
Training on :(8, 9)
training cost:0.0691854804754 and training accuracy:0.983050823212
validation cost:0.068986363709 and validation accuracy:0.985875725746
Training on :(8, 9)
Time taken:137.530714035
Method 3 test accuracy:0.981087446213
Method 3 test accuracy:0.890303611755
Method 3 test accuracy:0.557097136974
Method 3 test accuracy:0.873111784458
Method 3 test accuracy:0.702975273132
Training with lmbda:17023113.8655, 4
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.185739651322 and training accuracy:0.997744202614
validation cost:0.182639792562 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0555005222559 and training accuracy:0.998004496098
validation cost:0.0558135248721 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0318333655596 and training accuracy:0.998178005219
validation cost:0.0327127352357 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0225480105728 and training accuracy:0.998525083065
validation cost:0.0235897265375 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0176233183593 and training accuracy:0.998611807823
validation cost:0.0187160409987 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0145617239177 and training accuracy:0.998698592186
validation cost:0.0156639441848 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0124643230811 and training accuracy:0.998785376549
validation cost:0.0135588338599 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0109299588948 and training accuracy:0.998872101307
validation cost:0.0120089538395 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.00975448638201 and training accuracy:0.99895888567
validation cost:0.0108137615025 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:147.224107027
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.351340532303 and training accuracy:0.943368792534
validation cost:0.356651425362 and validation accuracy:0.945772051811
Training on :(2, 3)
training cost:0.176934719086 and training accuracy:0.961276233196
validation cost:0.182424485683 and validation accuracy:0.958639681339
Training on :(2, 3)
training cost:0.123491600156 and training accuracy:0.969911813736
validation cost:0.129746347666 and validation accuracy:0.967830896378
Training on :(2, 3)
training cost:0.0973379388452 and training accuracy:0.975365877151
validation cost:0.103789180517 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0814758837223 and training accuracy:0.979001879692
validation cost:0.0877237319946 and validation accuracy:0.976102948189
Training on :(2, 3)
training cost:0.0706693604589 and training accuracy:0.982365250587
validation cost:0.0765321105719 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0627478435636 and training accuracy:0.984365046024
validation cost:0.0681635737419 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0566468574107 and training accuracy:0.985819458961
validation cost:0.0616080760956 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.051774173975 and training accuracy:0.98772841692
validation cost:0.056301843375 and validation accuracy:0.984375
Training on :(2, 3)
Time taken:142.172040939
Method 3 test accuracy:0.986761212349
Method 3 test accuracy:0.931929469109
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.25743663311 and training accuracy:0.978926837444
validation cost:0.258555442095 and validation accuracy:0.984205305576
Training on :(4, 5)
training cost:0.13191318512 and training accuracy:0.98975610733
validation cost:0.12702268362 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0897169336677 and training accuracy:0.993365824223
validation cost:0.083026856184 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.0688377395272 and training accuracy:0.994829297066
validation cost:0.0616579949856 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0563716962934 and training accuracy:0.995317101479
validation cost:0.0491397380829 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0480551980436 and training accuracy:0.995707333088
validation cost:0.0409335233271 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0420884937048 and training accuracy:0.996097564697
validation cost:0.0351406447589 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0375815443695 and training accuracy:0.996682941914
validation cost:0.0308308005333 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.034045048058 and training accuracy:0.996780514717
validation cost:0.027496650815 and validation accuracy:1.0
Training on :(4, 5)
Time taken:131.901342154
Method 3 test accuracy:0.984397172928
Method 3 test accuracy:0.927522063255
Method 3 test accuracy:0.661152601242
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.181208610535 and training accuracy:0.991160809994
validation cost:0.174685537815 and validation accuracy:0.990875899792
Training on :(6, 7)
training cost:0.0903013423085 and training accuracy:0.994949042797
validation cost:0.0866467058659 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.062677077949 and training accuracy:0.996572554111
validation cost:0.0600031837821 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0491562448442 and training accuracy:0.996933341026
validation cost:0.0469324961305 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0410058163106 and training accuracy:0.997474491596
validation cost:0.0390345640481 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0354912020266 and training accuracy:0.998015701771
validation cost:0.0336788743734 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0314780808985 and training accuracy:0.998286306858
validation cost:0.0297761932015 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0284055974334 and training accuracy:0.998647093773
validation cost:0.0267875473946 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0259653311223 and training accuracy:0.9987372756
validation cost:0.0244144108146 and validation accuracy:1.0
Training on :(6, 7)
Time taken:142.273164988
Method 3 test accuracy:0.979669034481
Method 3 test accuracy:0.913320302963
Method 3 test accuracy:0.637139797211
Method 3 test accuracy:0.898288011551
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.255680799484 and training accuracy:0.958372116089
validation cost:0.254788398743 and validation accuracy:0.956685483456
Training on :(8, 9)
training cost:0.16110919416 and training accuracy:0.966846704483
validation cost:0.160866171122 and validation accuracy:0.966101706028
Training on :(8, 9)
training cost:0.127051204443 and training accuracy:0.971316814423
validation cost:0.127190053463 and validation accuracy:0.973634660244
Training on :(8, 9)
training cost:0.108426086605 and training accuracy:0.974762499332
validation cost:0.10868921876 and validation accuracy:0.97834277153
Training on :(8, 9)
training cost:0.0961693301797 and training accuracy:0.977556347847
validation cost:0.0964180156589 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.0872531831264 and training accuracy:0.979046404362
validation cost:0.0874202102423 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.0803530737758 and training accuracy:0.980350136757
validation cost:0.0804040357471 and validation accuracy:0.98399245739
Training on :(8, 9)
training cost:0.0747895091772 and training accuracy:0.981747090816
validation cost:0.0747105628252 and validation accuracy:0.98399245739
Training on :(8, 9)
training cost:0.0701697543263 and training accuracy:0.982864618301
validation cost:0.0699551552534 and validation accuracy:0.985875725746
Training on :(8, 9)
Time taken:138.601001024
Method 3 test accuracy:0.980141818523
Method 3 test accuracy:0.890303611755
Method 3 test accuracy:0.557097136974
Method 3 test accuracy:0.885699927807
Method 3 test accuracy:0.690872430801
Training with lmbda:20308059.8423, 5
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.185739651322 and training accuracy:0.997744202614
validation cost:0.182639792562 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0555005222559 and training accuracy:0.998004496098
validation cost:0.0558135248721 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0318333655596 and training accuracy:0.998178005219
validation cost:0.0327127352357 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0225480105728 and training accuracy:0.998525083065
validation cost:0.0235897265375 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0176233183593 and training accuracy:0.998611807823
validation cost:0.0187160409987 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0145617239177 and training accuracy:0.998698592186
validation cost:0.0156639441848 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0124643230811 and training accuracy:0.998785376549
validation cost:0.0135588338599 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0109299588948 and training accuracy:0.998872101307
validation cost:0.0120089538395 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.00975448638201 and training accuracy:0.99895888567
validation cost:0.0108137615025 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:148.96231699
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.35212662816 and training accuracy:0.943368792534
validation cost:0.357444226742 and validation accuracy:0.945772051811
Training on :(2, 3)
training cost:0.177647516131 and training accuracy:0.96136713028
validation cost:0.183137059212 and validation accuracy:0.958639681339
Training on :(2, 3)
training cost:0.124100856483 and training accuracy:0.969820916653
validation cost:0.130347877741 and validation accuracy:0.967830896378
Training on :(2, 3)
training cost:0.0978837013245 and training accuracy:0.975365877151
validation cost:0.104327149689 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0819756239653 and training accuracy:0.978820085526
validation cost:0.0882209613919 and validation accuracy:0.976102948189
Training on :(2, 3)
training cost:0.0711326226592 and training accuracy:0.982183456421
validation cost:0.0769984424114 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0631815940142 and training accuracy:0.984365046024
validation cost:0.0686035975814 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0570554696023 and training accuracy:0.985819458961
validation cost:0.0620273575187 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0521598756313 and training accuracy:0.987637460232
validation cost:0.0567009449005 and validation accuracy:0.983455896378
Training on :(2, 3)
Time taken:141.468849897
Method 3 test accuracy:0.986761212349
Method 3 test accuracy:0.931439757347
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.261134684086 and training accuracy:0.978731691837
validation cost:0.262374013662 and validation accuracy:0.984205305576
Training on :(4, 5)
training cost:0.134546250105 and training accuracy:0.989658534527
validation cost:0.1297775805 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0916891172528 and training accuracy:0.99317073822
validation cost:0.0850783661008 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.0703999921679 and training accuracy:0.994731724262
validation cost:0.0632714182138 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0576602332294 and training accuracy:0.995317101479
validation cost:0.0504612736404 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0491508543491 and training accuracy:0.995609760284
validation cost:0.0420504882932 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0430406779051 and training accuracy:0.996097564697
validation cost:0.0361065194011 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0384224653244 and training accuracy:0.996682941914
validation cost:0.0316801778972 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0347974598408 and training accuracy:0.996682941914
validation cost:0.0282531511039 and validation accuracy:1.0
Training on :(4, 5)
Time taken:131.436768055
Method 3 test accuracy:0.984397172928
Method 3 test accuracy:0.927032291889
Method 3 test accuracy:0.663820683956
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.185489490628 and training accuracy:0.991160809994
validation cost:0.178923368454 and validation accuracy:0.990875899792
Training on :(6, 7)
training cost:0.093205049634 and training accuracy:0.994768619537
validation cost:0.0895039215684 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0649131685495 and training accuracy:0.996482372284
validation cost:0.0622061230242 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0509907305241 and training accuracy:0.996933341026
validation cost:0.0487465746701 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0425688959658 and training accuracy:0.997203946114
validation cost:0.0405863039196 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0368575826287 and training accuracy:0.997925519943
validation cost:0.0350403003395 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0326937139034 and training accuracy:0.998286306858
validation cost:0.0309910383075 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0295019410551 and training accuracy:0.998647093773
validation cost:0.0278861932456 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0269648525864 and training accuracy:0.9987372756
validation cost:0.0254183579236 and validation accuracy:1.0
Training on :(6, 7)
Time taken:143.014520884
Method 3 test accuracy:0.980141818523
Method 3 test accuracy:0.913810014725
Method 3 test accuracy:0.639274299145
Method 3 test accuracy:0.897784471512
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.261111527681 and training accuracy:0.958651542664
validation cost:0.260198682547 and validation accuracy:0.957627117634
Training on :(8, 9)
training cost:0.16512735188 and training accuracy:0.966753602028
validation cost:0.164811626077 and validation accuracy:0.966101706028
Training on :(8, 9)
training cost:0.130411729217 and training accuracy:0.971223711967
validation cost:0.130455523729 and validation accuracy:0.973634660244
Training on :(8, 9)
training cost:0.111426301301 and training accuracy:0.974203765392
validation cost:0.111596174538 and validation accuracy:0.97834277153
Training on :(8, 9)
training cost:0.098938241601 and training accuracy:0.977090716362
validation cost:0.0991047024727 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.089853733778 and training accuracy:0.978953242302
validation cost:0.0899532586336 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.0828255489469 and training accuracy:0.980070769787
validation cost:0.0828231796622 and validation accuracy:0.983050823212
Training on :(8, 9)
training cost:0.0771560743451 and training accuracy:0.981188297272
validation cost:0.0770375058055 and validation accuracy:0.98399245739
Training on :(8, 9)
training cost:0.0724416449666 and training accuracy:0.982585191727
validation cost:0.0721974596381 and validation accuracy:0.985875725746
Training on :(8, 9)
Time taken:137.723355055
Method 3 test accuracy:0.980141818523
Method 3 test accuracy:0.888834476471
Method 3 test accuracy:0.553361773491
Method 3 test accuracy:0.884692847729
Method 3 test accuracy:0.693393826485
Training with lmbda:15727241.7392, 6
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.187413960695 and training accuracy:0.997744202614
validation cost:0.185390353203 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.055508248508 and training accuracy:0.99809128046
validation cost:0.0561634711921 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0318361148238 and training accuracy:0.998438298702
validation cost:0.0328947417438 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0225540343672 and training accuracy:0.998698592186
validation cost:0.0237094499171 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0176254808903 and training accuracy:0.998785376549
validation cost:0.0187979545444 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0145592540503 and training accuracy:0.998785376549
validation cost:0.0157190151513 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.012457286939 and training accuracy:0.998872101307
validation cost:0.0135930338874 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0109200486913 and training accuracy:0.99895888567
validation cost:0.0120275393128 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0097421137616 and training accuracy:0.99895888567
validation cost:0.0108201066032 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:147.415590048
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.340752661228 and training accuracy:0.946004927158
validation cost:0.346165031195 and validation accuracy:0.943933844566
Training on :(2, 3)
training cost:0.171248853207 and training accuracy:0.962185263634
validation cost:0.177296757698 and validation accuracy:0.959558844566
Training on :(2, 3)
training cost:0.119591869414 and training accuracy:0.971457123756
validation cost:0.126456424594 and validation accuracy:0.965073525906
Training on :(2, 3)
training cost:0.0943179875612 and training accuracy:0.976729393005
validation cost:0.101320043206 and validation accuracy:0.966911792755
Training on :(2, 3)
training cost:0.0789759606123 and training accuracy:0.980274498463
validation cost:0.0856866016984 and validation accuracy:0.974264681339
Training on :(2, 3)
training cost:0.068519257009 and training accuracy:0.982637941837
validation cost:0.0747495293617 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0608498863876 and training accuracy:0.985183179379
validation cost:0.0665380880237 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0549381487072 and training accuracy:0.986546695232
validation cost:0.0600828565657 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0502098724246 and training accuracy:0.987546563148
validation cost:0.0548372939229 and validation accuracy:0.983455896378
Training on :(2, 3)
Time taken:141.685580015
Method 3 test accuracy:0.911111116409
Method 3 test accuracy:0.981880486012
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.252816915512 and training accuracy:0.980780482292
validation cost:0.255250185728 and validation accuracy:0.984205305576
Training on :(4, 5)
training cost:0.127606496215 and training accuracy:0.991512179375
validation cost:0.124103426933 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0862073898315 and training accuracy:0.994243919849
validation cost:0.0808745920658 and validation accuracy:0.99703848362
Training on :(4, 5)
training cost:0.0659366771579 and training accuracy:0.995024383068
validation cost:0.0600482337177 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0539088472724 and training accuracy:0.995609760284
validation cost:0.0478980652988 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0459156148136 and training accuracy:0.99590241909
validation cost:0.0399490632117 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0401929281652 and training accuracy:0.996390223503
validation cost:0.0343392118812 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.035876955837 and training accuracy:0.99658536911
validation cost:0.0301657058299 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0324926562607 and training accuracy:0.996780514717
validation cost:0.0269345734268 and validation accuracy:0.999012827873
Training on :(4, 5)
Time taken:132.702109098
Method 3 test accuracy:0.873286068439
Method 3 test accuracy:0.969147920609
Method 3 test accuracy:0.725186765194
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.17437338829 and training accuracy:0.993505895138
validation cost:0.168888062239 and validation accuracy:0.994525551796
Training on :(6, 7)
training cost:0.0854591652751 and training accuracy:0.996211767197
validation cost:0.0825332999229 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0589432567358 and training accuracy:0.997203946114
validation cost:0.0568282902241 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0460834428668 and training accuracy:0.997835278511
validation cost:0.0443283617496 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0383738800883 and training accuracy:0.998105883598
validation cost:0.036811619997 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0331782959402 and training accuracy:0.998286306858
validation cost:0.0317368507385 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.029407504946 and training accuracy:0.9987372756
validation cost:0.0280492696911 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0265272520483 and training accuracy:0.998827457428
validation cost:0.0252287033945 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.024244857952 and training accuracy:0.999098062515
validation cost:0.0229919031262 and validation accuracy:1.0
Training on :(6, 7)
Time taken:142.525810003
Method 3 test accuracy:0.713948011398
Method 3 test accuracy:0.947110652924
Method 3 test accuracy:0.702774822712
Method 3 test accuracy:0.94612288475
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.253346532583 and training accuracy:0.956137061119
validation cost:0.254331618547 and validation accuracy:0.951977372169
Training on :(8, 9)
training cost:0.160457342863 and training accuracy:0.965170443058
validation cost:0.162205025554 and validation accuracy:0.964218437672
Training on :(8, 9)
training cost:0.1268299371 and training accuracy:0.970478653908
validation cost:0.128964647651 and validation accuracy:0.96798491478
Training on :(8, 9)
training cost:0.108342528343 and training accuracy:0.973831236362
validation cost:0.110614523292 and validation accuracy:0.975517868996
Training on :(8, 9)
training cost:0.0961442142725 and training accuracy:0.976438820362
validation cost:0.098424077034 and validation accuracy:0.979284346104
Training on :(8, 9)
training cost:0.0872658342123 and training accuracy:0.977928876877
validation cost:0.0894851386547 and validation accuracy:0.979284346104
Training on :(8, 9)
training cost:0.0804036706686 and training accuracy:0.979884505272
validation cost:0.0825315117836 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.0748804137111 and training accuracy:0.981840193272
validation cost:0.0769015327096 and validation accuracy:0.983050823212
Training on :(8, 9)
training cost:0.0703023448586 and training accuracy:0.983609616756
validation cost:0.0722124278545 and validation accuracy:0.98399245739
Training on :(8, 9)
Time taken:139.004817963
Method 3 test accuracy:0.707801401615
Method 3 test accuracy:0.914299726486
Method 3 test accuracy:0.62433296442
Method 3 test accuracy:0.925478339195
Method 3 test accuracy:0.72516387701
Training with lmbda:17023113.8655, 7
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.187413960695 and training accuracy:0.997744202614
validation cost:0.185390353203 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.055508248508 and training accuracy:0.99809128046
validation cost:0.0561634711921 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0318361148238 and training accuracy:0.998438298702
validation cost:0.0328947417438 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0225540343672 and training accuracy:0.998698592186
validation cost:0.0237094499171 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0176254808903 and training accuracy:0.998785376549
validation cost:0.0187979545444 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0145592540503 and training accuracy:0.998785376549
validation cost:0.0157190151513 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.012457286939 and training accuracy:0.998872101307
validation cost:0.0135930338874 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0109200486913 and training accuracy:0.99895888567
validation cost:0.0120275393128 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0097421137616 and training accuracy:0.99895888567
validation cost:0.0108201066032 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:148.448962927
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.341046005487 and training accuracy:0.946004927158
validation cost:0.346460670233 and validation accuracy:0.943933844566
Training on :(2, 3)
training cost:0.171518683434 and training accuracy:0.962185263634
validation cost:0.177567347884 and validation accuracy:0.959558844566
Training on :(2, 3)
training cost:0.119824364781 and training accuracy:0.971457123756
validation cost:0.12668851018 and validation accuracy:0.965073525906
Training on :(2, 3)
training cost:0.0945284962654 and training accuracy:0.976820290089
validation cost:0.101531110704 and validation accuracy:0.966911792755
Training on :(2, 3)
training cost:0.079170756042 and training accuracy:0.980274498463
validation cost:0.085885129869 and validation accuracy:0.974264681339
Training on :(2, 3)
training cost:0.068700954318 and training accuracy:0.982637941837
validation cost:0.0749373659492 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0610218644142 and training accuracy:0.985183179379
validation cost:0.0667183697224 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0551011376083 and training accuracy:0.986546695232
validation cost:0.060255933553 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0503655709326 and training accuracy:0.987546563148
validation cost:0.0550049245358 and validation accuracy:0.983455896378
Training on :(2, 3)
Time taken:141.028844833
Method 3 test accuracy:0.910638272762
Method 3 test accuracy:0.981880486012
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.254437416792 and training accuracy:0.980780482292
validation cost:0.25692525506 and validation accuracy:0.984205305576
Training on :(4, 5)
training cost:0.128742620349 and training accuracy:0.991317093372
validation cost:0.125293314457 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0870480984449 and training accuracy:0.994243919849
validation cost:0.0817517116666 and validation accuracy:0.99703848362
Training on :(4, 5)
training cost:0.066596314311 and training accuracy:0.995024383068
validation cost:0.0607329495251 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0544498860836 and training accuracy:0.995609760284
validation cost:0.0484572388232 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0463732630014 and training accuracy:0.99590241909
validation cost:0.0404199436307 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.040589556098 and training accuracy:0.996292710304
validation cost:0.0347458571196 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0362267158926 and training accuracy:0.99658536911
validation cost:0.0305233318359 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0328060500324 and training accuracy:0.996780514717
validation cost:0.0272542573512 and validation accuracy:0.999012827873
Training on :(4, 5)
Time taken:132.341195107
Method 3 test accuracy:0.873758852482
Method 3 test accuracy:0.969147920609
Method 3 test accuracy:0.726787626743
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.176118642092 and training accuracy:0.99341571331
validation cost:0.170619770885 and validation accuracy:0.994525551796
Training on :(6, 7)
training cost:0.0866274237633 and training accuracy:0.996211767197
validation cost:0.0836933255196 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0598355270922 and training accuracy:0.997203946114
validation cost:0.0577178895473 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0468149520457 and training accuracy:0.997835278511
validation cost:0.0450606942177 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0389987714589 and training accuracy:0.997925519943
validation cost:0.0374398455024 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.033726722002 and training accuracy:0.998286306858
validation cost:0.0322899073362 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0298985037953 and training accuracy:0.9987372756
validation cost:0.0285453032702 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.026973888278 and training accuracy:0.998827457428
validation cost:0.0256802514195 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0246552601457 and training accuracy:0.999007821083
validation cost:0.0234072934836 and validation accuracy:1.0
Training on :(6, 7)
Time taken:142.248026133
Method 3 test accuracy:0.71111112833
Method 3 test accuracy:0.947600364685
Method 3 test accuracy:0.704909265041
Method 3 test accuracy:0.945619344711
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.255603343248 and training accuracy:0.955950856209
validation cost:0.256593793631 and validation accuracy:0.951977372169
Training on :(8, 9)
training cost:0.162157446146 and training accuracy:0.965077280998
validation cost:0.16389799118 and validation accuracy:0.964218437672
Training on :(8, 9)
training cost:0.128287032247 and training accuracy:0.970571815968
validation cost:0.130409166217 and validation accuracy:0.96798491478
Training on :(8, 9)
training cost:0.109670966864 and training accuracy:0.973831236362
validation cost:0.111932113767 and validation accuracy:0.975517868996
Training on :(8, 9)
training cost:0.0973930805922 and training accuracy:0.976438820362
validation cost:0.099666915834 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.0884562879801 and training accuracy:0.977835714817
validation cost:0.0906760916114 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.0815475508571 and training accuracy:0.979512035847
validation cost:0.0836813151836 and validation accuracy:0.98116761446
Training on :(8, 9)
training cost:0.0759838148952 and training accuracy:0.981560826302
validation cost:0.0780163928866 and validation accuracy:0.983050823212
Training on :(8, 9)
training cost:0.0713716372848 and training accuracy:0.983143985271
validation cost:0.0732995569706 and validation accuracy:0.98399245739
Training on :(8, 9)
Time taken:139.137070179
Method 3 test accuracy:0.704964518547
Method 3 test accuracy:0.914299726486
Method 3 test accuracy:0.62379938364
Method 3 test accuracy:0.923464238644
Method 3 test accuracy:0.727181017399
Training with lmbda:20308059.8423, 8
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.187413960695 and training accuracy:0.997744202614
validation cost:0.185390353203 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.055508248508 and training accuracy:0.99809128046
validation cost:0.0561634711921 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0318361148238 and training accuracy:0.998438298702
validation cost:0.0328947417438 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0225540343672 and training accuracy:0.998698592186
validation cost:0.0237094499171 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0176254808903 and training accuracy:0.998785376549
validation cost:0.0187979545444 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0145592540503 and training accuracy:0.998785376549
validation cost:0.0157190151513 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.012457286939 and training accuracy:0.998872101307
validation cost:0.0135930338874 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0109200486913 and training accuracy:0.99895888567
validation cost:0.0120275393128 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0097421137616 and training accuracy:0.99895888567
validation cost:0.0108201066032 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:148.21288991
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.341755717993 and training accuracy:0.946095824242
validation cost:0.347176373005 and validation accuracy:0.943933844566
Training on :(2, 3)
training cost:0.172163575888 and training accuracy:0.96209436655
validation cost:0.178213238716 and validation accuracy:0.959558844566
Training on :(2, 3)
training cost:0.120377361774 and training accuracy:0.971457123756
validation cost:0.127239897847 and validation accuracy:0.965073525906
Training on :(2, 3)
training cost:0.0950237959623 and training accuracy:0.976820290089
validation cost:0.102027781308 and validation accuracy:0.966911792755
Training on :(2, 3)
training cost:0.0796268731356 and training accuracy:0.980274498463
validation cost:0.0863504260778 and validation accuracy:0.974264681339
Training on :(2, 3)
training cost:0.0691260248423 and training accuracy:0.982637941837
validation cost:0.0753769204021 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0614219605923 and training accuracy:0.985183179379
validation cost:0.0671381056309 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0554797649384 and training accuracy:0.986546695232
validation cost:0.0606590099633 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0507265329361 and training accuracy:0.987637460232
validation cost:0.0553932525218 and validation accuracy:0.983455896378
Training on :(2, 3)
Time taken:141.98467207
Method 3 test accuracy:0.911583900452
Method 3 test accuracy:0.981880486012
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.258182197809 and training accuracy:0.980780482292
validation cost:0.260794878006 and validation accuracy:0.983218193054
Training on :(4, 5)
training cost:0.131349310279 and training accuracy:0.991219520569
validation cost:0.128024578094 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0889693796635 and training accuracy:0.994243919849
validation cost:0.0837584584951 and validation accuracy:0.99703848362
Training on :(4, 5)
training cost:0.0680993795395 and training accuracy:0.994829297066
validation cost:0.0622948408127 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0556802526116 and training accuracy:0.995609760284
validation cost:0.0497301705182 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0474129021168 and training accuracy:0.99590241909
validation cost:0.0414911806583 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0414903797209 and training accuracy:0.996292710304
validation cost:0.0356711037457 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0370219796896 and training accuracy:0.99658536911
validation cost:0.0313373617828 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.033518332988 and training accuracy:0.996780514717
validation cost:0.0279814489186 and validation accuracy:0.999012827873
Training on :(4, 5)
Time taken:132.808535099
Method 3 test accuracy:0.875177323818
Method 3 test accuracy:0.969147920609
Method 3 test accuracy:0.730522930622
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.180256262422 and training accuracy:0.993325531483
validation cost:0.174731343985 and validation accuracy:0.994525551796
Training on :(6, 7)
training cost:0.0893690958619 and training accuracy:0.996211767197
validation cost:0.0864199846983 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0619179792702 and training accuracy:0.997113764286
validation cost:0.0597974061966 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0485129095614 and training accuracy:0.997835278511
validation cost:0.0467637479305 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0404436141253 and training accuracy:0.997925519943
validation cost:0.0388954132795 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.034991774708 and training accuracy:0.998196065426
validation cost:0.0335683040321 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0310294236988 and training accuracy:0.998647093773
validation cost:0.0296899620444 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.027999650687 and training accuracy:0.998827457428
validation cost:0.0267201922834 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0255970638245 and training accuracy:0.998917639256
validation cost:0.0243630968034 and validation accuracy:0.999087572098
Training on :(6, 7)
Time taken:142.53430295
Method 3 test accuracy:0.751773059368
Method 3 test accuracy:0.952007830143
Method 3 test accuracy:0.716115236282
Method 3 test accuracy:0.93152064085
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.260945081711 and training accuracy:0.956043958664
validation cost:0.261939466 and validation accuracy:0.952919006348
Training on :(8, 9)
training cost:0.166202738881 and training accuracy:0.964332282543
validation cost:0.16792562604 and validation accuracy:0.96233522892
Training on :(8, 9)
training cost:0.131745100021 and training accuracy:0.969826757908
validation cost:0.133841663599 and validation accuracy:0.96798491478
Training on :(8, 9)
training cost:0.112812206149 and training accuracy:0.973738133907
validation cost:0.115049436688 and validation accuracy:0.975517868996
Training on :(8, 9)
training cost:0.100329563022 and training accuracy:0.976345717907
validation cost:0.102590560913 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.0912450551987 and training accuracy:0.977649450302
validation cost:0.0934680253267 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.0842194929719 and training accuracy:0.979046404362
validation cost:0.0863733515143 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.0785583928227 and training accuracy:0.981002032757
validation cost:0.0806257724762 and validation accuracy:0.983050823212
Training on :(8, 9)
training cost:0.0738577991724 and training accuracy:0.982678353786
validation cost:0.0758314207196 and validation accuracy:0.98399245739
Training on :(8, 9)
Time taken:139.171004057
Method 3 test accuracy:0.741843998432
Method 3 test accuracy:0.916748285294
Method 3 test accuracy:0.626467466354
Method 3 test accuracy:0.897280991077
Method 3 test accuracy:0.765002548695
Training with lmbda:15727241.7392, 9
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.183363392949 and training accuracy:0.997657477856
validation cost:0.181296974421 and validation accuracy:0.996488153934
Training on :(0, 1)
training cost:0.0548925288022 and training accuracy:0.998178005219
validation cost:0.0557739771903 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0315684601665 and training accuracy:0.998438298702
validation cost:0.0329111069441 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0224072262645 and training accuracy:0.998525083065
validation cost:0.0238557700068 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0175414085388 and training accuracy:0.998611807823
validation cost:0.0189981702715 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0145130045712 and training accuracy:0.998872101307
validation cost:0.0159453377128 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0124365072697 and training accuracy:0.99895888567
validation cost:0.0138321891427 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0109167657793 and training accuracy:0.999045610428
validation cost:0.0122721334919 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.00975155737251 and training accuracy:0.999132394791
validation cost:0.0110663883388 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:147.481623173
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.338620513678 and training accuracy:0.944459617138
validation cost:0.343336373568 and validation accuracy:0.949448525906
Training on :(2, 3)
training cost:0.172939956188 and training accuracy:0.963276088238
validation cost:0.177286371589 and validation accuracy:0.959558844566
Training on :(2, 3)
training cost:0.121390372515 and training accuracy:0.972002565861
validation cost:0.126292139292 and validation accuracy:0.965073525906
Training on :(2, 3)
training cost:0.0959479659796 and training accuracy:0.976547598839
validation cost:0.100996606052 and validation accuracy:0.972426474094
Training on :(2, 3)
training cost:0.0804657116532 and training accuracy:0.979183733463
validation cost:0.0853452906013 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0698976665735 and training accuracy:0.982547044754
validation cost:0.0744592472911 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0621486194432 and training accuracy:0.984728634357
validation cost:0.066342048347 and validation accuracy:0.983455896378
Training on :(2, 3)
training cost:0.0561765432358 and training accuracy:0.986728489399
validation cost:0.0599981881678 and validation accuracy:0.985294103622
Training on :(2, 3)
training cost:0.0514021106064 and training accuracy:0.987819314003
validation cost:0.0548620708287 and validation accuracy:0.986213207245
Training on :(2, 3)
Time taken:141.978896856
Method 3 test accuracy:0.982505917549
Method 3 test accuracy:0.941723823547
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.254639536142 and training accuracy:0.980585336685
validation cost:0.257222384214 and validation accuracy:0.98617964983
Training on :(4, 5)
training cost:0.12946665287 and training accuracy:0.989853680134
validation cost:0.125826478004 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0879476815462 and training accuracy:0.993365824223
validation cost:0.0822444185615 and validation accuracy:0.99703848362
Training on :(4, 5)
training cost:0.0675543695688 and training accuracy:0.994341492653
validation cost:0.0611557886004 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0554227866232 and training accuracy:0.995219528675
validation cost:0.0488217324018 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0473432950675 and training accuracy:0.995512187481
validation cost:0.0407414510846 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0415477156639 and training accuracy:0.995999991894
validation cost:0.035036355257 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0371683426201 and training accuracy:0.996195137501
validation cost:0.0307877790183 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0337294973433 and training accuracy:0.996487796307
validation cost:0.0274976976216 and validation accuracy:1.0
Training on :(4, 5)
Time taken:132.157408953
Method 3 test accuracy:0.974468111992
Method 3 test accuracy:0.888834476471
Method 3 test accuracy:0.86125934124
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.180687367916 and training accuracy:0.992333352566
validation cost:0.175184339285 and validation accuracy:0.989963531494
Training on :(6, 7)
training cost:0.0885862186551 and training accuracy:0.996031403542
validation cost:0.0859804525971 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0609808526933 and training accuracy:0.997113764286
validation cost:0.0593351460993 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0475841835141 and training accuracy:0.997835278511
validation cost:0.0463620051742 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0395648255944 and training accuracy:0.998196065426
validation cost:0.0385678224266 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0341734439135 and training accuracy:0.9987372756
validation cost:0.0333115570247 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0302707999945 and training accuracy:0.998827457428
validation cost:0.0294982884079 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0272972565144 and training accuracy:0.999007821083
validation cost:0.0265884548426 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0249455142766 and training accuracy:0.999188244343
validation cost:0.0242845341563 and validation accuracy:1.0
Training on :(6, 7)
Time taken:143.066426039
Method 3 test accuracy:0.971631228924
Method 3 test accuracy:0.881488740444
Method 3 test accuracy:0.853255093098
Method 3 test accuracy:0.858006060123
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.261295944452 and training accuracy:0.954833328724
validation cost:0.262523651123 and validation accuracy:0.950094163418
Training on :(8, 9)
training cost:0.164767608047 and training accuracy:0.963214755058
validation cost:0.1667765975 and validation accuracy:0.960451960564
Training on :(8, 9)
training cost:0.129823192954 and training accuracy:0.968616127968
validation cost:0.132133126259 and validation accuracy:0.963276863098
Training on :(8, 9)
training cost:0.110638946295 and training accuracy:0.972248077393
validation cost:0.112984202802 and validation accuracy:0.969868183136
Training on :(8, 9)
training cost:0.0979976654053 and training accuracy:0.975693821907
validation cost:0.100261271 and validation accuracy:0.97834277153
Training on :(8, 9)
training cost:0.0888099595904 and training accuracy:0.978021979332
validation cost:0.0909375697374 and validation accuracy:0.98116761446
Training on :(8, 9)
training cost:0.0817153677344 and training accuracy:0.979977667332
validation cost:0.0836841985583 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.0760087147355 and training accuracy:0.981747090816
validation cost:0.0778097063303 and validation accuracy:0.983050823212
Training on :(8, 9)
training cost:0.0712835937738 and training accuracy:0.982398927212
validation cost:0.0729207620025 and validation accuracy:0.983050823212
Training on :(8, 9)
Time taken:137.532761097
Method 3 test accuracy:0.971158385277
Method 3 test accuracy:0.856023490429
Method 3 test accuracy:0.832977592945
Method 3 test accuracy:0.832326292992
Method 3 test accuracy:0.700958132744
Training with lmbda:17023113.8655, 10
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.183363392949 and training accuracy:0.997657477856
validation cost:0.181296974421 and validation accuracy:0.996488153934
Training on :(0, 1)
training cost:0.0548925288022 and training accuracy:0.998178005219
validation cost:0.0557739771903 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0315684601665 and training accuracy:0.998438298702
validation cost:0.0329111069441 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0224072262645 and training accuracy:0.998525083065
validation cost:0.0238557700068 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0175414085388 and training accuracy:0.998611807823
validation cost:0.0189981702715 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0145130045712 and training accuracy:0.998872101307
validation cost:0.0159453377128 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0124365072697 and training accuracy:0.99895888567
validation cost:0.0138321891427 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0109167657793 and training accuracy:0.999045610428
validation cost:0.0122721334919 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.00975155737251 and training accuracy:0.999132394791
validation cost:0.0110663883388 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:147.924606085
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.338952183723 and training accuracy:0.944550514221
validation cost:0.343667805195 and validation accuracy:0.949448525906
Training on :(2, 3)
training cost:0.173248082399 and training accuracy:0.963276088238
validation cost:0.177594125271 and validation accuracy:0.959558844566
Training on :(2, 3)
training cost:0.121660545468 and training accuracy:0.972002565861
validation cost:0.126560032368 and validation accuracy:0.965073525906
Training on :(2, 3)
training cost:0.0961935594678 and training accuracy:0.976456701756
validation cost:0.101239517331 and validation accuracy:0.972426474094
Training on :(2, 3)
training cost:0.0806930884719 and training accuracy:0.97909283638
validation cost:0.0855714157224 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0701110959053 and training accuracy:0.982456147671
validation cost:0.0746728479862 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0623492859304 and training accuracy:0.984637737274
validation cost:0.0665445774794 and validation accuracy:0.983455896378
Training on :(2, 3)
training cost:0.0563663803041 and training accuracy:0.986728489399
validation cost:0.060190692544 and validation accuracy:0.985294103622
Training on :(2, 3)
training cost:0.0515822917223 and training accuracy:0.987819314003
validation cost:0.0550452545285 and validation accuracy:0.986213207245
Training on :(2, 3)
Time taken:141.245598793
Method 3 test accuracy:0.982505917549
Method 3 test accuracy:0.941723823547
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.256345063448 and training accuracy:0.980585336685
validation cost:0.258987039328 and validation accuracy:0.98617964983
Training on :(4, 5)
training cost:0.130676999688 and training accuracy:0.989853680134
validation cost:0.127095550299 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0888583958149 and training accuracy:0.993365824223
validation cost:0.0831955596805 and validation accuracy:0.99703848362
Training on :(4, 5)
training cost:0.0682802796364 and training accuracy:0.994243919849
validation cost:0.0619091652334 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0560254752636 and training accuracy:0.995121955872
validation cost:0.0494434535503 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0478582121432 and training accuracy:0.995512187481
validation cost:0.0412699617445 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0419985540211 and training accuracy:0.995999991894
validation cost:0.0354965552688 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0375695377588 and training accuracy:0.996195137501
validation cost:0.0311951190233 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0340912416577 and training accuracy:0.996487796307
validation cost:0.0278633832932 and validation accuracy:1.0
Training on :(4, 5)
Time taken:132.339101791
Method 3 test accuracy:0.974468111992
Method 3 test accuracy:0.889324188232
Method 3 test accuracy:0.860725700855
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.182526126504 and training accuracy:0.992333352566
validation cost:0.177022621036 and validation accuracy:0.989963531494
Training on :(6, 7)
training cost:0.0898196846247 and training accuracy:0.996031403542
validation cost:0.0872099176049 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0619307234883 and training accuracy:0.997023522854
validation cost:0.0602845437825 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0483700670302 and training accuracy:0.997835278511
validation cost:0.0471511818469 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0402417778969 and training accuracy:0.998196065426
validation cost:0.0392513014376 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0347719751298 and training accuracy:0.998647093773
validation cost:0.0339184887707 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0308100692928 and training accuracy:0.998827457428
validation cost:0.0300468318164 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0277894996107 and training accuracy:0.998917639256
validation cost:0.0270905736834 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0253996066749 and training accuracy:0.999188244343
validation cost:0.0247490536422 and validation accuracy:1.0
Training on :(6, 7)
Time taken:142.413972139
Method 3 test accuracy:0.971631228924
Method 3 test accuracy:0.882957875729
Method 3 test accuracy:0.853255093098
Method 3 test accuracy:0.857502520084
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.26380443573 and training accuracy:0.954740166664
validation cost:0.26502469182 and validation accuracy:0.950094163418
Training on :(8, 9)
training cost:0.166591718793 and training accuracy:0.963121652603
validation cost:0.168582513928 and validation accuracy:0.95951038599
Training on :(8, 9)
training cost:0.131349012256 and training accuracy:0.968616127968
validation cost:0.133639410138 and validation accuracy:0.96233522892
Training on :(8, 9)
training cost:0.112006857991 and training accuracy:0.972248077393
validation cost:0.114335544407 and validation accuracy:0.969868183136
Training on :(8, 9)
training cost:0.0992622300982 and training accuracy:0.975507557392
validation cost:0.101515226066 and validation accuracy:0.97834277153
Training on :(8, 9)
training cost:0.0900005698204 and training accuracy:0.977556347847
validation cost:0.0921251401305 and validation accuracy:0.979284346104
Training on :(8, 9)
training cost:0.0828478783369 and training accuracy:0.979884505272
validation cost:0.0848201587796 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.0770943909883 and training accuracy:0.981374561787
validation cost:0.078905723989 and validation accuracy:0.983050823212
Training on :(8, 9)
training cost:0.0723268911242 and training accuracy:0.982305824757
validation cost:0.0739797353745 and validation accuracy:0.983050823212
Training on :(8, 9)
Time taken:138.047262192
Method 3 test accuracy:0.971158385277
Method 3 test accuracy:0.854554355145
Method 3 test accuracy:0.834578454494
Method 3 test accuracy:0.830815732479
Method 3 test accuracy:0.702471017838
Training with lmbda:20308059.8423, 11
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.183363392949 and training accuracy:0.997657477856
validation cost:0.181296974421 and validation accuracy:0.996488153934
Training on :(0, 1)
training cost:0.0548925288022 and training accuracy:0.998178005219
validation cost:0.0557739771903 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0315684601665 and training accuracy:0.998438298702
validation cost:0.0329111069441 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0224072262645 and training accuracy:0.998525083065
validation cost:0.0238557700068 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0175414085388 and training accuracy:0.998611807823
validation cost:0.0189981702715 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0145130045712 and training accuracy:0.998872101307
validation cost:0.0159453377128 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0124365072697 and training accuracy:0.99895888567
validation cost:0.0138321891427 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0109167657793 and training accuracy:0.999045610428
validation cost:0.0122721334919 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.00975155737251 and training accuracy:0.999132394791
validation cost:0.0110663883388 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:147.949144125
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.339752823114 and training accuracy:0.944459617138
validation cost:0.344468176365 and validation accuracy:0.948529422283
Training on :(2, 3)
training cost:0.173989638686 and training accuracy:0.963276088238
validation cost:0.178334102035 and validation accuracy:0.959558844566
Training on :(2, 3)
training cost:0.122301615775 and training accuracy:0.972002565861
validation cost:0.127194702625 and validation accuracy:0.965073525906
Training on :(2, 3)
training cost:0.0967734754086 and training accuracy:0.976456701756
validation cost:0.101813696325 and validation accuracy:0.972426474094
Training on :(2, 3)
training cost:0.0812279507518 and training accuracy:0.979183733463
validation cost:0.0861025229096 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0706099793315 and training accuracy:0.982456147671
validation cost:0.0751713588834 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.062818236649 and training accuracy:0.984728634357
validation cost:0.0670166760683 and validation accuracy:0.984375
Training on :(2, 3)
training cost:0.0568092092872 and training accuracy:0.986728489399
validation cost:0.0606398172677 and validation accuracy:0.985294103622
Training on :(2, 3)
training cost:0.0520026311278 and training accuracy:0.987819314003
validation cost:0.0554734617472 and validation accuracy:0.986213207245
Training on :(2, 3)
Time taken:141.668229818
Method 3 test accuracy:0.982505917549
Method 3 test accuracy:0.941723823547
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.260297685862 and training accuracy:0.980292677879
validation cost:0.263073861599 and validation accuracy:0.985192477703
Training on :(4, 5)
training cost:0.133474901319 and training accuracy:0.98975610733
validation cost:0.130032107234 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0909538716078 and training accuracy:0.993268311024
validation cost:0.0853874310851 and validation accuracy:0.99703848362
Training on :(4, 5)
training cost:0.0699455887079 and training accuracy:0.994048774242
validation cost:0.0636407732964 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0574039407074 and training accuracy:0.995024383068
validation cost:0.0508687645197 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0490346699953 and training accuracy:0.995414614677
validation cost:0.0424806959927 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0430259369314 and training accuracy:0.99590241909
validation cost:0.036548383534 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0384824313223 and training accuracy:0.996195137501
validation cost:0.032125428319 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0349130406976 and training accuracy:0.996487796307
validation cost:0.0286968778819 and validation accuracy:1.0
Training on :(4, 5)
Time taken:133.015140057
Method 3 test accuracy:0.974468111992
Method 3 test accuracy:0.888344764709
Method 3 test accuracy:0.861792981625
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.186873078346 and training accuracy:0.992333352566
validation cost:0.181367501616 and validation accuracy:0.989963531494
Training on :(6, 7)
training cost:0.0927338898182 and training accuracy:0.996031403542
validation cost:0.0901155993342 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0641701593995 and training accuracy:0.996933341026
validation cost:0.0625237524509 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0502169877291 and training accuracy:0.997835278511
validation cost:0.0490062311292 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0418314933777 and training accuracy:0.998105883598
validation cost:0.0408554300666 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0361766181886 and training accuracy:0.998466670513
validation cost:0.0353420041502 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0320731960237 and training accuracy:0.998827457428
validation cost:0.0313320830464 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0289420131594 and training accuracy:0.998827457428
validation cost:0.0282669644803 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0264616496861 and training accuracy:0.999188244343
validation cost:0.0258360132575 and validation accuracy:1.0
Training on :(6, 7)
Time taken:143.692008018
Method 3 test accuracy:0.971631228924
Method 3 test accuracy:0.882468163967
Method 3 test accuracy:0.855923175812
Method 3 test accuracy:0.855991959572
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.269758880138 and training accuracy:0.954553902149
validation cost:0.270961105824 and validation accuracy:0.948210895061
Training on :(8, 9)
training cost:0.170923098922 and training accuracy:0.963121652603
validation cost:0.172872379422 and validation accuracy:0.960451960564
Training on :(8, 9)
training cost:0.134950906038 and training accuracy:0.967964231968
validation cost:0.137197613716 and validation accuracy:0.96233522892
Training on :(8, 9)
training cost:0.115212455392 and training accuracy:0.971503078938
validation cost:0.117508493364 and validation accuracy:0.969868183136
Training on :(8, 9)
training cost:0.102219298482 and training accuracy:0.974669396877
validation cost:0.10445342958 and validation accuracy:0.975517868996
Training on :(8, 9)
training cost:0.0927780792117 and training accuracy:0.976904451847
validation cost:0.0948967337608 and validation accuracy:0.979284346104
Training on :(8, 9)
training cost:0.0854862332344 and training accuracy:0.979139506817
validation cost:0.0874650403857 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.0796180963516 and training accuracy:0.981002032757
validation cost:0.0814503580332 and validation accuracy:0.983050823212
Training on :(8, 9)
training cost:0.0747537910938 and training accuracy:0.981933295727
validation cost:0.076438434422 and validation accuracy:0.982109248638
Training on :(8, 9)
Time taken:137.763180017
Method 3 test accuracy:0.971158385277
Method 3 test accuracy:0.854554355145
Method 3 test accuracy:0.836179316044
Method 3 test accuracy:0.829808652401
Method 3 test accuracy:0.702975273132
Training with lmbda:15727241.7392, 12
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.185201182961 and training accuracy:0.997483968735
validation cost:0.183476597071 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0560917071998 and training accuracy:0.99809128046
validation cost:0.0573302432895 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0324285849929 and training accuracy:0.998264789581
validation cost:0.0341561622918 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0230844113976 and training accuracy:0.998351573944
validation cost:0.0249240230769 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0181016530842 and training accuracy:0.998525083065
validation cost:0.019950889051 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0149912079796 and training accuracy:0.998611807823
validation cost:0.0168148633093 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0128520894796 and training accuracy:0.998785376549
validation cost:0.014636320062 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0112824933603 and training accuracy:0.99895888567
validation cost:0.013022984378 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0100769754499 and training accuracy:0.99895888567
validation cost:0.0117728943005 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:148.593173027
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.343936920166 and training accuracy:0.940278172493
validation cost:0.348930180073 and validation accuracy:0.946691155434
Training on :(2, 3)
training cost:0.175957992673 and training accuracy:0.960367262363
validation cost:0.180168628693 and validation accuracy:0.960477948189
Training on :(2, 3)
training cost:0.122966617346 and training accuracy:0.970548152924
validation cost:0.127545312047 and validation accuracy:0.966911792755
Training on :(2, 3)
training cost:0.0969190150499 and training accuracy:0.975820362568
validation cost:0.101559102535 and validation accuracy:0.972426474094
Training on :(2, 3)
training cost:0.0811697915196 and training accuracy:0.97963821888
validation cost:0.0856051668525 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0704824924469 and training accuracy:0.982092559338
validation cost:0.0745921880007 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0626688078046 and training accuracy:0.984001457691
validation cost:0.066415078938 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0566582232714 and training accuracy:0.985183179379
validation cost:0.0600440502167 and validation accuracy:0.982536792755
Training on :(2, 3)
training cost:0.0518608912826 and training accuracy:0.986819386482
validation cost:0.0549061372876 and validation accuracy:0.982536792755
Training on :(2, 3)
Time taken:141.415756941
Method 3 test accuracy:0.98581558466
Method 3 test accuracy:0.926542580128
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.252016782761 and training accuracy:0.981463432312
validation cost:0.254400581121 and validation accuracy:0.987166821957
Training on :(4, 5)
training cost:0.129206001759 and training accuracy:0.989951193333
validation cost:0.125311806798 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0880142152309 and training accuracy:0.993463397026
validation cost:0.082148373127 and validation accuracy:0.99703848362
Training on :(4, 5)
training cost:0.0676621869206 and training accuracy:0.994536578655
validation cost:0.0611645020545 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0555180050433 and training accuracy:0.995219528675
validation cost:0.0488528423011 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0474163666368 and training accuracy:0.995707333088
validation cost:0.0407685153186 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0416008606553 and training accuracy:0.995999991894
validation cost:0.0350502505898 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0372071787715 and training accuracy:0.996292710304
validation cost:0.0307894721627 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0337580963969 and training accuracy:0.996292710304
validation cost:0.0274881273508 and validation accuracy:1.0
Training on :(4, 5)
Time taken:132.829021931
Method 3 test accuracy:0.982033073902
Method 3 test accuracy:0.837414324284
Method 3 test accuracy:0.907150506973
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.180394008756 and training accuracy:0.991250991821
validation cost:0.175176277757 and validation accuracy:0.991788327694
Training on :(6, 7)
training cost:0.0893688574433 and training accuracy:0.995219647884
validation cost:0.0870900377631 and validation accuracy:0.993613123894
Training on :(6, 7)
training cost:0.0618132613599 and training accuracy:0.996482372284
validation cost:0.0604460015893 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0483268424869 and training accuracy:0.997203946114
validation cost:0.0473405495286 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.040200766176 and training accuracy:0.997654914856
validation cost:0.0393993966281 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0347086638212 and training accuracy:0.998105883598
validation cost:0.034004945308 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.030716182664 and training accuracy:0.998286306858
validation cost:0.0300678852946 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0276654958725 and training accuracy:0.998556852341
validation cost:0.0270499978215 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0252466835082 and training accuracy:0.998827457428
validation cost:0.0246519781649 and validation accuracy:0.999087572098
Training on :(6, 7)
Time taken:142.220252991
Method 3 test accuracy:0.979669034481
Method 3 test accuracy:0.824681699276
Method 3 test accuracy:0.903948783875
Method 3 test accuracy:0.871601223946
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.255086541176 and training accuracy:0.959862172604
validation cost:0.25465914607 and validation accuracy:0.961393594742
Training on :(8, 9)
training cost:0.158624261618 and training accuracy:0.967498600483
validation cost:0.158466935158 and validation accuracy:0.967043340206
Training on :(8, 9)
training cost:0.124066352844 and training accuracy:0.971782445908
validation cost:0.124055020511 and validation accuracy:0.974576294422
Training on :(8, 9)
training cost:0.105311982334 and training accuracy:0.974855661392
validation cost:0.105307303369 and validation accuracy:0.976459503174
Training on :(8, 9)
training cost:0.093071192503 and training accuracy:0.977463185787
validation cost:0.0930005013943 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.0842494592071 and training accuracy:0.980350136757
validation cost:0.0840768888593 and validation accuracy:0.983050823212
Training on :(8, 9)
training cost:0.0774855241179 and training accuracy:0.981840193272
validation cost:0.0771967023611 and validation accuracy:0.985875725746
Training on :(8, 9)
training cost:0.0720815435052 and training accuracy:0.982585191727
validation cost:0.0716746523976 and validation accuracy:0.985875725746
Training on :(8, 9)
training cost:0.0676313042641 and training accuracy:0.983330249786
validation cost:0.0671100988984 and validation accuracy:0.985875725746
Training on :(8, 9)
Time taken:138.372230053
Method 3 test accuracy:0.978250563145
Method 3 test accuracy:0.791870713234
Method 3 test accuracy:0.893276393414
Method 3 test accuracy:0.860523641109
Method 3 test accuracy:0.631870925426
Training with lmbda:17023113.8655, 13
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.185201182961 and training accuracy:0.997483968735
validation cost:0.183476597071 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0560917071998 and training accuracy:0.99809128046
validation cost:0.0573302432895 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0324285849929 and training accuracy:0.998264789581
validation cost:0.0341561622918 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0230844113976 and training accuracy:0.998351573944
validation cost:0.0249240230769 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0181016530842 and training accuracy:0.998525083065
validation cost:0.019950889051 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0149912079796 and training accuracy:0.998611807823
validation cost:0.0168148633093 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0128520894796 and training accuracy:0.998785376549
validation cost:0.014636320062 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0112824933603 and training accuracy:0.99895888567
validation cost:0.013022984378 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0100769754499 and training accuracy:0.99895888567
validation cost:0.0117728943005 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:147.709419012
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.344268679619 and training accuracy:0.940369069576
validation cost:0.349265784025 and validation accuracy:0.946691155434
Training on :(2, 3)
training cost:0.176273554564 and training accuracy:0.960367262363
validation cost:0.180487498641 and validation accuracy:0.960477948189
Training on :(2, 3)
training cost:0.123242400587 and training accuracy:0.970548152924
validation cost:0.127821266651 and validation accuracy:0.966911792755
Training on :(2, 3)
training cost:0.097169674933 and training accuracy:0.976002156734
validation cost:0.10180978477 and validation accuracy:0.972426474094
Training on :(2, 3)
training cost:0.0814024582505 and training accuracy:0.979547321796
validation cost:0.0858377441764 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0707012936473 and training accuracy:0.982001662254
validation cost:0.0748127400875 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0628756284714 and training accuracy:0.984001457691
validation cost:0.0666258409619 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0568550489843 and training accuracy:0.985092282295
validation cost:0.0602452456951 and validation accuracy:0.982536792755
Training on :(2, 3)
training cost:0.0520479418337 and training accuracy:0.986819386482
validation cost:0.0550985820591 and validation accuracy:0.982536792755
Training on :(2, 3)
Time taken:141.012712955
Method 3 test accuracy:0.98581558466
Method 3 test accuracy:0.926542580128
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.253702044487 and training accuracy:0.981073141098
validation cost:0.256149977446 and validation accuracy:0.98617964983
Training on :(4, 5)
training cost:0.130396261811 and training accuracy:0.98975610733
validation cost:0.126560777426 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0888969302177 and training accuracy:0.993463397026
validation cost:0.083071000874 and validation accuracy:0.99703848362
Training on :(4, 5)
training cost:0.0683594271541 and training accuracy:0.994536578655
validation cost:0.061889141798 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0560935772955 and training accuracy:0.995219528675
validation cost:0.0494475588202 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0479072965682 and training accuracy:0.995707333088
validation cost:0.0412733070552 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0420298017561 and training accuracy:0.995999991894
validation cost:0.0354897044599 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0375889353454 and training accuracy:0.996292710304
validation cost:0.0311790015548 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0341025404632 and training accuracy:0.996292710304
validation cost:0.0278382729739 and validation accuracy:1.0
Training on :(4, 5)
Time taken:132.970104933
Method 3 test accuracy:0.982033073902
Method 3 test accuracy:0.837904036045
Method 3 test accuracy:0.908217728138
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.182312637568 and training accuracy:0.991250991821
validation cost:0.177084326744 and validation accuracy:0.991788327694
Training on :(6, 7)
training cost:0.090602427721 and training accuracy:0.995129406452
validation cost:0.0883231163025 and validation accuracy:0.993613123894
Training on :(6, 7)
training cost:0.0627327635884 and training accuracy:0.996482372284
validation cost:0.0613741911948 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0490689836442 and training accuracy:0.997203946114
validation cost:0.0480970218778 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.040828846395 and training accuracy:0.997654914856
validation cost:0.0400449037552 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0352569073439 and training accuracy:0.998105883598
validation cost:0.0345728583634 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0312048904598 and training accuracy:0.998286306858
validation cost:0.0305773355067 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0281076934189 and training accuracy:0.998466670513
validation cost:0.0275132972747 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0256521515548 and training accuracy:0.9987372756
validation cost:0.0250787138939 and validation accuracy:0.999087572098
Training on :(6, 7)
Time taken:142.271375179
Method 3 test accuracy:0.979669034481
Method 3 test accuracy:0.825171411037
Method 3 test accuracy:0.903948783875
Method 3 test accuracy:0.871601223946
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.257417470217 and training accuracy:0.959955275059
validation cost:0.256968230009 and validation accuracy:0.961393594742
Training on :(8, 9)
training cost:0.1603230685 and training accuracy:0.967591702938
validation cost:0.160128772259 and validation accuracy:0.967043340206
Training on :(8, 9)
training cost:0.125490799546 and training accuracy:0.971968710423
validation cost:0.125436156988 and validation accuracy:0.974576294422
Training on :(8, 9)
training cost:0.106589615345 and training accuracy:0.974762499332
validation cost:0.106540009379 and validation accuracy:0.976459503174
Training on :(8, 9)
training cost:0.0942561551929 and training accuracy:0.977090716362
validation cost:0.0941424369812 and validation accuracy:0.979284346104
Training on :(8, 9)
training cost:0.0853682160378 and training accuracy:0.980070769787
validation cost:0.085158392787 and validation accuracy:0.983050823212
Training on :(8, 9)
training cost:0.078552596271 and training accuracy:0.981653928757
validation cost:0.0782314240932 and validation accuracy:0.985875725746
Training on :(8, 9)
training cost:0.0731062814593 and training accuracy:0.982585191727
validation cost:0.072671033442 and validation accuracy:0.985875725746
Training on :(8, 9)
training cost:0.0686202272773 and training accuracy:0.983237087727
validation cost:0.0680750533938 and validation accuracy:0.985875725746
Training on :(8, 9)
Time taken:137.638487816
Method 3 test accuracy:0.979196190834
Method 3 test accuracy:0.791870713234
Method 3 test accuracy:0.894343674183
Method 3 test accuracy:0.859516620636
Method 3 test accuracy:0.633383750916
Training with lmbda:20308059.8423, 14
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.185201182961 and training accuracy:0.997483968735
validation cost:0.183476597071 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0560917071998 and training accuracy:0.99809128046
validation cost:0.0573302432895 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0324285849929 and training accuracy:0.998264789581
validation cost:0.0341561622918 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0230844113976 and training accuracy:0.998351573944
validation cost:0.0249240230769 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0181016530842 and training accuracy:0.998525083065
validation cost:0.019950889051 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0149912079796 and training accuracy:0.998611807823
validation cost:0.0168148633093 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0128520894796 and training accuracy:0.998785376549
validation cost:0.014636320062 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0112824933603 and training accuracy:0.99895888567
validation cost:0.013022984378 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0100769754499 and training accuracy:0.99895888567
validation cost:0.0117728943005 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:147.638278008
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.34506726265 and training accuracy:0.940369069576
validation cost:0.350072622299 and validation accuracy:0.946691155434
Training on :(2, 3)
training cost:0.177021130919 and training accuracy:0.960367262363
validation cost:0.181242957711 and validation accuracy:0.960477948189
Training on :(2, 3)
training cost:0.123895063996 and training accuracy:0.97072994709
validation cost:0.128474265337 and validation accuracy:0.966911792755
Training on :(2, 3)
training cost:0.0977603569627 and training accuracy:0.975820362568
validation cost:0.102399893105 and validation accuracy:0.972426474094
Training on :(2, 3)
training cost:0.0819490849972 and training accuracy:0.97963821888
validation cost:0.0863841250539 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0712118670344 and training accuracy:0.982001662254
validation cost:0.0753260776401 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.063357077539 and training accuracy:0.984092354774
validation cost:0.0671124607325 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0573120489717 and training accuracy:0.985092282295
validation cost:0.0607099197805 and validation accuracy:0.982536792755
Training on :(2, 3)
training cost:0.0524827875197 and training accuracy:0.986546695232
validation cost:0.0555423647165 and validation accuracy:0.982536792755
Training on :(2, 3)
Time taken:141.213805199
Method 3 test accuracy:0.98581558466
Method 3 test accuracy:0.926542580128
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.257583737373 and training accuracy:0.980780482292
validation cost:0.260180473328 and validation accuracy:0.98617964983
Training on :(4, 5)
training cost:0.133125379682 and training accuracy:0.989658534527
validation cost:0.129429534078 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0909217000008 and training accuracy:0.993365824223
validation cost:0.0851906314492 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0699565336108 and training accuracy:0.994536578655
validation cost:0.0635514482856 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0574119538069 and training accuracy:0.995219528675
validation cost:0.0508132614195 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0490309298038 and training accuracy:0.995707333088
validation cost:0.0424316525459 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0430103801191 and training accuracy:0.995999991894
validation cost:0.0364963300526 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0384608097374 and training accuracy:0.996292710304
validation cost:0.0320703051984 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0348886959255 and training accuracy:0.996390223503
validation cost:0.0286393873394 and validation accuracy:1.0
Training on :(4, 5)
Time taken:131.220236063
Method 3 test accuracy:0.982033073902
Method 3 test accuracy:0.838883459568
Method 3 test accuracy:0.908217728138
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.186796694994 and training accuracy:0.991250991821
validation cost:0.181543558836 and validation accuracy:0.991788327694
Training on :(6, 7)
training cost:0.0934761092067 and training accuracy:0.995039224625
validation cost:0.0911981388927 and validation accuracy:0.993613123894
Training on :(6, 7)
training cost:0.0648666918278 and training accuracy:0.996482372284
validation cost:0.0635312646627 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0507887974381 and training accuracy:0.997113764286
validation cost:0.0498521737754 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0422831699252 and training accuracy:0.997654914856
validation cost:0.0415422357619 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0365258231759 and training accuracy:0.998015701771
validation cost:0.0358896367252 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0323359109461 and training accuracy:0.998286306858
validation cost:0.0317588336766 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0291315838695 and training accuracy:0.998466670513
validation cost:0.0285893920809 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0265895333141 and training accuracy:0.998647093773
validation cost:0.02606767416 and validation accuracy:0.999087572098
Training on :(6, 7)
Time taken:142.496354103
Method 3 test accuracy:0.979196190834
Method 3 test accuracy:0.825661122799
Method 3 test accuracy:0.903948783875
Method 3 test accuracy:0.87210470438
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.262948513031 and training accuracy:0.960327804089
validation cost:0.262465059757 and validation accuracy:0.961393594742
Training on :(8, 9)
training cost:0.164376139641 and training accuracy:0.967777967453
validation cost:0.164112076163 and validation accuracy:0.967043340206
Training on :(8, 9)
training cost:0.128871038556 and training accuracy:0.971596181393
validation cost:0.128728121519 and validation accuracy:0.973634660244
Training on :(8, 9)
training cost:0.109606452286 and training accuracy:0.974203765392
validation cost:0.10946495831 and validation accuracy:0.976459503174
Training on :(8, 9)
training cost:0.0970469564199 and training accuracy:0.976531922817
validation cost:0.0968462452292 and validation accuracy:0.97834277153
Training on :(8, 9)
training cost:0.0879959538579 and training accuracy:0.979605138302
validation cost:0.0877068713307 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.0810557231307 and training accuracy:0.981095194817
validation cost:0.0806649774313 and validation accuracy:0.984934091568
Training on :(8, 9)
training cost:0.0755050033331 and training accuracy:0.982398927212
validation cost:0.0750115960836 and validation accuracy:0.985875725746
Training on :(8, 9)
training cost:0.0709293335676 and training accuracy:0.983050823212
validation cost:0.0703349485993 and validation accuracy:0.985875725746
Training on :(8, 9)
Time taken:138.23430109
Method 3 test accuracy:0.977777779102
Method 3 test accuracy:0.788442730904
Method 3 test accuracy:0.885272145271
Method 3 test accuracy:0.852970778942
Method 3 test accuracy:0.67977809906
Training with lmbda:15727241.7392, 15
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.18300165236 and training accuracy:0.997744202614
validation cost:0.180041104555 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0551121495664 and training accuracy:0.998178005219
validation cost:0.0553850792348 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0317224673927 and training accuracy:0.998264789581
validation cost:0.0325507335365 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0225060489029 and training accuracy:0.998351573944
validation cost:0.0235052797943 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0176029242575 and training accuracy:0.998698592186
validation cost:0.0186661407351 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.014548827894 and training accuracy:0.998872101307
validation cost:0.0156352259219 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0124530969188 and training accuracy:0.998872101307
validation cost:0.013544889167 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0109188891947 and training accuracy:0.99895888567
validation cost:0.0120074385777 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.00974285230041 and training accuracy:0.999132394791
validation cost:0.0108234938234 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:147.910654068
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.337540209293 and training accuracy:0.944914102554
validation cost:0.34098893404 and validation accuracy:0.947610318661
Training on :(2, 3)
training cost:0.171221598983 and training accuracy:0.962730646133
validation cost:0.175484597683 and validation accuracy:0.960477948189
Training on :(2, 3)
training cost:0.120020464063 and training accuracy:0.971093535423
validation cost:0.125363409519 and validation accuracy:0.965073525906
Training on :(2, 3)
training cost:0.0948415845633 and training accuracy:0.976638495922
validation cost:0.10051228106 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0795245394111 and training accuracy:0.979729115963
validation cost:0.0850474387407 and validation accuracy:0.974264681339
Training on :(2, 3)
training cost:0.0690726190805 and training accuracy:0.982637941837
validation cost:0.0742473825812 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0614063814282 and training accuracy:0.984819591045
validation cost:0.0661671981215 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0554981939495 and training accuracy:0.986274003983
validation cost:0.0598400197923 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0507749579847 and training accuracy:0.987455666065
validation cost:0.0547136962414 and validation accuracy:0.983455896378
Training on :(2, 3)
Time taken:140.013584137
Method 3 test accuracy:0.983924329281
Method 3 test accuracy:0.945641517639
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.248988613486 and training accuracy:0.980390250683
validation cost:0.251836776733 and validation accuracy:0.982231020927
Training on :(4, 5)
training cost:0.126936167479 and training accuracy:0.990926802158
validation cost:0.123503528535 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0863106772304 and training accuracy:0.993073165417
validation cost:0.0807686671615 and validation accuracy:0.99703848362
Training on :(4, 5)
training cost:0.0663306415081 and training accuracy:0.994829297066
validation cost:0.0600480511785 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0544425137341 and training accuracy:0.995317101479
validation cost:0.0479187332094 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0465285740793 and training accuracy:0.995707333088
validation cost:0.0399742461741 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0408574566245 and training accuracy:0.996097564697
validation cost:0.0343681015074 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0365756079555 and training accuracy:0.996195137501
validation cost:0.0301959328353 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0332145392895 and training accuracy:0.996390223503
validation cost:0.0269661806524 and validation accuracy:1.0
Training on :(4, 5)
Time taken:132.282696009
Method 3 test accuracy:0.981087446213
Method 3 test accuracy:0.94074434042
Method 3 test accuracy:0.660085380077
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.184185177088 and training accuracy:0.991250991821
validation cost:0.177336379886 and validation accuracy:0.992700755596
Training on :(6, 7)
training cost:0.0906633362174 and training accuracy:0.995129406452
validation cost:0.0869396179914 and validation accuracy:0.993613123894
Training on :(6, 7)
training cost:0.0624380633235 and training accuracy:0.996843159199
validation cost:0.0597147978842 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0487097203732 and training accuracy:0.997384309769
validation cost:0.0464183837175 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.040480684489 and training accuracy:0.997654914856
validation cost:0.0384185872972 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0349415466189 and training accuracy:0.997925519943
validation cost:0.0330181568861 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0309251770377 and training accuracy:0.998105883598
validation cost:0.0290956106037 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.027860743925 and training accuracy:0.998647093773
validation cost:0.0261010192335 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0254337582737 and training accuracy:0.998827457428
validation cost:0.0237287133932 and validation accuracy:1.0
Training on :(6, 7)
Time taken:141.934011221
Method 3 test accuracy:0.975413739681
Method 3 test accuracy:0.928011775017
Method 3 test accuracy:0.643009603024
Method 3 test accuracy:0.904330313206
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.248046845198 and training accuracy:0.958837747574
validation cost:0.249664708972 and validation accuracy:0.957627117634
Training on :(8, 9)
training cost:0.15739056468 and training accuracy:0.965729176998
validation cost:0.159523412585 and validation accuracy:0.963276863098
Training on :(8, 9)
training cost:0.124477148056 and training accuracy:0.970944285393
validation cost:0.12679694593 and validation accuracy:0.970809817314
Training on :(8, 9)
training cost:0.106382571161 and training accuracy:0.974948763847
validation cost:0.108705572784 and validation accuracy:0.976459503174
Training on :(8, 9)
training cost:0.0944593474269 and training accuracy:0.976811349392
validation cost:0.0966973006725 and validation accuracy:0.976459503174
Training on :(8, 9)
training cost:0.0857941284776 and training accuracy:0.978673875332
validation cost:0.0879086479545 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.0791062489152 and training accuracy:0.979698240757
validation cost:0.0810821130872 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.073731996119 and training accuracy:0.981002032757
validation cost:0.0755703747272 and validation accuracy:0.98399245739
Training on :(8, 9)
training cost:0.0692843273282 and training accuracy:0.982119560242
validation cost:0.0709934309125 and validation accuracy:0.985875725746
Training on :(8, 9)
Time taken:137.256875038
Method 3 test accuracy:0.973049640656
Method 3 test accuracy:0.892262458801
Method 3 test accuracy:0.578975439072
Method 3 test accuracy:0.880664646626
Method 3 test accuracy:0.715078175068
Training with lmbda:17023113.8655, 16
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.18300165236 and training accuracy:0.997744202614
validation cost:0.180041104555 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0551121495664 and training accuracy:0.998178005219
validation cost:0.0553850792348 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0317224673927 and training accuracy:0.998264789581
validation cost:0.0325507335365 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0225060489029 and training accuracy:0.998351573944
validation cost:0.0235052797943 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0176029242575 and training accuracy:0.998698592186
validation cost:0.0186661407351 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.014548827894 and training accuracy:0.998872101307
validation cost:0.0156352259219 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0124530969188 and training accuracy:0.998872101307
validation cost:0.013544889167 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0109188891947 and training accuracy:0.99895888567
validation cost:0.0120074385777 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.00974285230041 and training accuracy:0.999132394791
validation cost:0.0108234938234 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:147.826557875
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.337857097387 and training accuracy:0.945004999638
validation cost:0.341307640076 and validation accuracy:0.947610318661
Training on :(2, 3)
training cost:0.171515077353 and training accuracy:0.962730646133
validation cost:0.175778314471 and validation accuracy:0.960477948189
Training on :(2, 3)
training cost:0.120273113251 and training accuracy:0.971184432507
validation cost:0.125613510609 and validation accuracy:0.965073525906
Training on :(2, 3)
training cost:0.0950701236725 and training accuracy:0.976638495922
validation cost:0.10074017942 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0797358751297 and training accuracy:0.979729115963
validation cost:0.0852618068457 and validation accuracy:0.974264681339
Training on :(2, 3)
training cost:0.0692690908909 and training accuracy:0.982637941837
validation cost:0.0744487196207 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0615918524563 and training accuracy:0.984819591045
validation cost:0.0663592219353 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0556730777025 and training accuracy:0.986274003983
validation cost:0.0600235760212 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0509415008128 and training accuracy:0.987273871899
validation cost:0.054888933897 and validation accuracy:0.983455896378
Training on :(2, 3)
Time taken:141.540118933
Method 3 test accuracy:0.983924329281
Method 3 test accuracy:0.945641517639
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.250552773476 and training accuracy:0.980390250683
validation cost:0.253468483686 and validation accuracy:0.982231020927
Training on :(4, 5)
training cost:0.128046154976 and training accuracy:0.99082928896
validation cost:0.124679908156 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0871506556869 and training accuracy:0.993073165417
validation cost:0.0816573649645 and validation accuracy:0.99703848362
Training on :(4, 5)
training cost:0.067004814744 and training accuracy:0.994829297066
validation cost:0.0607569850981 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0550067424774 and training accuracy:0.995219528675
validation cost:0.0485085658729 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.047014515847 and training accuracy:0.995707333088
validation cost:0.0404792875051 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0412854105234 and training accuracy:0.996097564697
validation cost:0.0348101221025 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0369587168097 and training accuracy:0.996195137501
validation cost:0.0305889435112 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0335622802377 and training accuracy:0.996390223503
validation cost:0.0273206327111 and validation accuracy:1.0
Training on :(4, 5)
Time taken:132.176032066
Method 3 test accuracy:0.981087446213
Method 3 test accuracy:0.94074434042
Method 3 test accuracy:0.661152601242
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.186187669635 and training accuracy:0.991250991821
validation cost:0.179323300719 and validation accuracy:0.992700755596
Training on :(6, 7)
training cost:0.0919842272997 and training accuracy:0.995129406452
validation cost:0.0882447883487 and validation accuracy:0.993613123894
Training on :(6, 7)
training cost:0.0634368360043 and training accuracy:0.996843159199
validation cost:0.0607026778162 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0495242141187 and training accuracy:0.997384309769
validation cost:0.0472265817225 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0411749854684 and training accuracy:0.997654914856
validation cost:0.0391087792814 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0355479568243 and training accuracy:0.997925519943
validation cost:0.0336217693985 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0314653031528 and training accuracy:0.998105883598
validation cost:0.0296341199428 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0283490549773 and training accuracy:0.998647093773
validation cost:0.0265876296908 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0258800834417 and training accuracy:0.998827457428
validation cost:0.0241737198085 and validation accuracy:1.0
Training on :(6, 7)
Time taken:142.659062862
Method 3 test accuracy:0.975413739681
Method 3 test accuracy:0.927522063255
Method 3 test accuracy:0.644076824188
Method 3 test accuracy:0.904330313206
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.250285059214 and training accuracy:0.958651542664
validation cost:0.251880705357 and validation accuracy:0.957627117634
Training on :(8, 9)
training cost:0.159032151103 and training accuracy:0.965729176998
validation cost:0.161138579249 and validation accuracy:0.964218437672
Training on :(8, 9)
training cost:0.125866442919 and training accuracy:0.971130549908
validation cost:0.128160089254 and validation accuracy:0.970809817314
Training on :(8, 9)
training cost:0.107641763985 and training accuracy:0.974576294422
validation cost:0.109943635762 and validation accuracy:0.975517868996
Training on :(8, 9)
training cost:0.0956375300884 and training accuracy:0.976625084877
validation cost:0.0978602692485 and validation accuracy:0.976459503174
Training on :(8, 9)
training cost:0.086916834116 and training accuracy:0.978394508362
validation cost:0.0890216529369 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.0801874995232 and training accuracy:0.979698240757
validation cost:0.0821601599455 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.0747775360942 and training accuracy:0.980908930302
validation cost:0.0766197741032 and validation accuracy:0.98399245739
Training on :(8, 9)
training cost:0.0702989399433 and training accuracy:0.981840193272
validation cost:0.0720162242651 and validation accuracy:0.985875725746
Training on :(8, 9)
Time taken:137.631958961
Method 3 test accuracy:0.973522484303
Method 3 test accuracy:0.892262458801
Method 3 test accuracy:0.578441858292
Method 3 test accuracy:0.880664646626
Method 3 test accuracy:0.716591000557
Training with lmbda:20308059.8423, 17
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.18300165236 and training accuracy:0.997744202614
validation cost:0.180041104555 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0551121495664 and training accuracy:0.998178005219
validation cost:0.0553850792348 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0317224673927 and training accuracy:0.998264789581
validation cost:0.0325507335365 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0225060489029 and training accuracy:0.998351573944
validation cost:0.0235052797943 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0176029242575 and training accuracy:0.998698592186
validation cost:0.0186661407351 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.014548827894 and training accuracy:0.998872101307
validation cost:0.0156352259219 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0124530969188 and training accuracy:0.998872101307
validation cost:0.013544889167 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0109188891947 and training accuracy:0.99895888567
validation cost:0.0120074385777 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.00974285230041 and training accuracy:0.999132394791
validation cost:0.0108234938234 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:147.531913042
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.338631033897 and training accuracy:0.945004999638
validation cost:0.342086106539 and validation accuracy:0.947610318661
Training on :(2, 3)
training cost:0.172214061022 and training accuracy:0.962730646133
validation cost:0.176477104425 and validation accuracy:0.960477948189
Training on :(2, 3)
training cost:0.120874129236 and training accuracy:0.971366226673
validation cost:0.126208081841 and validation accuracy:0.965073525906
Training on :(2, 3)
training cost:0.0956075340509 and training accuracy:0.976638495922
validation cost:0.101273231208 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0802295356989 and training accuracy:0.979729115963
validation cost:0.0857610106468 and validation accuracy:0.974264681339
Training on :(2, 3)
training cost:0.0697282031178 and training accuracy:0.982547044754
validation cost:0.0749190822244 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0620216839015 and training accuracy:0.984910488129
validation cost:0.0668053030968 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0560793578625 and training accuracy:0.986274003983
validation cost:0.0604487583041 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0513269267976 and training accuracy:0.987182974815
validation cost:0.0552962608635 and validation accuracy:0.983455896378
Training on :(2, 3)
Time taken:141.800186157
Method 3 test accuracy:0.983924329281
Method 3 test accuracy:0.946131229401
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.254148155451 and training accuracy:0.980487823486
validation cost:0.257220953703 and validation accuracy:0.982231020927
Training on :(4, 5)
training cost:0.13059861958 and training accuracy:0.990536570549
validation cost:0.127388775349 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0890801101923 and training accuracy:0.992780506611
validation cost:0.08370269835 and validation accuracy:0.99703848362
Training on :(4, 5)
training cost:0.0685507506132 and training accuracy:0.994634151459
validation cost:0.0623876675963 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0563000962138 and training accuracy:0.995219528675
validation cost:0.0498653426766 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0481293164194 and training accuracy:0.995707333088
validation cost:0.0416416674852 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.042266882956 and training accuracy:0.995999991894
validation cost:0.0358269028366 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0378367491066 and training accuracy:0.996097564697
validation cost:0.0314930938184 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.034358959645 and training accuracy:0.996390223503
validation cost:0.0281360968947 and validation accuracy:1.0
Training on :(4, 5)
Time taken:132.678728819
Method 3 test accuracy:0.98156028986
Method 3 test accuracy:0.939275205135
Method 3 test accuracy:0.661686241627
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.190902248025 and training accuracy:0.991160809994
validation cost:0.184001654387 and validation accuracy:0.992700755596
Training on :(6, 7)
training cost:0.0950772464275 and training accuracy:0.995129406452
validation cost:0.0913022905588 and validation accuracy:0.993613123894
Training on :(6, 7)
training cost:0.0657694637775 and training accuracy:0.996752977371
validation cost:0.063012868166 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0514201894403 and training accuracy:0.997384309769
validation cost:0.0491107478738 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0427836850286 and training accuracy:0.997654914856
validation cost:0.0407119207084 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0369516424835 and training accuracy:0.997925519943
validation cost:0.0350239537656 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0327137224376 and training accuracy:0.998015701771
validation cost:0.0308832637966 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0294748991728 and training accuracy:0.998556852341
validation cost:0.0277152769268 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0269065313041 and training accuracy:0.998827457428
validation cost:0.0252010896802 and validation accuracy:1.0
Training on :(6, 7)
Time taken:141.879215956
Method 3 test accuracy:0.973049640656
Method 3 test accuracy:0.926542580128
Method 3 test accuracy:0.643009603024
Method 3 test accuracy:0.914904356003
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.255560129881 and training accuracy:0.958651542664
validation cost:0.257107824087 and validation accuracy:0.957627117634
Training on :(8, 9)
training cost:0.162912651896 and training accuracy:0.965449810028
validation cost:0.164966672659 and validation accuracy:0.96233522892
Training on :(8, 9)
training cost:0.129140943289 and training accuracy:0.970571815968
validation cost:0.131383255124 and validation accuracy:0.96798491478
Training on :(8, 9)
training cost:0.110595978796 and training accuracy:0.974390029907
validation cost:0.112854138017 and validation accuracy:0.975517868996
Training on :(8, 9)
training cost:0.0983978360891 and training accuracy:0.976438820362
validation cost:0.100590966642 and validation accuracy:0.976459503174
Training on :(8, 9)
training cost:0.0895411297679 and training accuracy:0.978021979332
validation cost:0.0916302874684 and validation accuracy:0.979284346104
Training on :(8, 9)
training cost:0.0827075466514 and training accuracy:0.979418873787
validation cost:0.0846804976463 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.077210187912 and training accuracy:0.979884505272
validation cost:0.0790645331144 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.0726541727781 and training accuracy:0.981095194817
validation cost:0.0743926092982 and validation accuracy:0.98399245739
Training on :(8, 9)
Time taken:139.651095867
Method 3 test accuracy:0.972104012966
Method 3 test accuracy:0.892262458801
Method 3 test accuracy:0.580576300621
Method 3 test accuracy:0.894763350487
Method 3 test accuracy:0.702471017838
Training with lmbda:15727241.7392, 18
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.176431387663 and training accuracy:0.997657477856
validation cost:0.175373464823 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0536804720759 and training accuracy:0.997917771339
validation cost:0.0552427694201 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.031071877107 and training accuracy:0.998178005219
validation cost:0.0329087935388 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0221254955977 and training accuracy:0.998351573944
validation cost:0.0239604897797 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0173518024385 and training accuracy:0.998611807823
validation cost:0.0191254429519 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0143707823008 and training accuracy:0.998872101307
validation cost:0.0160710196942 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0123212244362 and training accuracy:0.99895888567
validation cost:0.0139480028301 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0108183240518 and training accuracy:0.999045610428
validation cost:0.0123760458082 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.00966470036656 and training accuracy:0.999045610428
validation cost:0.0111590242013 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:149.526950836
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.343111783266 and training accuracy:0.944914102554
validation cost:0.345376819372 and validation accuracy:0.948529422283
Training on :(2, 3)
training cost:0.174095660448 and training accuracy:0.9623670578
validation cost:0.177144110203 and validation accuracy:0.962316155434
Training on :(2, 3)
training cost:0.121823318303 and training accuracy:0.971638917923
validation cost:0.126189172268 and validation accuracy:0.966911792755
Training on :(2, 3)
training cost:0.096204020083 and training accuracy:0.976911187172
validation cost:0.101074337959 and validation accuracy:0.975183844566
Training on :(2, 3)
training cost:0.0806746631861 and training accuracy:0.980365395546
validation cost:0.0855694338679 and validation accuracy:0.977941155434
Training on :(2, 3)
training cost:0.0700972676277 and training accuracy:0.983365178108
validation cost:0.0747914463282 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0623467154801 and training accuracy:0.984819591045
validation cost:0.0667453184724 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0563756562769 and training accuracy:0.986001253128
validation cost:0.0604437179863 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0516021028161 and training accuracy:0.987273871899
validation cost:0.0553299598396 and validation accuracy:0.983455896378
Training on :(2, 3)
Time taken:144.088166952
Method 3 test accuracy:0.987234055996
Method 3 test accuracy:0.929480910301
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.259605407715 and training accuracy:0.980682909489
validation cost:0.262252360582 and validation accuracy:0.98617964983
Training on :(4, 5)
training cost:0.132142722607 and training accuracy:0.98975610733
validation cost:0.128334924579 and validation accuracy:0.994077026844
Training on :(4, 5)
training cost:0.0895917713642 and training accuracy:0.993073165417
validation cost:0.083702288568 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0686849206686 and training accuracy:0.994146347046
validation cost:0.0621208995581 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.0562543235719 and training accuracy:0.994634151459
validation cost:0.0495067499578 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.0479830801487 and training accuracy:0.995121955872
validation cost:0.0412455014884 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0420582965016 and training accuracy:0.995414614677
validation cost:0.0354127064347 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0375855974853 and training accuracy:0.995804905891
validation cost:0.0310696009547 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0340776629746 and training accuracy:0.996097564697
validation cost:0.0277078337967 and validation accuracy:1.0
Training on :(4, 5)
Time taken:138.262513876
Method 3 test accuracy:0.981087446213
Method 3 test accuracy:0.841332018375
Method 3 test accuracy:0.917289197445
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.183508783579 and training accuracy:0.991250991821
validation cost:0.177182108164 and validation accuracy:0.991788327694
Training on :(6, 7)
training cost:0.0909816175699 and training accuracy:0.995400011539
validation cost:0.0876618400216 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0628181993961 and training accuracy:0.996572554111
validation cost:0.0604899264872 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0490444526076 and training accuracy:0.997474491596
validation cost:0.0471585132182 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.040757291019 and training accuracy:0.997925519943
validation cost:0.0391054973006 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0351647697389 and training accuracy:0.998015701771
validation cost:0.0336551293731 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0311057772487 and training accuracy:0.998286306858
validation cost:0.0296917725354 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0280076656491 and training accuracy:0.998556852341
validation cost:0.0266623143107 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0255552902818 and training accuracy:0.998647093773
validation cost:0.0242614895105 and validation accuracy:0.999087572098
Training on :(6, 7)
Time taken:145.341070175
Method 3 test accuracy:0.978723406792
Method 3 test accuracy:0.824681699276
Method 3 test accuracy:0.910885810852
Method 3 test accuracy:0.878650546074
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.252671211958 and training accuracy:0.955578327179
validation cost:0.253322958946 and validation accuracy:0.951035797596
Training on :(8, 9)
training cost:0.160752668977 and training accuracy:0.964518547058
validation cost:0.16175031662 and validation accuracy:0.961393594742
Training on :(8, 9)
training cost:0.127282097936 and training accuracy:0.970851182938
validation cost:0.128279462457 and validation accuracy:0.971751391888
Training on :(8, 9)
training cost:0.108816690743 and training accuracy:0.973644971848
validation cost:0.109659723938 and validation accuracy:0.972693026066
Training on :(8, 9)
training cost:0.096609480679 and training accuracy:0.976531922817
validation cost:0.0972503423691 and validation accuracy:0.979284346104
Training on :(8, 9)
training cost:0.0877111107111 and training accuracy:0.978580713272
validation cost:0.088147982955 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.0808279886842 and training accuracy:0.979977667332
validation cost:0.0810733810067 and validation accuracy:0.98399245739
Training on :(8, 9)
training cost:0.0752881020308 and training accuracy:0.981560826302
validation cost:0.0753594040871 and validation accuracy:0.98399245739
Training on :(8, 9)
training cost:0.0706949159503 and training accuracy:0.982678353786
validation cost:0.0706106349826 and validation accuracy:0.987758934498
Training on :(8, 9)
Time taken:138.897898912
Method 3 test accuracy:0.977777779102
Method 3 test accuracy:0.79382956028
Method 3 test accuracy:0.896478116512
Method 3 test accuracy:0.858006060123
Method 3 test accuracy:0.65305095911
Training with lmbda:17023113.8655, 19
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.176431387663 and training accuracy:0.997657477856
validation cost:0.175373464823 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0536804720759 and training accuracy:0.997917771339
validation cost:0.0552427694201 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.031071877107 and training accuracy:0.998178005219
validation cost:0.0329087935388 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0221254955977 and training accuracy:0.998351573944
validation cost:0.0239604897797 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0173518024385 and training accuracy:0.998611807823
validation cost:0.0191254429519 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0143707823008 and training accuracy:0.998872101307
validation cost:0.0160710196942 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0123212244362 and training accuracy:0.99895888567
validation cost:0.0139480028301 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0108183240518 and training accuracy:0.999045610428
validation cost:0.0123760458082 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.00966470036656 and training accuracy:0.999045610428
validation cost:0.0111590242013 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:148.912702084
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.343432426453 and training accuracy:0.944823205471
validation cost:0.345700323582 and validation accuracy:0.948529422283
Training on :(2, 3)
training cost:0.174408346415 and training accuracy:0.9623670578
validation cost:0.177454605699 and validation accuracy:0.962316155434
Training on :(2, 3)
training cost:0.1221011132 and training accuracy:0.971638917923
validation cost:0.126460820436 and validation accuracy:0.966911792755
Training on :(2, 3)
training cost:0.0964585617185 and training accuracy:0.976820290089
validation cost:0.101322434843 and validation accuracy:0.975183844566
Training on :(2, 3)
training cost:0.0809113234282 and training accuracy:0.980365395546
validation cost:0.085800550878 and validation accuracy:0.977941155434
Training on :(2, 3)
training cost:0.0703183934093 and training accuracy:0.983365178108
validation cost:0.0750086158514 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0625550672412 and training accuracy:0.984819591045
validation cost:0.0669510364532 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0565727502108 and training accuracy:0.986001253128
validation cost:0.0606389902532 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0517901480198 and training accuracy:0.987182974815
validation cost:0.0555173531175 and validation accuracy:0.983455896378
Training on :(2, 3)
Time taken:144.069035053
Method 3 test accuracy:0.987234055996
Method 3 test accuracy:0.929480910301
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.261288136244 and training accuracy:0.980585336685
validation cost:0.263997763395 and validation accuracy:0.98617964983
Training on :(4, 5)
training cost:0.133332699537 and training accuracy:0.98946338892
validation cost:0.129584133625 and validation accuracy:0.994077026844
Training on :(4, 5)
training cost:0.0904802009463 and training accuracy:0.993073165417
validation cost:0.0846319198608 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0693893134594 and training accuracy:0.994048774242
validation cost:0.0628529340029 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.0568391308188 and training accuracy:0.994731724262
validation cost:0.0501099787652 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.0484840087593 and training accuracy:0.995121955872
validation cost:0.0417586117983 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0424966663122 and training accuracy:0.995414614677
validation cost:0.0358589440584 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0379763804376 and training accuracy:0.99590241909
validation cost:0.0314648710191 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0344311110675 and training accuracy:0.996097564697
validation cost:0.0280633457005 and validation accuracy:1.0
Training on :(4, 5)
Time taken:133.852586985
Method 3 test accuracy:0.98061466217
Method 3 test accuracy:0.841332018375
Method 3 test accuracy:0.91782283783
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.18545293808 and training accuracy:0.991250991821
validation cost:0.179114297032 and validation accuracy:0.991788327694
Training on :(6, 7)
training cost:0.092272400856 and training accuracy:0.995400011539
validation cost:0.0889400839806 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0637939944863 and training accuracy:0.996482372284
validation cost:0.0614586025476 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0498390160501 and training accuracy:0.997384309769
validation cost:0.047949757427 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0414334572852 and training accuracy:0.997925519943
validation cost:0.0397809557617 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0357571057975 and training accuracy:0.998015701771
validation cost:0.0342480577528 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0316353030503 and training accuracy:0.998286306858
validation cost:0.0302226729691 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0284888353199 and training accuracy:0.998556852341
validation cost:0.0271454583853 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0259972773492 and training accuracy:0.998647093773
validation cost:0.0247058775276 and validation accuracy:0.999087572098
Training on :(6, 7)
Time taken:143.862088919
Method 3 test accuracy:0.979196190834
Method 3 test accuracy:0.825661122799
Method 3 test accuracy:0.911419451237
Method 3 test accuracy:0.879657626152
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.255363315344 and training accuracy:0.955578327179
validation cost:0.255959361792 and validation accuracy:0.951035797596
Training on :(8, 9)
training cost:0.162450000644 and training accuracy:0.964518547058
validation cost:0.163376182318 and validation accuracy:0.96233522892
Training on :(8, 9)
training cost:0.12861391902 and training accuracy:0.970758080482
validation cost:0.129528954625 and validation accuracy:0.971751391888
Training on :(8, 9)
training cost:0.109971880913 and training accuracy:0.973644971848
validation cost:0.110731743276 and validation accuracy:0.972693026066
Training on :(8, 9)
training cost:0.0976615250111 and training accuracy:0.976252555847
validation cost:0.0982232317328 and validation accuracy:0.97834277153
Training on :(8, 9)
training cost:0.0886949375272 and training accuracy:0.978301346302
validation cost:0.0890572890639 and validation accuracy:0.98116761446
Training on :(8, 9)
training cost:0.0817614644766 and training accuracy:0.979698240757
validation cost:0.0819359570742 and validation accuracy:0.98399245739
Training on :(8, 9)
training cost:0.0761817768216 and training accuracy:0.981281459332
validation cost:0.0761869326234 and validation accuracy:0.98399245739
Training on :(8, 9)
training cost:0.0715564414859 and training accuracy:0.982585191727
validation cost:0.0714112073183 and validation accuracy:0.987758934498
Training on :(8, 9)
Time taken:140.531233788
Method 3 test accuracy:0.977777779102
Method 3 test accuracy:0.794808983803
Method 3 test accuracy:0.896478116512
Method 3 test accuracy:0.856998980045
Method 3 test accuracy:0.660615205765
Training with lmbda:20308059.8423, 20
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.176431387663 and training accuracy:0.997657477856
validation cost:0.175373464823 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0536804720759 and training accuracy:0.997917771339
validation cost:0.0552427694201 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.031071877107 and training accuracy:0.998178005219
validation cost:0.0329087935388 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0221254955977 and training accuracy:0.998351573944
validation cost:0.0239604897797 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0173518024385 and training accuracy:0.998611807823
validation cost:0.0191254429519 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0143707823008 and training accuracy:0.998872101307
validation cost:0.0160710196942 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0123212244362 and training accuracy:0.99895888567
validation cost:0.0139480028301 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0108183240518 and training accuracy:0.999045610428
validation cost:0.0123760458082 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.00966470036656 and training accuracy:0.999045610428
validation cost:0.0111590242013 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:149.949834824
Method 3 test accuracy:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.344214618206 and training accuracy:0.944823205471
validation cost:0.346488595009 and validation accuracy:0.948529422283
Training on :(2, 3)
training cost:0.175158172846 and training accuracy:0.962276160717
validation cost:0.178198367357 and validation accuracy:0.962316155434
Training on :(2, 3)
training cost:0.122760400176 and training accuracy:0.971638917923
validation cost:0.127105012536 and validation accuracy:0.966911792755
Training on :(2, 3)
training cost:0.0970557630062 and training accuracy:0.976820290089
validation cost:0.101904325187 and validation accuracy:0.976102948189
Training on :(2, 3)
training cost:0.0814644023776 and training accuracy:0.980365395546
validation cost:0.0863408222795 and validation accuracy:0.977941155434
Training on :(2, 3)
training cost:0.0708348825574 and training accuracy:0.983456075191
validation cost:0.0755161717534 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0630392432213 and training accuracy:0.984819591045
validation cost:0.0674282386899 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0570289492607 and training accuracy:0.985910356045
validation cost:0.0610913522542 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0522215552628 and training accuracy:0.987001180649
validation cost:0.0559475086629 and validation accuracy:0.982536792755
Training on :(2, 3)
Time taken:141.555716038
Method 3 test accuracy:0.987234055996
Method 3 test accuracy:0.929480910301
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.265180021524 and training accuracy:0.980292677879
validation cost:0.268034428358 and validation accuracy:0.985192477703
Training on :(4, 5)
training cost:0.13606967032 and training accuracy:0.988975584507
validation cost:0.132458671927 and validation accuracy:0.994077026844
Training on :(4, 5)
training cost:0.0925198048353 and training accuracy:0.993073165417
validation cost:0.0867668762803 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0710067898035 and training accuracy:0.99385368824
validation cost:0.0645342245698 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.0581804253161 and training accuracy:0.994731724262
validation cost:0.0514946356416 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.0496319830418 and training accuracy:0.995121955872
validation cost:0.0429360456765 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0435019209981 and training accuracy:0.995414614677
validation cost:0.0368839725852 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0388720631599 and training accuracy:0.99590241909
validation cost:0.0323734693229 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0352402329445 and training accuracy:0.996097564697
validation cost:0.0288803000003 and validation accuracy:1.0
Training on :(4, 5)
Time taken:132.706648827
Method 3 test accuracy:0.980141818523
Method 3 test accuracy:0.841821730137
Method 3 test accuracy:0.917289197445
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.189994513988 and training accuracy:0.991160809994
validation cost:0.183630362153 and validation accuracy:0.991788327694
Training on :(6, 7)
training cost:0.095279186964 and training accuracy:0.995309829712
validation cost:0.0919210240245 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0660573765635 and training accuracy:0.996392190456
validation cost:0.0637082159519 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0516752749681 and training accuracy:0.997294127941
validation cost:0.0497806631029 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0429939851165 and training accuracy:0.997835278511
validation cost:0.041342061013 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0371239110827 and training accuracy:0.998015701771
validation cost:0.0356196463108 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0328563861549 and training accuracy:0.998196065426
validation cost:0.0314506739378 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0295963231474 and training accuracy:0.998466670513
validation cost:0.0282616633922 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0270124189556 and training accuracy:0.998647093773
validation cost:0.0257311351597 and validation accuracy:0.999087572098
Training on :(6, 7)
Time taken:141.833524942
Method 3 test accuracy:0.978723406792
Method 3 test accuracy:0.824681699276
Method 3 test accuracy:0.908751308918
Method 3 test accuracy:0.888721048832
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.260943740606 and training accuracy:0.955764591694
validation cost:0.261479139328 and validation accuracy:0.951035797596
Training on :(8, 9)
training cost:0.166576638818 and training accuracy:0.964518547058
validation cost:0.167434945703 and validation accuracy:0.96233522892
Training on :(8, 9)
training cost:0.132087349892 and training accuracy:0.970478653908
validation cost:0.132940292358 and validation accuracy:0.969868183136
Training on :(8, 9)
training cost:0.113089881837 and training accuracy:0.973272502422
validation cost:0.113797605038 and validation accuracy:0.972693026066
Training on :(8, 9)
training cost:0.100551880896 and training accuracy:0.976066291332
validation cost:0.101072020829 and validation accuracy:0.97834277153
Training on :(8, 9)
training cost:0.0914273783565 and training accuracy:0.978115081787
validation cost:0.0917567461729 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.0843696966767 and training accuracy:0.979232609272
validation cost:0.0845181718469 and validation accuracy:0.983050823212
Training on :(8, 9)
training cost:0.0786845162511 and training accuracy:0.980443298817
validation cost:0.0786689966917 and validation accuracy:0.98399245739
Training on :(8, 9)
training cost:0.0739685595036 and training accuracy:0.981933295727
validation cost:0.0738094225526 and validation accuracy:0.984934091568
Training on :(8, 9)
Time taken:140.319699049
Method 3 test accuracy:0.977777779102
Method 3 test accuracy:0.79578846693
Method 3 test accuracy:0.894877254963
Method 3 test accuracy:0.871097683907
Method 3 test accuracy:0.654059529305
Training with lmbda:15727241.7392, 21
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.174038305879 and training accuracy:0.997657477856
validation cost:0.171872153878 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.054135248065 and training accuracy:0.998004496098
validation cost:0.0547703653574 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0316030569375 and training accuracy:0.998264789581
validation cost:0.0326831489801 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226018596441 and training accuracy:0.998351573944
validation cost:0.0237815957516 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0177727974951 and training accuracy:0.998698592186
validation cost:0.0189616121352 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0147457355633 and training accuracy:0.99895888567
validation cost:0.0159146208316 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.01265872363 and training accuracy:0.99895888567
validation cost:0.0137961311266 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0111242728308 and training accuracy:0.99895888567
validation cost:0.0122250914574 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.00994336046278 and training accuracy:0.99895888567
validation cost:0.0110064344481 and validation accuracy:0.997366130352
Training on :(0, 1)
Time taken:150.199862003
Method 3 test accuracy:0.998581588268
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.339087128639 and training accuracy:0.946368515491
validation cost:0.34445258975 and validation accuracy:0.955882370472
Training on :(2, 3)
training cost:0.172272711992 and training accuracy:0.963457882404
validation cost:0.177651569247 and validation accuracy:0.960477948189
Training on :(2, 3)
training cost:0.121012456715 and training accuracy:0.972093462944
validation cost:0.126943409443 and validation accuracy:0.967830896378
Training on :(2, 3)
training cost:0.095920689404 and training accuracy:0.976729393005
validation cost:0.101882345974 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0807037353516 and training accuracy:0.97991091013
validation cost:0.0863683521748 and validation accuracy:0.978860318661
Training on :(2, 3)
training cost:0.0703236013651 and training accuracy:0.982728838921
validation cost:0.0755645409226 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0626985803246 and training accuracy:0.984637737274
validation cost:0.06749240309 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0568044744432 and training accuracy:0.986274003983
validation cost:0.0611637197435 and validation accuracy:0.983455896378
Training on :(2, 3)
training cost:0.052080757916 and training accuracy:0.987455666065
validation cost:0.0560323707759 and validation accuracy:0.986213207245
Training on :(2, 3)
Time taken:142.544525146
Method 3 test accuracy:0.916784882545
Method 3 test accuracy:0.979431927204
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.253796577454 and training accuracy:0.980975627899
validation cost:0.255776107311 and validation accuracy:0.985192477703
Training on :(4, 5)
training cost:0.129405707121 and training accuracy:0.990536570549
validation cost:0.125250518322 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0878050029278 and training accuracy:0.993658542633
validation cost:0.0817470476031 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.0673457384109 and training accuracy:0.994926810265
validation cost:0.060711838305 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0551851354539 and training accuracy:0.99590241909
validation cost:0.0484316758811 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0471002422273 and training accuracy:0.99590241909
validation cost:0.0404034219682 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0413139835 and training accuracy:0.996195137501
validation cost:0.0347479991615 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0369515120983 and training accuracy:0.996487796307
validation cost:0.030546143651 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0335340499878 and training accuracy:0.99658536911
validation cost:0.027298392728 and validation accuracy:1.0
Training on :(4, 5)
Time taken:134.749624014
Method 3 test accuracy:0.857683241367
Method 3 test accuracy:0.954946160316
Method 3 test accuracy:0.80683028698
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.18312188983 and training accuracy:0.992243170738
validation cost:0.177164956927 and validation accuracy:0.992700755596
Training on :(6, 7)
training cost:0.0894282758236 and training accuracy:0.995760798454
validation cost:0.0865619778633 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0612687431276 and training accuracy:0.996572554111
validation cost:0.059403181076 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0475869886577 and training accuracy:0.997925519943
validation cost:0.0461650565267 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0393929593265 and training accuracy:0.998105883598
validation cost:0.0382069610059 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.033882919699 and training accuracy:0.998196065426
validation cost:0.0328368581831 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0298960898072 and training accuracy:0.998556852341
validation cost:0.0289404466748 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0268615465611 and training accuracy:0.998556852341
validation cost:0.0259682126343 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0244645122439 and training accuracy:0.998917639256
validation cost:0.0236162655056 and validation accuracy:1.0
Training on :(6, 7)
Time taken:144.611853123
Method 3 test accuracy:0.702600479126
Method 3 test accuracy:0.939275205135
Method 3 test accuracy:0.792956233025
Method 3 test accuracy:0.941591143608
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.253794252872 and training accuracy:0.957720220089
validation cost:0.25344774127 and validation accuracy:0.956685483456
Training on :(8, 9)
training cost:0.160842463374 and training accuracy:0.966101706028
validation cost:0.160721719265 and validation accuracy:0.967043340206
Training on :(8, 9)
training cost:0.127064436674 and training accuracy:0.970199286938
validation cost:0.127052694559 and validation accuracy:0.973634660244
Training on :(8, 9)
training cost:0.108460940421 and training accuracy:0.973458766937
validation cost:0.108422793448 and validation accuracy:0.975517868996
Training on :(8, 9)
training cost:0.0961683169007 and training accuracy:0.976252555847
validation cost:0.0960318669677 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.0872133523226 and training accuracy:0.978301346302
validation cost:0.0869477167726 and validation accuracy:0.983050823212
Training on :(8, 9)
training cost:0.0802826285362 and training accuracy:0.979512035847
validation cost:0.079880900681 and validation accuracy:0.983050823212
Training on :(8, 9)
training cost:0.0746979787946 and training accuracy:0.982026457787
validation cost:0.074160143733 and validation accuracy:0.98681730032
Training on :(8, 9)
training cost:0.0700661987066 and training accuracy:0.982957720757
validation cost:0.0694002360106 and validation accuracy:0.987758934498
Training on :(8, 9)
Time taken:140.217069864
Method 3 test accuracy:0.696453928947
Method 3 test accuracy:0.903036236763
Method 3 test accuracy:0.73532551527
Method 3 test accuracy:0.920443117619
Method 3 test accuracy:0.717599570751
Training with lmbda:17023113.8655, 22
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.174038305879 and training accuracy:0.997657477856
validation cost:0.171872153878 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.054135248065 and training accuracy:0.998004496098
validation cost:0.0547703653574 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0316030569375 and training accuracy:0.998264789581
validation cost:0.0326831489801 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226018596441 and training accuracy:0.998351573944
validation cost:0.0237815957516 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0177727974951 and training accuracy:0.998698592186
validation cost:0.0189616121352 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0147457355633 and training accuracy:0.99895888567
validation cost:0.0159146208316 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.01265872363 and training accuracy:0.99895888567
validation cost:0.0137961311266 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0111242728308 and training accuracy:0.99895888567
validation cost:0.0122250914574 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.00994336046278 and training accuracy:0.99895888567
validation cost:0.0110064344481 and validation accuracy:0.997366130352
Training on :(0, 1)
Time taken:150.135808945
Method 3 test accuracy:0.998581588268
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.339413404465 and training accuracy:0.946368515491
validation cost:0.344781160355 and validation accuracy:0.955882370472
Training on :(2, 3)
training cost:0.172589614987 and training accuracy:0.963548779488
validation cost:0.177967891097 and validation accuracy:0.960477948189
Training on :(2, 3)
training cost:0.121294803917 and training accuracy:0.972093462944
validation cost:0.127223074436 and validation accuracy:0.967830896378
Training on :(2, 3)
training cost:0.0961791798472 and training accuracy:0.976638495922
validation cost:0.102137103677 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.08094394207 and training accuracy:0.97991091013
validation cost:0.0866062045097 and validation accuracy:0.978860318661
Training on :(2, 3)
training cost:0.0705498382449 and training accuracy:0.982728838921
validation cost:0.0757898688316 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0629118904471 and training accuracy:0.984637737274
validation cost:0.0677057355642 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0570069253445 and training accuracy:0.986274003983
validation cost:0.0613673590124 and validation accuracy:0.983455896378
Training on :(2, 3)
training cost:0.0522736907005 and training accuracy:0.987455666065
validation cost:0.0562265813351 and validation accuracy:0.986213207245
Training on :(2, 3)
Time taken:143.124052048
Method 3 test accuracy:0.917257666588
Method 3 test accuracy:0.978942215443
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.255429804325 and training accuracy:0.980975627899
validation cost:0.25746563077 and validation accuracy:0.985192477703
Training on :(4, 5)
training cost:0.130570620298 and training accuracy:0.990438997746
validation cost:0.126470595598 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0886856541038 and training accuracy:0.993658542633
validation cost:0.0826653316617 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.0680519491434 and training accuracy:0.994731724262
validation cost:0.0614448189735 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0557762235403 and training accuracy:0.995707333088
validation cost:0.0490424707532 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.047609642148 and training accuracy:0.99590241909
validation cost:0.0409285351634 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0417630411685 and training accuracy:0.996195137501
validation cost:0.035209801048 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0373538956046 and training accuracy:0.996487796307
validation cost:0.03095850721 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0338991209865 and training accuracy:0.99658536911
validation cost:0.0276718195528 and validation accuracy:1.0
Training on :(4, 5)
Time taken:133.193395853
Method 3 test accuracy:0.858628869057
Method 3 test accuracy:0.954946160316
Method 3 test accuracy:0.80683028698
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.184982225299 and training accuracy:0.992152988911
validation cost:0.179011911154 and validation accuracy:0.991788327694
Training on :(6, 7)
training cost:0.0906528457999 and training accuracy:0.995670616627
validation cost:0.0877766609192 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0621861480176 and training accuracy:0.996482372284
validation cost:0.0603181757033 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0483266636729 and training accuracy:0.997925519943
validation cost:0.046907775104 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0400163084269 and training accuracy:0.998105883598
validation cost:0.0388367623091 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0344248227775 and training accuracy:0.998196065426
validation cost:0.033387042582 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.030377952382 and training accuracy:0.998556852341
validation cost:0.0294312424958 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0272975489497 and training accuracy:0.998556852341
validation cost:0.0264133475721 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0248640328646 and training accuracy:0.998917639256
validation cost:0.0240252185613 and validation accuracy:1.0
Training on :(6, 7)
Time taken:143.914892912
Method 3 test accuracy:0.70118200779
Method 3 test accuracy:0.939764916897
Method 3 test accuracy:0.794023454189
Method 3 test accuracy:0.941591143608
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.256123811007 and training accuracy:0.957347750664
validation cost:0.255789756775 and validation accuracy:0.955743908882
Training on :(8, 9)
training cost:0.16254208982 and training accuracy:0.965915441513
validation cost:0.162419274449 and validation accuracy:0.967043340206
Training on :(8, 9)
training cost:0.128494560719 and training accuracy:0.970199286938
validation cost:0.128472313285 and validation accuracy:0.973634660244
Training on :(8, 9)
training cost:0.109747566283 and training accuracy:0.973272502422
validation cost:0.109697975218 and validation accuracy:0.975517868996
Training on :(8, 9)
training cost:0.0973665490746 and training accuracy:0.976252555847
validation cost:0.0972185507417 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.0883473008871 and training accuracy:0.978301346302
validation cost:0.0880735591054 and validation accuracy:0.983050823212
Training on :(8, 9)
training cost:0.0813660770655 and training accuracy:0.979232609272
validation cost:0.0809594541788 and validation accuracy:0.983050823212
Training on :(8, 9)
training cost:0.0757391527295 and training accuracy:0.981933295727
validation cost:0.0751995444298 and validation accuracy:0.985875725746
Training on :(8, 9)
training cost:0.0710720717907 and training accuracy:0.982864618301
validation cost:0.070407487452 and validation accuracy:0.987758934498
Training on :(8, 9)
Time taken:139.376139164
Method 3 test accuracy:0.69692671299
Method 3 test accuracy:0.903036236763
Method 3 test accuracy:0.734258294106
Method 3 test accuracy:0.920946598053
Method 3 test accuracy:0.721129596233
Training with lmbda:20308059.8423, 23
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.174038305879 and training accuracy:0.997657477856
validation cost:0.171872153878 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.054135248065 and training accuracy:0.998004496098
validation cost:0.0547703653574 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0316030569375 and training accuracy:0.998264789581
validation cost:0.0326831489801 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226018596441 and training accuracy:0.998351573944
validation cost:0.0237815957516 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0177727974951 and training accuracy:0.998698592186
validation cost:0.0189616121352 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0147457355633 and training accuracy:0.99895888567
validation cost:0.0159146208316 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.01265872363 and training accuracy:0.99895888567
validation cost:0.0137961311266 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0111242728308 and training accuracy:0.99895888567
validation cost:0.0122250914574 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.00994336046278 and training accuracy:0.99895888567
validation cost:0.0110064344481 and validation accuracy:0.997366130352
Training on :(0, 1)
Time taken:149.14816618
Method 3 test accuracy:0.998581588268
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.34020242095 and training accuracy:0.946368515491
validation cost:0.345575451851 and validation accuracy:0.955882370472
Training on :(2, 3)
training cost:0.173350021243 and training accuracy:0.963548779488
validation cost:0.178726166487 and validation accuracy:0.960477948189
Training on :(2, 3)
training cost:0.121963299811 and training accuracy:0.972093462944
validation cost:0.127883851528 and validation accuracy:0.967830896378
Training on :(2, 3)
training cost:0.096788033843 and training accuracy:0.976547598839
validation cost:0.102737233043 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0815091356635 and training accuracy:0.97991091013
validation cost:0.0871660560369 and validation accuracy:0.978860318661
Training on :(2, 3)
training cost:0.0710783079267 and training accuracy:0.982728838921
validation cost:0.0763161256909 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0634094774723 and training accuracy:0.984546840191
validation cost:0.0682037770748 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0574776679277 and training accuracy:0.986183047295
validation cost:0.0618401691318 and validation accuracy:0.983455896378
Training on :(2, 3)
training cost:0.0527208819985 and training accuracy:0.987364768982
validation cost:0.0566775090992 and validation accuracy:0.986213207245
Training on :(2, 3)
Time taken:141.992642164
Method 3 test accuracy:0.917730510235
Method 3 test accuracy:0.978942215443
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.259192824364 and training accuracy:0.980878055096
validation cost:0.26135122776 and validation accuracy:0.985192477703
Training on :(4, 5)
training cost:0.133259937167 and training accuracy:0.990243911743
validation cost:0.129283428192 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0907178446651 and training accuracy:0.993658542633
validation cost:0.0847829729319 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.0696827098727 and training accuracy:0.994731724262
validation cost:0.0631358325481 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0571416355669 and training accuracy:0.995707333088
validation cost:0.050452735275 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0487863607705 and training accuracy:0.99590241909
validation cost:0.0421400032938 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0427993535995 and training accuracy:0.996097564697
validation cost:0.0362737774849 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0382829420269 and training accuracy:0.996487796307
validation cost:0.0319095179439 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0347414389253 and training accuracy:0.99658536911
validation cost:0.0285315662622 and validation accuracy:1.0
Training on :(4, 5)
Time taken:133.23939991
Method 3 test accuracy:0.860047280788
Method 3 test accuracy:0.955435872078
Method 3 test accuracy:0.808964788914
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.189361020923 and training accuracy:0.991972565651
validation cost:0.183359250426 and validation accuracy:0.991788327694
Training on :(6, 7)
training cost:0.0935209617019 and training accuracy:0.995309829712
validation cost:0.0906228274107 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0643231570721 and training accuracy:0.996482372284
validation cost:0.0624506957829 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0500448532403 and training accuracy:0.997835278511
validation cost:0.048634339124 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0414649397135 and training accuracy:0.998105883598
validation cost:0.0403000786901 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.035685069859 and training accuracy:0.998196065426
validation cost:0.034666005522 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0314998812973 and training accuracy:0.998466670513
validation cost:0.0305739697069 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0283133182675 and training accuracy:0.998556852341
validation cost:0.0274510905147 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0257960427552 and training accuracy:0.9987372756
validation cost:0.0249796323478 and validation accuracy:1.0
Training on :(6, 7)
Time taken:144.221457005
Method 3 test accuracy:0.70118200779
Method 3 test accuracy:0.940254628658
Method 3 test accuracy:0.794023454189
Method 3 test accuracy:0.941591143608
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.261676818132 and training accuracy:0.956788957119
validation cost:0.261374980211 and validation accuracy:0.955743908882
Training on :(8, 9)
training cost:0.166590511799 and training accuracy:0.965542912483
validation cost:0.166465312243 and validation accuracy:0.966101706028
Training on :(8, 9)
training cost:0.131882861257 and training accuracy:0.970292448997
validation cost:0.131841659546 and validation accuracy:0.973634660244
Training on :(8, 9)
training cost:0.112785317004 and training accuracy:0.972899973392
validation cost:0.112713053823 and validation accuracy:0.975517868996
Training on :(8, 9)
training cost:0.100182339549 and training accuracy:0.975786924362
validation cost:0.100014455616 and validation accuracy:0.979284346104
Training on :(8, 9)
training cost:0.0910044759512 and training accuracy:0.977928876877
validation cost:0.0907167941332 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.0839026272297 and training accuracy:0.979046404362
validation cost:0.083488561213 and validation accuracy:0.983050823212
Training on :(8, 9)
training cost:0.0781745389104 and training accuracy:0.981188297272
validation cost:0.0776358544827 and validation accuracy:0.985875725746
Training on :(8, 9)
training cost:0.0734196156263 and training accuracy:0.982492089272
validation cost:0.0727606937289 and validation accuracy:0.98681730032
Training on :(8, 9)
Time taken:137.113356113
Method 3 test accuracy:0.694562673569
Method 3 test accuracy:0.904015660286
Method 3 test accuracy:0.733724653721
Method 3 test accuracy:0.920946598053
Method 3 test accuracy:0.72516387701
Training with lmbda:15727241.7392, 24
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.187800481915 and training accuracy:0.997657477856
validation cost:0.185233682394 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0556595101953 and training accuracy:0.997917771339
validation cost:0.0566286668181 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0318946912885 and training accuracy:0.998178005219
validation cost:0.0333917215466 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226054172963 and training accuracy:0.998351573944
validation cost:0.024216093123 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.017684943974 and training accuracy:0.998525083065
validation cost:0.0193010065705 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0146277258173 and training accuracy:0.998698592186
validation cost:0.0162140671164 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0125324195251 and training accuracy:0.998872101307
validation cost:0.0140765998513 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.010999395512 and training accuracy:0.99895888567
validation cost:0.0124963019043 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.00982450786978 and training accuracy:0.999045610428
validation cost:0.0112750455737 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:148.816608906
Method 3 test accuracy:0.998581588268
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.343387812376 and training accuracy:0.943368792534
validation cost:0.346320182085 and validation accuracy:0.944852948189
Training on :(2, 3)
training cost:0.174063757062 and training accuracy:0.962003469467
validation cost:0.177769958973 and validation accuracy:0.958639681339
Training on :(2, 3)
training cost:0.121751204133 and training accuracy:0.971729815006
validation cost:0.126522421837 and validation accuracy:0.965992629528
Training on :(2, 3)
training cost:0.0961189940572 and training accuracy:0.976729393005
validation cost:0.101234510541 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.080577634275 and training accuracy:0.980092704296
validation cost:0.0855990126729 and validation accuracy:0.977022051811
Training on :(2, 3)
training cost:0.0699926391244 and training accuracy:0.982910633087
validation cost:0.0747314542532 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0622319206595 and training accuracy:0.984365046024
validation cost:0.0666147917509 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0562498643994 and training accuracy:0.985728561878
validation cost:0.0602642372251 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0514690689743 and training accuracy:0.987455666065
validation cost:0.0551279820502 and validation accuracy:0.981617629528
Training on :(2, 3)
Time taken:143.144240856
Method 3 test accuracy:0.988179683685
Method 3 test accuracy:0.928501486778
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.250869512558 and training accuracy:0.981170713902
validation cost:0.254293680191 and validation accuracy:0.98617964983
Training on :(4, 5)
training cost:0.128455847502 and training accuracy:0.990341484547
validation cost:0.125101417303 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.08744250983 and training accuracy:0.99385368824
validation cost:0.081848949194 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0671616718173 and training accuracy:0.994926810265
validation cost:0.0607943162322 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.055055771023 and training accuracy:0.995317101479
validation cost:0.0484432950616 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0469828993082 and training accuracy:0.99590241909
validation cost:0.040345236659 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.041192509234 and training accuracy:0.996390223503
validation cost:0.0346296578646 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0368189923465 and training accuracy:0.99658536911
validation cost:0.0303768962622 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0333887822926 and training accuracy:0.996682941914
validation cost:0.02708838135 and validation accuracy:1.0
Training on :(4, 5)
Time taken:133.224341869
Method 3 test accuracy:0.985342800617
Method 3 test accuracy:0.92066603899
Method 3 test accuracy:0.663820683956
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.181647643447 and training accuracy:0.991972565651
validation cost:0.175531819463 and validation accuracy:0.990875899792
Training on :(6, 7)
training cost:0.0887849852443 and training accuracy:0.996031403542
validation cost:0.0859124734998 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0610316433012 and training accuracy:0.997294127941
validation cost:0.0591913200915 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0475948378444 and training accuracy:0.997564733028
validation cost:0.0461916252971 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0395537726581 and training accuracy:0.998015701771
validation cost:0.0383698232472 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0341395996511 and training accuracy:0.998105883598
validation cost:0.0330799743533 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0302138384432 and training accuracy:0.998466670513
validation cost:0.0292325746268 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0272182617337 and training accuracy:0.998827457428
validation cost:0.0262895748019 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0248454790562 and training accuracy:0.999098062515
validation cost:0.0239550843835 and validation accuracy:1.0
Training on :(6, 7)
Time taken:142.722701073
Method 3 test accuracy:0.982033073902
Method 3 test accuracy:0.904995083809
Method 3 test accuracy:0.648345768452
Method 3 test accuracy:0.890231609344
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.254302173853 and training accuracy:0.955671429634
validation cost:0.252826929092 and validation accuracy:0.95951038599
Training on :(8, 9)
training cost:0.159960791469 and training accuracy:0.964611649513
validation cost:0.158789649606 and validation accuracy:0.96516007185
Training on :(8, 9)
training cost:0.126064777374 and training accuracy:0.970758080482
validation cost:0.125091031194 and validation accuracy:0.970809817314
Training on :(8, 9)
training cost:0.107525937259 and training accuracy:0.974296867847
validation cost:0.106599934399 and validation accuracy:0.974576294422
Training on :(8, 9)
training cost:0.0953369140625 and training accuracy:0.976997554302
validation cost:0.0943767130375 and validation accuracy:0.979284346104
Training on :(8, 9)
training cost:0.086493588984 and training accuracy:0.978673875332
validation cost:0.0854634866118 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.0796741470695 and training accuracy:0.980536401272
validation cost:0.0785563141108 and validation accuracy:0.984934091568
Training on :(8, 9)
training cost:0.0741968974471 and training accuracy:0.981653928757
validation cost:0.0729864165187 and validation accuracy:0.985875725746
Training on :(8, 9)
training cost:0.069663874805 and training accuracy:0.982957720757
validation cost:0.0683624818921 and validation accuracy:0.987758934498
Training on :(8, 9)
Time taken:139.337059021
Method 3 test accuracy:0.983451545238
Method 3 test accuracy:0.878550469875
Method 3 test accuracy:0.584845244884
Method 3 test accuracy:0.875629425049
Method 3 test accuracy:0.710539579391
Training with lmbda:17023113.8655, 25
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.187800481915 and training accuracy:0.997657477856
validation cost:0.185233682394 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0556595101953 and training accuracy:0.997917771339
validation cost:0.0566286668181 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0318946912885 and training accuracy:0.998178005219
validation cost:0.0333917215466 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226054172963 and training accuracy:0.998351573944
validation cost:0.024216093123 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.017684943974 and training accuracy:0.998525083065
validation cost:0.0193010065705 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0146277258173 and training accuracy:0.998698592186
validation cost:0.0162140671164 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0125324195251 and training accuracy:0.998872101307
validation cost:0.0140765998513 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.010999395512 and training accuracy:0.99895888567
validation cost:0.0124963019043 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.00982450786978 and training accuracy:0.999045610428
validation cost:0.0112750455737 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:148.432331085
Method 3 test accuracy:0.998581588268
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.343739420176 and training accuracy:0.943459689617
validation cost:0.346671998501 and validation accuracy:0.945772051811
Training on :(2, 3)
training cost:0.174392431974 and training accuracy:0.962003469467
validation cost:0.1780936867 and validation accuracy:0.958639681339
Training on :(2, 3)
training cost:0.12203720212 and training accuracy:0.971729815006
validation cost:0.126799434423 and validation accuracy:0.965992629528
Training on :(2, 3)
training cost:0.0963783040643 and training accuracy:0.976729393005
validation cost:0.101485282183 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0808173269033 and training accuracy:0.980092704296
validation cost:0.0858319848776 and validation accuracy:0.977022051811
Training on :(2, 3)
training cost:0.07021664083 and training accuracy:0.98300153017
validation cost:0.0749529227614 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0624434091151 and training accuracy:0.984365046024
validation cost:0.0668265670538 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0564493127167 and training accuracy:0.985728561878
validation cost:0.0604666247964 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0516577363014 and training accuracy:0.987455666065
validation cost:0.0553207099438 and validation accuracy:0.981617629528
Training on :(2, 3)
Time taken:141.700875998
Method 3 test accuracy:0.988179683685
Method 3 test accuracy:0.928011775017
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.252584427595 and training accuracy:0.981073141098
validation cost:0.256083339453 and validation accuracy:0.98617964983
Training on :(4, 5)
training cost:0.129640221596 and training accuracy:0.990341484547
validation cost:0.12635794282 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0883219391108 and training accuracy:0.993756115437
validation cost:0.0827797353268 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0678567960858 and training accuracy:0.994829297066
validation cost:0.0615256652236 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0556302033365 and training accuracy:0.995317101479
validation cost:0.0490435920656 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0474736988544 and training accuracy:0.995804905891
validation cost:0.0408550426364 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0416216962039 and training accuracy:0.996390223503
validation cost:0.035072747618 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0372015088797 and training accuracy:0.99658536911
validation cost:0.0307696070522 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0337340533733 and training accuracy:0.996682941914
validation cost:0.0274408347905 and validation accuracy:1.0
Training on :(4, 5)
Time taken:133.246722937
Method 3 test accuracy:0.985342800617
Method 3 test accuracy:0.920176327229
Method 3 test accuracy:0.66595518589
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.183543801308 and training accuracy:0.991882383823
validation cost:0.177412375808 and validation accuracy:0.990875899792
Training on :(6, 7)
training cost:0.0900425985456 and training accuracy:0.996031403542
validation cost:0.087158344686 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0619889162481 and training accuracy:0.997113764286
validation cost:0.0601443275809 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0483760125935 and training accuracy:0.997564733028
validation cost:0.0469746626914 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0402174852788 and training accuracy:0.997925519943
validation cost:0.0390401184559 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0347184091806 and training accuracy:0.998015701771
validation cost:0.0336683541536 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0307292193174 and training accuracy:0.998376488686
validation cost:0.0297590065747 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0276832096279 and training accuracy:0.9987372756
validation cost:0.0267666969448 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0252690836787 and training accuracy:0.999098062515
validation cost:0.0243914946914 and validation accuracy:1.0
Training on :(6, 7)
Time taken:143.784416914
Method 3 test accuracy:0.982033073902
Method 3 test accuracy:0.904995083809
Method 3 test accuracy:0.647812187672
Method 3 test accuracy:0.889728069305
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.256577342749 and training accuracy:0.955205798149
validation cost:0.255090206861 and validation accuracy:0.95951038599
Training on :(8, 9)
training cost:0.161630809307 and training accuracy:0.964239180088
validation cost:0.160426720977 and validation accuracy:0.96516007185
Training on :(8, 9)
training cost:0.127482071519 and training accuracy:0.970758080482
validation cost:0.126462236047 and validation accuracy:0.970809817314
Training on :(8, 9)
training cost:0.108813099563 and training accuracy:0.974390029907
validation cost:0.107838429511 and validation accuracy:0.974576294422
Training on :(8, 9)
training cost:0.096544303 and training accuracy:0.976904451847
validation cost:0.0955392569304 and validation accuracy:0.97834277153
Training on :(8, 9)
training cost:0.0876433849335 and training accuracy:0.978487610817
validation cost:0.0865748077631 and validation accuracy:0.98116761446
Training on :(8, 9)
training cost:0.0807787254453 and training accuracy:0.980163931847
validation cost:0.0796269699931 and validation accuracy:0.98399245739
Training on :(8, 9)
training cost:0.0752627328038 and training accuracy:0.981467664242
validation cost:0.0740219652653 and validation accuracy:0.985875725746
Training on :(8, 9)
training cost:0.0706956088543 and training accuracy:0.982678353786
validation cost:0.0693691298366 and validation accuracy:0.987758934498
Training on :(8, 9)
Time taken:140.474241018
Method 3 test accuracy:0.983451545238
Method 3 test accuracy:0.878550469875
Method 3 test accuracy:0.5843116045
Method 3 test accuracy:0.874622344971
Method 3 test accuracy:0.711043894291
Training with lmbda:20308059.8423, 26
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.187800481915 and training accuracy:0.997657477856
validation cost:0.185233682394 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0556595101953 and training accuracy:0.997917771339
validation cost:0.0566286668181 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0318946912885 and training accuracy:0.998178005219
validation cost:0.0333917215466 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226054172963 and training accuracy:0.998351573944
validation cost:0.024216093123 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.017684943974 and training accuracy:0.998525083065
validation cost:0.0193010065705 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0146277258173 and training accuracy:0.998698592186
validation cost:0.0162140671164 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0125324195251 and training accuracy:0.998872101307
validation cost:0.0140765998513 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.010999395512 and training accuracy:0.99895888567
validation cost:0.0124963019043 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.00982450786978 and training accuracy:0.999045610428
validation cost:0.0112750455737 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:150.733075857
Method 3 test accuracy:0.998581588268
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.344589948654 and training accuracy:0.943459689617
validation cost:0.34752240777 and validation accuracy:0.945772051811
Training on :(2, 3)
training cost:0.175178900361 and training accuracy:0.961912572384
validation cost:0.1788662076 and validation accuracy:0.958639681339
Training on :(2, 3)
training cost:0.122714631259 and training accuracy:0.971638917923
validation cost:0.127454191446 and validation accuracy:0.965992629528
Training on :(2, 3)
training cost:0.0969876646996 and training accuracy:0.976729393005
validation cost:0.102073602378 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0813780352473 and training accuracy:0.980092704296
validation cost:0.0863775089383 and validation accuracy:0.977022051811
Training on :(2, 3)
training cost:0.0707369968295 and training accuracy:0.98300153017
validation cost:0.0754634216428 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0629325658083 and training accuracy:0.984274148941
validation cost:0.0673137530684 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.056911367923 and training accuracy:0.985455870628
validation cost:0.0609324611723 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0520960390568 and training accuracy:0.987364768982
validation cost:0.0557670742273 and validation accuracy:0.981617629528
Training on :(2, 3)
Time taken:140.932919979
Method 3 test accuracy:0.988179683685
Method 3 test accuracy:0.928011775017
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.256534099579 and training accuracy:0.980682909489
validation cost:0.260202199221 and validation accuracy:0.98617964983
Training on :(4, 5)
training cost:0.132361277938 and training accuracy:0.990243911743
validation cost:0.129244983196 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0903381705284 and training accuracy:0.993658542633
validation cost:0.0849139019847 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0694509223104 and training accuracy:0.994829297066
validation cost:0.0632031783462 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0569482073188 and training accuracy:0.995317101479
validation cost:0.0504223108292 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.048598986119 and training accuracy:0.99590241909
validation cost:0.042025052011 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0426049046218 and training accuracy:0.996390223503
validation cost:0.0360887311399 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0380764752626 and training accuracy:0.99658536911
validation cost:0.0316681973636 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0345230735838 and training accuracy:0.996682941914
validation cost:0.0282464232296 and validation accuracy:1.0
Training on :(4, 5)
Time taken:134.327429056
Method 3 test accuracy:0.986288428307
Method 3 test accuracy:0.919686555862
Method 3 test accuracy:0.669690489769
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.188040450215 and training accuracy:0.991972565651
validation cost:0.181872680783 and validation accuracy:0.991788327694
Training on :(6, 7)
training cost:0.0930048748851 and training accuracy:0.996031403542
validation cost:0.0900955870748 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0642281025648 and training accuracy:0.997203946114
validation cost:0.0623771697283 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0501906946301 and training accuracy:0.997564733028
validation cost:0.0487966537476 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0417521521449 and training accuracy:0.997925519943
validation cost:0.0405920594931 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0360525399446 and training accuracy:0.998015701771
validation cost:0.0350266955793 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0319106802344 and training accuracy:0.998286306858
validation cost:0.0309687741101 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0287458300591 and training accuracy:0.998556852341
validation cost:0.027860308066 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0262354798615 and training accuracy:0.998917639256
validation cost:0.0253908205777 and validation accuracy:1.0
Training on :(6, 7)
Time taken:143.137948036
Method 3 test accuracy:0.982505917549
Method 3 test accuracy:0.904015660286
Method 3 test accuracy:0.648879408836
Method 3 test accuracy:0.904330313206
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.261966854334 and training accuracy:0.955298960209
validation cost:0.260456442833 and validation accuracy:0.961393594742
Training on :(8, 9)
training cost:0.165611729026 and training accuracy:0.964146018028
validation cost:0.164337486029 and validation accuracy:0.963276863098
Training on :(8, 9)
training cost:0.130852714181 and training accuracy:0.970292448997
validation cost:0.129733741283 and validation accuracy:0.970809817314
Training on :(8, 9)
training cost:0.111861199141 and training accuracy:0.973924398422
validation cost:0.110784180462 and validation accuracy:0.973634660244
Training on :(8, 9)
training cost:0.0993916168809 and training accuracy:0.976345717907
validation cost:0.0982908681035 and validation accuracy:0.977401137352
Training on :(8, 9)
training cost:0.0903429761529 and training accuracy:0.977835714817
validation cost:0.0891859158874 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.0833628177643 and training accuracy:0.979698240757
validation cost:0.0821346268058 and validation accuracy:0.98399245739
Training on :(8, 9)
training cost:0.0777504369617 and training accuracy:0.981188297272
validation cost:0.0764454081655 and validation accuracy:0.984934091568
Training on :(8, 9)
training cost:0.0730981603265 and training accuracy:0.982398927212
validation cost:0.0717172473669 and validation accuracy:0.98681730032
Training on :(8, 9)
Time taken:139.949795008
Method 3 test accuracy:0.982978701591
Method 3 test accuracy:0.876101851463
Method 3 test accuracy:0.5843116045
Method 3 test accuracy:0.887210488319
Method 3 test accuracy:0.702975273132
Training with lmbda:15727241.7392, 27
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.177878066897 and training accuracy:0.99705016613
validation cost:0.175777256489 and validation accuracy:0.996488153934
Training on :(0, 1)
training cost:0.0543369539082 and training accuracy:0.997570693493
validation cost:0.0553945638239 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.031618706882 and training accuracy:0.997830986977
validation cost:0.0331955589354 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226058047265 and training accuracy:0.997917771339
validation cost:0.0243187975138 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.017782099545 and training accuracy:0.998351573944
validation cost:0.0195217430592 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0147604439408 and training accuracy:0.998525083065
validation cost:0.0164875015616 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0126767754555 and training accuracy:0.998611807823
validation cost:0.0143733676523 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0111444368958 and training accuracy:0.998785376549
validation cost:0.0128030572087 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.00996474083513 and training accuracy:0.998872101307
validation cost:0.0115825748071 and validation accuracy:0.997366130352
Training on :(0, 1)
Time taken:150.013333082
Method 3 test accuracy:0.998581588268
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.336154937744 and training accuracy:0.946277618408
validation cost:0.34434607625 and validation accuracy:0.949448525906
Training on :(2, 3)
training cost:0.170890122652 and training accuracy:0.964185059071
validation cost:0.179065316916 and validation accuracy:0.957720577717
Training on :(2, 3)
training cost:0.119876399636 and training accuracy:0.971093535423
validation cost:0.12848097086 and validation accuracy:0.964154422283
Training on :(2, 3)
training cost:0.0948327556252 and training accuracy:0.976547598839
validation cost:0.103326804936 and validation accuracy:0.972426474094
Training on :(2, 3)
training cost:0.0796193629503 and training accuracy:0.980456292629
validation cost:0.0876652225852 and validation accuracy:0.977022051811
Training on :(2, 3)
training cost:0.0692422538996 and training accuracy:0.983092427254
validation cost:0.0767100676894 and validation accuracy:0.978860318661
Training on :(2, 3)
training cost:0.0616256780922 and training accuracy:0.985274076462
validation cost:0.0684940516949 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0557467527688 and training accuracy:0.986728489399
validation cost:0.0620317533612 and validation accuracy:0.982536792755
Training on :(2, 3)
training cost:0.0510393381119 and training accuracy:0.987910211086
validation cost:0.0567747652531 and validation accuracy:0.984375
Training on :(2, 3)
Time taken:142.320369959
Method 3 test accuracy:0.965484619141
Method 3 test accuracy:0.963271319866
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.256628721952 and training accuracy:0.980292677879
validation cost:0.259890288115 and validation accuracy:0.981243848801
Training on :(4, 5)
training cost:0.130235821009 and training accuracy:0.990048766136
validation cost:0.127088263631 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0882606133819 and training accuracy:0.992975592613
validation cost:0.082944855094 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.0676791965961 and training accuracy:0.994634151459
validation cost:0.0616201683879 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0554596818984 and training accuracy:0.995121955872
validation cost:0.049171641469 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0473343543708 and training accuracy:0.99590241909
validation cost:0.0410278514028 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0415153577924 and training accuracy:0.996195137501
validation cost:0.0352832376957 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0371241606772 and training accuracy:0.996390223503
validation cost:0.0310097429901 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0336807146668 and training accuracy:0.996487796307
validation cost:0.0277033559978 and validation accuracy:1.0
Training on :(4, 5)
Time taken:133.641682148
Method 3 test accuracy:0.956501185894
Method 3 test accuracy:0.946620941162
Method 3 test accuracy:0.76307362318
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.179131105542 and training accuracy:0.993325531483
validation cost:0.172823637724 and validation accuracy:0.992700755596
Training on :(6, 7)
training cost:0.0881050601602 and training accuracy:0.996211767197
validation cost:0.0847825929523 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.060766082257 and training accuracy:0.997203946114
validation cost:0.0583787597716 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0474794730544 and training accuracy:0.997835278511
validation cost:0.0454976707697 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0395164228976 and training accuracy:0.998196065426
validation cost:0.0377491489053 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0341523699462 and training accuracy:0.998286306858
validation cost:0.0325149334967 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0302610322833 and training accuracy:0.9987372756
validation cost:0.0287110265344 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0272915661335 and training accuracy:0.998827457428
validation cost:0.0258064195514 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0249387603253 and training accuracy:0.998917639256
validation cost:0.0235053636134 and validation accuracy:1.0
Training on :(6, 7)
Time taken:143.014801025
Method 3 test accuracy:0.923404276371
Method 3 test accuracy:0.928501486778
Method 3 test accuracy:0.757737457752
Method 3 test accuracy:0.913897275925
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.251386761665 and training accuracy:0.957813382149
validation cost:0.25216448307 and validation accuracy:0.952919006348
Training on :(8, 9)
training cost:0.157978698611 and training accuracy:0.965822339058
validation cost:0.159379154444 and validation accuracy:0.963276863098
Training on :(8, 9)
training cost:0.124291107059 and training accuracy:0.970664918423
validation cost:0.125943750143 and validation accuracy:0.971751391888
Training on :(8, 9)
training cost:0.10583537817 and training accuracy:0.974110662937
validation cost:0.107499472797 and validation accuracy:0.976459503174
Training on :(8, 9)
training cost:0.0936938226223 and training accuracy:0.977183818817
validation cost:0.0952547937632 and validation accuracy:0.98116761446
Training on :(8, 9)
training cost:0.0848825052381 and training accuracy:0.978953242302
validation cost:0.086294233799 and validation accuracy:0.98116761446
Training on :(8, 9)
training cost:0.0780898705125 and training accuracy:0.980257034302
validation cost:0.079338543117 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.0726373046637 and training accuracy:0.981467664242
validation cost:0.0737238302827 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.0681328997016 and training accuracy:0.982864618301
validation cost:0.0690645575523 and validation accuracy:0.98399245739
Training on :(8, 9)
Time taken:139.085197926
Method 3 test accuracy:0.920567393303
Method 3 test accuracy:0.895200788975
Method 3 test accuracy:0.700106739998
Method 3 test accuracy:0.886203408241
Method 3 test accuracy:0.751386761665
Training with lmbda:17023113.8655, 28
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.177878066897 and training accuracy:0.99705016613
validation cost:0.175777256489 and validation accuracy:0.996488153934
Training on :(0, 1)
training cost:0.0543369539082 and training accuracy:0.997570693493
validation cost:0.0553945638239 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.031618706882 and training accuracy:0.997830986977
validation cost:0.0331955589354 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226058047265 and training accuracy:0.997917771339
validation cost:0.0243187975138 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.017782099545 and training accuracy:0.998351573944
validation cost:0.0195217430592 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0147604439408 and training accuracy:0.998525083065
validation cost:0.0164875015616 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0126767754555 and training accuracy:0.998611807823
validation cost:0.0143733676523 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0111444368958 and training accuracy:0.998785376549
validation cost:0.0128030572087 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.00996474083513 and training accuracy:0.998872101307
validation cost:0.0115825748071 and validation accuracy:0.997366130352
Training on :(0, 1)
Time taken:148.963060856
Method 3 test accuracy:0.998581588268
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.336487144232 and training accuracy:0.946277618408
validation cost:0.344683647156 and validation accuracy:0.949448525906
Training on :(2, 3)
training cost:0.171192228794 and training accuracy:0.964185059071
validation cost:0.179373383522 and validation accuracy:0.957720577717
Training on :(2, 3)
training cost:0.120133988559 and training accuracy:0.971184432507
validation cost:0.128741204739 and validation accuracy:0.964154422283
Training on :(2, 3)
training cost:0.0950629115105 and training accuracy:0.976547598839
validation cost:0.103560052812 and validation accuracy:0.972426474094
Training on :(2, 3)
training cost:0.0798313394189 and training accuracy:0.980456292629
validation cost:0.0878815427423 and validation accuracy:0.977022051811
Training on :(2, 3)
training cost:0.0694405660033 and training accuracy:0.983092427254
validation cost:0.0769142657518 and validation accuracy:0.978860318661
Training on :(2, 3)
training cost:0.061812363565 and training accuracy:0.985274076462
validation cost:0.0686877369881 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0559237971902 and training accuracy:0.986728489399
validation cost:0.0622163787484 and validation accuracy:0.982536792755
Training on :(2, 3)
training cost:0.0512078143656 and training accuracy:0.987819314003
validation cost:0.0569517873228 and validation accuracy:0.983455896378
Training on :(2, 3)
Time taken:142.344309807
Method 3 test accuracy:0.965484619141
Method 3 test accuracy:0.963271319866
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.258303970098 and training accuracy:0.980195105076
validation cost:0.261637806892 and validation accuracy:0.981243848801
Training on :(4, 5)
training cost:0.131424307823 and training accuracy:0.989951193333
validation cost:0.128350421786 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0891520231962 and training accuracy:0.992780506611
validation cost:0.0838912650943 and validation accuracy:0.99703848362
Training on :(4, 5)
training cost:0.0683907642961 and training accuracy:0.994634151459
validation cost:0.0623725987971 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0560523830354 and training accuracy:0.995121955872
validation cost:0.0497960038483 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0478429682553 and training accuracy:0.99590241909
validation cost:0.0415615141392 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0419615395367 and training accuracy:0.996097564697
validation cost:0.0357491448522 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0375226549804 and training accuracy:0.996390223503
validation cost:0.0314240455627 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0340413711965 and training accuracy:0.996487796307
validation cost:0.0280770473182 and validation accuracy:1.0
Training on :(4, 5)
Time taken:132.855036974
Method 3 test accuracy:0.956028342247
Method 3 test accuracy:0.946620941162
Method 3 test accuracy:0.76414090395
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.181055173278 and training accuracy:0.993235349655
validation cost:0.174737080932 and validation accuracy:0.992700755596
Training on :(6, 7)
training cost:0.0893568694592 and training accuracy:0.996211767197
validation cost:0.0860232636333 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0617164373398 and training accuracy:0.997203946114
validation cost:0.0593229569495 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0482579171658 and training accuracy:0.997745096684
validation cost:0.0462741702795 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.040181659162 and training accuracy:0.998105883598
validation cost:0.0384152457118 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0347362607718 and training accuracy:0.998286306858
validation cost:0.0331010296941 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0307841897011 and training accuracy:0.9987372756
validation cost:0.0292370822281 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0277663916349 and training accuracy:0.998827457428
validation cost:0.0262845009565 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0253746472299 and training accuracy:0.998917639256
validation cost:0.0239446461201 and validation accuracy:1.0
Training on :(6, 7)
Time taken:144.513380051
Method 3 test accuracy:0.922931432724
Method 3 test accuracy:0.928501486778
Method 3 test accuracy:0.759338319302
Method 3 test accuracy:0.913897275925
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.253589391708 and training accuracy:0.957720220089
validation cost:0.254346579313 and validation accuracy:0.952919006348
Training on :(8, 9)
training cost:0.159577518702 and training accuracy:0.965915441513
validation cost:0.160948708653 and validation accuracy:0.963276863098
Training on :(8, 9)
training cost:0.125638067722 and training accuracy:0.970478653908
validation cost:0.127260163426 and validation accuracy:0.971751391888
Training on :(8, 9)
training cost:0.107054822147 and training accuracy:0.974110662937
validation cost:0.108691766858 and validation accuracy:0.976459503174
Training on :(8, 9)
training cost:0.0948379635811 and training accuracy:0.976904451847
validation cost:0.0963786765933 and validation accuracy:0.98116761446
Training on :(8, 9)
training cost:0.0859747976065 and training accuracy:0.978860139847
validation cost:0.0873737633228 and validation accuracy:0.98116761446
Training on :(8, 9)
training cost:0.0791417509317 and training accuracy:0.979977667332
validation cost:0.080383002758 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.0736571550369 and training accuracy:0.981467664242
validation cost:0.0747413560748 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.0691240504384 and training accuracy:0.982585191727
validation cost:0.0700572729111 and validation accuracy:0.983050823212
Training on :(8, 9)
Time taken:137.741729021
Method 3 test accuracy:0.919621765614
Method 3 test accuracy:0.895690500736
Method 3 test accuracy:0.701173961163
Method 3 test accuracy:0.88418930769
Method 3 test accuracy:0.753908216953
Training with lmbda:20308059.8423, 29
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.177878066897 and training accuracy:0.99705016613
validation cost:0.175777256489 and validation accuracy:0.996488153934
Training on :(0, 1)
training cost:0.0543369539082 and training accuracy:0.997570693493
validation cost:0.0553945638239 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.031618706882 and training accuracy:0.997830986977
validation cost:0.0331955589354 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226058047265 and training accuracy:0.997917771339
validation cost:0.0243187975138 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.017782099545 and training accuracy:0.998351573944
validation cost:0.0195217430592 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0147604439408 and training accuracy:0.998525083065
validation cost:0.0164875015616 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0126767754555 and training accuracy:0.998611807823
validation cost:0.0143733676523 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0111444368958 and training accuracy:0.998785376549
validation cost:0.0128030572087 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.00996474083513 and training accuracy:0.998872101307
validation cost:0.0115825748071 and validation accuracy:0.997366130352
Training on :(0, 1)
Time taken:148.67632699
Method 3 test accuracy:0.998581588268
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.337290495634 and training accuracy:0.946277618408
validation cost:0.345499008894 and validation accuracy:0.949448525906
Training on :(2, 3)
training cost:0.171911686659 and training accuracy:0.964185059071
validation cost:0.1801071316 and validation accuracy:0.957720577717
Training on :(2, 3)
training cost:0.120744094253 and training accuracy:0.97127532959
validation cost:0.129357159138 and validation accuracy:0.964154422283
Training on :(2, 3)
training cost:0.0956076160073 and training accuracy:0.976638495922
validation cost:0.104110404849 and validation accuracy:0.972426474094
Training on :(2, 3)
training cost:0.080331094563 and training accuracy:0.980365395546
validation cost:0.0883901789784 and validation accuracy:0.977022051811
Training on :(2, 3)
training cost:0.069904692471 and training accuracy:0.983183324337
validation cost:0.077390037477 and validation accuracy:0.978860318661
Training on :(2, 3)
training cost:0.0622480139136 and training accuracy:0.985274076462
validation cost:0.0691376104951 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0563363432884 and training accuracy:0.986637592316
validation cost:0.0626450479031 and validation accuracy:0.982536792755
Training on :(2, 3)
training cost:0.0515995509923 and training accuracy:0.987819314003
validation cost:0.0573612228036 and validation accuracy:0.983455896378
Training on :(2, 3)
Time taken:143.030716181
Method 3 test accuracy:0.965957462788
Method 3 test accuracy:0.963271319866
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.262177973986 and training accuracy:0.97990244627
validation cost:0.265678018332 and validation accuracy:0.980256676674
Training on :(4, 5)
training cost:0.134164959192 and training accuracy:0.989560961723
validation cost:0.131261736155 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0912058055401 and training accuracy:0.992780506611
validation cost:0.0860729888082 and validation accuracy:0.99703848362
Training on :(4, 5)
training cost:0.070026434958 and training accuracy:0.994634151459
validation cost:0.0641040578485 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0574132278562 and training accuracy:0.995024383068
validation cost:0.0512309260666 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0490103438497 and training accuracy:0.995999991894
validation cost:0.0427871607244 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0429857559502 and training accuracy:0.996097564697
validation cost:0.0368203781545 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.038436755538 and training accuracy:0.996390223503
validation cost:0.0323765911162 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.034867156297 and training accuracy:0.996487796307
validation cost:0.0289343632758 and validation accuracy:1.0
Training on :(4, 5)
Time taken:133.018534184
Method 3 test accuracy:0.956028342247
Method 3 test accuracy:0.946620941162
Method 3 test accuracy:0.765741705894
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.185578584671 and training accuracy:0.993235349655
validation cost:0.179239332676 and validation accuracy:0.992700755596
Training on :(6, 7)
training cost:0.0922894850373 and training accuracy:0.996211767197
validation cost:0.0889350101352 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0639327019453 and training accuracy:0.997113764286
validation cost:0.0615304969251 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0500677861273 and training accuracy:0.997564733028
validation cost:0.0480838604271 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0417260639369 and training accuracy:0.998105883598
validation cost:0.0399644039571 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0360903851688 and training accuracy:0.998196065426
validation cost:0.0344628021121 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.031993817538 and training accuracy:0.998647093773
validation cost:0.0304561108351 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0288618933409 and training accuracy:0.9987372756
validation cost:0.0273903999478 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0263773780316 and training accuracy:0.998917639256
validation cost:0.0249579884112 and validation accuracy:1.0
Training on :(6, 7)
Time taken:142.851102114
Method 3 test accuracy:0.921985805035
Method 3 test accuracy:0.92899119854
Method 3 test accuracy:0.761472761631
Method 3 test accuracy:0.913393735886
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.258819669485 and training accuracy:0.957720220089
validation cost:0.25953412056 and validation accuracy:0.952919006348
Training on :(8, 9)
training cost:0.163403362036 and training accuracy:0.965636074543
validation cost:0.16471464932 and validation accuracy:0.963276863098
Training on :(8, 9)
training cost:0.128854230046 and training accuracy:0.970385551453
validation cost:0.130413427949 and validation accuracy:0.971751391888
Training on :(8, 9)
training cost:0.109957315028 and training accuracy:0.973924398422
validation cost:0.111540965736 and validation accuracy:0.975517868996
Training on :(8, 9)
training cost:0.0975527316332 and training accuracy:0.976811349392
validation cost:0.0990567281842 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.0885598435998 and training accuracy:0.978766977787
validation cost:0.0899382159114 and validation accuracy:0.98116761446
Training on :(8, 9)
training cost:0.0816294103861 and training accuracy:0.979791402817
validation cost:0.0828650817275 and validation accuracy:0.98116761446
Training on :(8, 9)
training cost:0.0760664269328 and training accuracy:0.980722665787
validation cost:0.0771569013596 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.0714649856091 and training accuracy:0.981840193272
validation cost:0.0724152550101 and validation accuracy:0.982109248638
Training on :(8, 9)
Time taken:139.558192968
Method 3 test accuracy:0.919148921967
Method 3 test accuracy:0.901077389717
Method 3 test accuracy:0.712913572788
Method 3 test accuracy:0.892245709896
Method 3 test accuracy:0.734241068363
Total time:21749.0544069
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Final-accuracy">Final accuracy<a class="anchor-link" href="#Final-accuracy">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[40]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">all_test_samples</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">n_test_samples</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">all_test_samples</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">n_test_samples</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">i</span><span class="p">])</span>
<span class="n">all_test_samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">all_test_samples</span><span class="p">)]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">all_prev_task_test_accs</span><span class="p">)</span>

<span class="n">indices</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">15</span><span class="p">]]</span>

<span class="n">np_all_test_accs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">all_prev_task_test_accs</span><span class="p">]</span>
<span class="n">scaled_all_accs</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="p">,</span> <span class="n">all_test_samples</span><span class="p">,</span> <span class="n">np_all_test_accs</span><span class="p">)</span>

<span class="n">sum_scaled</span> <span class="o">=</span> <span class="p">[</span><span class="n">thing</span><span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">all_test_samples</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="k">for</span> <span class="n">thing</span> <span class="ow">in</span> <span class="n">scaled_all_accs</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>
<span class="n">sum_scaled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sum_scaled</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Plots">Plots<a class="anchor-link" href="#Plots">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[45]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">MultiIndex</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">([</span><span class="n">lmbdas</span><span class="p">],</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;lmbdas&#39;</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">)],</span> <span class="n">data</span><span class="o">=</span><span class="n">sum_scaled</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;spike_mnist_ar1_final.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[45]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
    </tr>
    <tr>
      <th>lmbdas</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1.572724e+07</th>
      <td>0.999054</td>
      <td>0.956459</td>
      <td>0.869673</td>
      <td>0.868280</td>
      <td>0.8178</td>
    </tr>
    <tr>
      <th>1.702311e+07</th>
      <td>0.999054</td>
      <td>0.956700</td>
      <td>0.862046</td>
      <td>0.861419</td>
      <td>0.8114</td>
    </tr>
    <tr>
      <th>2.030806e+07</th>
      <td>0.999054</td>
      <td>0.956459</td>
      <td>0.862544</td>
      <td>0.861794</td>
      <td>0.8101</td>
    </tr>
    <tr>
      <th>1.572724e+07</th>
      <td>0.999054</td>
      <td>0.960067</td>
      <td>0.863538</td>
      <td>0.861045</td>
      <td>0.8065</td>
    </tr>
    <tr>
      <th>1.702311e+07</th>
      <td>0.999054</td>
      <td>0.959827</td>
      <td>0.864699</td>
      <td>0.862542</td>
      <td>0.8064</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[120]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">group_by_lmbda</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;lmbdas&#39;</span><span class="p">])</span>
<span class="n">df1</span> <span class="o">=</span> <span class="n">group_by_lmbda</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
<span class="n">display</span><span class="p">(</span><span class="n">df1</span><span class="p">)</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">group_by_lmbda</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
<span class="n">display</span><span class="p">(</span><span class="n">df2</span><span class="p">)</span>
<span class="n">df3</span> <span class="o">=</span> <span class="n">group_by_lmbda</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
<span class="n">display</span><span class="p">(</span><span class="n">df3</span><span class="p">)</span>
<span class="n">df4</span> <span class="o">=</span> <span class="n">group_by_lmbda</span><span class="o">.</span><span class="n">median</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
<span class="n">display</span><span class="p">(</span><span class="n">df4</span><span class="p">)</span>
<span class="n">df5</span> <span class="o">=</span> <span class="n">group_by_lmbda</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
<span class="n">display</span><span class="p">(</span><span class="n">df5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>lmbdas</th>
      <th>15727241.73916555</th>
      <th>17023113.865521524</th>
      <th>20308059.84228695</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.998582</td>
      <td>0.998582</td>
      <td>0.998582</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.945874</td>
      <td>0.945634</td>
      <td>0.946115</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.859725</td>
      <td>0.860388</td>
      <td>0.862046</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.828240</td>
      <td>0.827991</td>
      <td>0.838967</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.781000</td>
      <td>0.780300</td>
      <td>0.791400</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>lmbdas</th>
      <th>15727241.73916555</th>
      <th>17023113.865521524</th>
      <th>20308059.84228695</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.999054</td>
      <td>0.999054</td>
      <td>0.999054</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.965119</td>
      <td>0.965119</td>
      <td>0.965360</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.913945</td>
      <td>0.913945</td>
      <td>0.913779</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.898840</td>
      <td>0.899588</td>
      <td>0.900836</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.840600</td>
      <td>0.840600</td>
      <td>0.840800</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>lmbdas</th>
      <th>15727241.73916555</th>
      <th>17023113.865521524</th>
      <th>20308059.84228695</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.998913</td>
      <td>0.998913</td>
      <td>0.998913</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.957638</td>
      <td>0.957590</td>
      <td>0.957662</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.882607</td>
      <td>0.882209</td>
      <td>0.882806</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.870151</td>
      <td>0.869714</td>
      <td>0.871623</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.816820</td>
      <td>0.816400</td>
      <td>0.818160</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>lmbdas</th>
      <th>15727241.73916555</th>
      <th>17023113.865521524</th>
      <th>20308059.84228695</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.999054</td>
      <td>0.999054</td>
      <td>0.999054</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.958865</td>
      <td>0.958744</td>
      <td>0.958744</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.872243</td>
      <td>0.871580</td>
      <td>0.872161</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.868155</td>
      <td>0.865349</td>
      <td>0.867407</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.815500</td>
      <td>0.812550</td>
      <td>0.812750</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>lmbdas</th>
      <th>15727241.73916555</th>
      <th>17023113.865521524</th>
      <th>20308059.84228695</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.000228</td>
      <td>0.000228</td>
      <td>0.000228</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.006465</td>
      <td>0.006496</td>
      <td>0.006413</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.021855</td>
      <td>0.022304</td>
      <td>0.021914</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.023140</td>
      <td>0.023470</td>
      <td>0.021473</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.019461</td>
      <td>0.019838</td>
      <td>0.018690</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[104]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1">#fig, ax = plt.subplots(figsize=(4.5,2.5))</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">4.75</span><span class="p">,</span><span class="mf">3.0</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.linewidth&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.markersize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;xtick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">13</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;ytick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;legend.fontsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">df2</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">b</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasks&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[104]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Text(0.5,0,&#39;Tasks&#39;)</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[60]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span><span class="mf">3.25</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.linewidth&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.markersize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;xtick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">13</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;ytick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;legend.fontsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">df3</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">b</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasks&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[60]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Text(0.5,0,&#39;Tasks&#39;)</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[105]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">Min</span> <span class="o">=</span> <span class="n">df1</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">Max</span> <span class="o">=</span> <span class="n">df2</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">Mean</span> <span class="o">=</span> <span class="n">df3</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">final_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Min&#39;</span><span class="p">:</span><span class="n">Mini</span><span class="p">,</span> <span class="s1">&#39;Max&#39;</span><span class="p">:</span><span class="n">Maxi</span><span class="p">,</span> <span class="s1">&#39;Mean&#39;</span><span class="p">:</span><span class="n">Mean</span><span class="p">})</span>
<span class="n">final_df</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[105]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Max</th>
      <th>Mean</th>
      <th>Min</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.999054</td>
      <td>0.998913</td>
      <td>0.998582</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.965119</td>
      <td>0.957662</td>
      <td>0.945874</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.913945</td>
      <td>0.882806</td>
      <td>0.859725</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.898840</td>
      <td>0.871623</td>
      <td>0.828240</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.840600</td>
      <td>0.818160</td>
      <td>0.781000</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[106]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">final_df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s1">&#39;Task&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">final_df</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[106]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Max</th>
      <th>Mean</th>
      <th>Min</th>
    </tr>
    <tr>
      <th>Task</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.999054</td>
      <td>0.998913</td>
      <td>0.998582</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.965119</td>
      <td>0.957662</td>
      <td>0.945874</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.913945</td>
      <td>0.882806</td>
      <td>0.859725</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.898840</td>
      <td>0.871623</td>
      <td>0.828240</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.840600</td>
      <td>0.818160</td>
      <td>0.781000</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[119]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">4.75</span><span class="p">,</span><span class="mf">3.0</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.linewidth&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.markersize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;xtick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">13</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;ytick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;legend.fontsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">final_df</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Mean&#39;</span><span class="p">,</span><span class="s1">&#39;Max&#39;</span><span class="p">,</span><span class="s1">&#39;Min&#39;</span><span class="p">],</span><span class="n">x</span><span class="o">=</span><span class="n">final_df</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="nb">str</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span> <span class="nb">str</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)),</span> <span class="nb">str</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">)),</span> <span class="nb">str</span><span class="p">((</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">)),</span> <span class="nb">str</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">))])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">b</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;../outputs/tg_mnist_results_cl/disjoint_accuracy.pdf&#39;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;../outputs/tg_mnist_results_cl/disjoint_accuracy.png&#39;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;../outputs/tg_mnist_results_cl/disjoint_accuracy.eps&#39;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Init-the-writer-with--best-$\lambda$s-and-train-$10\%$-of-previous-samples">Init the writer with  best $\lambda$s and train $10\%$ of previous samples<a class="anchor-link" href="#Init-the-writer-with--best-$\lambda$s-and-train-$10\%$-of-previous-samples">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;/home/ruthvik/Desktop/Summer 2017/tf_graph_outputs/mnist/continual_learning/original_mnist_5sets&#39;</span>
<span class="n">merged</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">merge_all</span><span class="p">()</span>
<span class="n">train_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="s1">&#39;/spike_mnist_ar1_final_5pc&#39;</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Generate-$\lambda$s">Generate $\lambda$s<a class="anchor-link" href="#Generate-$\lambda$s">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">n_lmbdas</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mf">111.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">220</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_lmbdas</span><span class="p">,))</span>
<span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="k">print</span><span class="p">()</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">*</span><span class="mf">1.0e5</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">a</span><span class="p">)]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">a</span><span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:]</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">+</span><span class="p">[</span><span class="mf">1.5</span><span class="o">*</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="k">print</span><span class="p">()</span>
<span class="n">n_reps</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1">#a = ([0]+a.tolist())*n_reps</span>
<span class="c1">#n_lmbdas+=1</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">*</span><span class="n">n_reps</span>
<span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[170.23113866 141.34226298 157.27241739 203.08059842 111.51435532
 124.25103417]
()
[20308059.84228695, 30462089.763430428]
()
([20308059.84228695, 30462089.763430428, 20308059.84228695, 30462089.763430428, 20308059.84228695, 30462089.763430428, 20308059.84228695, 30462089.763430428, 20308059.84228695, 30462089.763430428, 20308059.84228695, 30462089.763430428, 20308059.84228695, 30462089.763430428, 20308059.84228695, 30462089.763430428, 20308059.84228695, 30462089.763430428, 20308059.84228695, 30462089.763430428], 20)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Generate-random-weights">Generate random weights<a class="anchor-link" href="#Generate-random-weights">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">lmbdas</span> <span class="o">=</span> <span class="n">a</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">np_weights</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">n_lmbdas</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">low</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="o">/</span><span class="p">(</span><span class="n">n_input</span><span class="p">))</span> <span class="c1"># use 4 for sigmoid, 1 for tanh activation </span>
<span class="n">high</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="o">/</span><span class="p">(</span><span class="n">n_input</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_reps</span><span class="p">):</span>
    <span class="n">np_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">low</span><span class="p">,</span><span class="n">high</span><span class="o">=</span><span class="n">high</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_input</span><span class="p">,</span><span class="n">n_middle</span><span class="p">)))</span>

<span class="n">np_weights</span><span class="o">=</span><span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">np_weights</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_lmbdas</span><span class="p">)]</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">np_weights</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">lmbdas</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(20, 20)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">np_weights</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">np_weights</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[13]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>True</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">np_weights</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">np_weights</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[14]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>False</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Commence-training">Commence training<a class="anchor-link" href="#Commence-training">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">START_TIME</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">method3_test_accs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1">#INITIALIZE THE NETWORK</span>
<span class="n">logging_count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init_op</span><span class="p">,</span><span class="n">options</span><span class="o">=</span><span class="n">run_options</span><span class="p">,</span> <span class="n">run_metadata</span><span class="o">=</span><span class="n">run_metadata</span><span class="p">)</span>
<span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">finalize</span><span class="p">()</span>
<span class="n">all_prev_task_test_accs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_prev_task_test_activs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_prev_task_test_accs_extra</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_prev_task_test_activs_extra</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">retrain_tes_acc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lmbdas</span><span class="p">)):</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Training with lmbda:{}, {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lmbdas</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">l</span><span class="p">))</span>
    <span class="c1">#sess.run(init_op,options=run_options, run_metadata=run_metadata)</span>
    <span class="n">zeta</span> <span class="o">=</span> <span class="mf">1e-3</span>
    <span class="n">new_big_omeg_w2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_input</span><span class="p">,</span><span class="n">n_middle</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">new_big_omeg_b2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">n_middle</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">w3_zeros</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_middle</span><span class="p">,</span><span class="n">n_out</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">b3_zeros</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">n_out</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">w3_accum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_middle</span><span class="p">,</span><span class="n">n_out</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">w3_accum</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">b3_accum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">n_out</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">b3_accum</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">reset_w2_grad_accum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_input</span><span class="p">,</span><span class="n">n_middle</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">reset_b2_grad_accum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">n_middle</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">start_w2</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">start_b2</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w_2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">w_2_update_placeholder</span><span class="p">:</span><span class="n">np_weights</span><span class="p">[</span><span class="n">l</span><span class="p">]})</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b_2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">b_2_update_placeholder</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">n_middle</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)})</span>
    <span class="n">end_w2</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">end_b2</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="n">old_test_data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">frac_old_train_images</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">frac_old_train_labels</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">historical_cross_test_acc</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">historical_train_accuracies</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">historical_train_costs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">historical_val_accuracies</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">historical_val_costs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">sets</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">)]</span>
    <span class="c1">#sets = [(0,4),(5,9)]</span>
    <span class="n">test_labels_set</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">prev_task_test_accs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">prev_task_test_activs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">prev_task_test_accs_extra</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">prev_task_test_activs_extra</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_test_samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">a_set</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sets</span><span class="p">)):</span>
        <span class="n">current_set</span> <span class="o">=</span> <span class="n">sets</span><span class="p">[</span><span class="n">a_set</span><span class="p">]</span>
        <span class="n">current_set_name</span> <span class="o">=</span> <span class="s1">&#39;set&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">a_set</span><span class="p">)</span>
        <span class="n">mask_val</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">num_classes</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">current_set</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">mask_val</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>
        <span class="n">set_mask_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">mask_val</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Current mask:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">set_mask_val</span><span class="p">))</span>
        <span class="n">train_data_set</span><span class="p">,</span> <span class="n">valid_data_set</span><span class="p">,</span> <span class="n">test_data_set</span> <span class="o">=</span> <span class="n">extract_class_data</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="n">current_set</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                                                      <span class="n">stop</span><span class="o">=</span><span class="n">current_set</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">train_images_set</span><span class="p">,</span> <span class="n">train_labels_set</span> <span class="o">=</span> <span class="n">train_data_set</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_data_set</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">valid_images_set</span><span class="p">,</span> <span class="n">valid_labels_set</span> <span class="o">=</span> <span class="n">valid_data_set</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">valid_data_set</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">test_images_set</span><span class="p">,</span> <span class="n">test_labels_set</span> <span class="o">=</span> <span class="n">test_data_set</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">test_data_set</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">n_test_samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_labels_set</span><span class="p">))</span>
        <span class="n">train_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_images_set</span><span class="p">)</span>
        <span class="n">n_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_images_set</span><span class="p">)</span><span class="o">/</span><span class="n">BATCH_SIZE</span>
        <span class="c1">#@@print(&#39;Number of batches:{}&#39;.format(n_batches))</span>


        <span class="c1">#@@set_omegas = [tf.assign(big_omeg_w2, new_big_omeg_w2), tf.assign(big_omeg_b2, new_big_omeg_b2)]</span>
        <span class="c1">#@@sess.run(set_omegas)</span>
        
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">big_omeg_w2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">big_omeg_w2_update_placeholder</span><span class="p">:</span><span class="n">new_big_omeg_w2</span><span class="p">})</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">big_omeg_b2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">big_omeg_b2_update_placeholder</span><span class="p">:</span><span class="n">new_big_omeg_b2</span><span class="p">})</span>

        <span class="c1">#@@reset_grad_accums = [tf.assign(w2_grad_accum, reset_w2_grad_accum),</span>
        <span class="c1">#@@                     tf.assign(b2_grad_accum, reset_b2_grad_accum)]</span>
        <span class="c1">#@@sess.run(reset_grad_accums)</span>
        
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w2_grad_accum_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">w2_grad_accum_update_placeholder</span><span class="p">:</span><span class="n">reset_w2_grad_accum</span><span class="p">})</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b2_grad_accum_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">b2_grad_accum_update_placeholder</span><span class="p">:</span><span class="n">reset_b2_grad_accum</span><span class="p">})</span>

        
        <span class="c1">#@@reset_w3 = [tf.assign(w_3, w3_zeros), tf.assign(b_3, b3_zeros)]</span>
        <span class="c1">#@@sess.run(reset_w3)</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w_3_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">w_3_update_placeholder</span><span class="p">:</span><span class="n">w3_zeros</span><span class="p">})</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b_3_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">b_3_update_placeholder</span><span class="p">:</span><span class="n">b3_zeros</span><span class="p">})</span>
    
        <span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="n">repeats</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">for</span> <span class="n">repeat</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">repeats</span><span class="p">):</span>
            <span class="c1">#tf.set_random_seed(l)</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Repeat:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">repeat</span><span class="p">))</span>
            <span class="n">train_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">train_costs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">val_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">val_costs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">best_val</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">first_params_set</span> <span class="o">=</span> <span class="bp">None</span>
            <span class="n">last_params_set</span> <span class="o">=</span> <span class="bp">None</span>
            <span class="n">T1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
                <span class="k">if</span><span class="p">(</span><span class="n">i</span><span class="o">==</span><span class="n">epochs</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                    <span class="n">start_w2</span><span class="p">,</span> <span class="n">start_b2</span> <span class="o">=</span> <span class="n">w_2</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">b_2</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="nb">iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">a_1</span><span class="p">:</span> <span class="n">train_images_set</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">train_labels_set</span><span class="p">,</span>
                                                      <span class="n">batch_size</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_images_set</span><span class="p">)})</span>
                <span class="c1">#@@print(&#39;Epoch:{}&#39;.format((i)))</span>
                <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

                <span class="c1">### CALCULATE TRAIN COSTS AND TRAIN ACCURACIES</span>
                <span class="n">train_cost</span><span class="p">,</span> <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">cost</span><span class="p">,</span> <span class="n">acct_res</span><span class="p">]</span> <span class="p">,</span><span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span> <span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> 
                                                                                     <span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">})</span>
                <span class="n">train_costs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_cost</span><span class="p">)</span>
                <span class="n">train_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_accuracy</span><span class="p">)</span>
                <span class="c1">#train_writer.add_summary(summary,logging_count)</span>
                <span class="k">if</span><span class="p">(</span><span class="n">i</span><span class="o">%</span><span class="k">2</span>==0):
                    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;training cost:{} and training accuracy:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_costs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">train_accuracies</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

                <span class="c1">### CALCULATE VALID COSTS AND VALID ACCURACIES</span>
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="nb">iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">a_1</span><span class="p">:</span> <span class="n">valid_images_set</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">valid_labels_set</span><span class="p">,</span>
                                                      <span class="n">batch_size</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_images_set</span><span class="p">)})</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="n">val_cost</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">predictions</span><span class="p">,</span><span class="n">acct_mat</span><span class="p">,</span><span class="n">acct_res</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">a_3</span><span class="p">],</span>
                                                      <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span> <span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span><span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">})</span>
                <span class="n">val_costs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_cost</span><span class="p">)</span>
                <span class="n">val_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_acc</span><span class="p">)</span>

                <span class="k">if</span><span class="p">(</span><span class="n">val_acc</span><span class="o">&gt;</span><span class="n">best_val</span><span class="p">):</span>
                    <span class="n">best_val</span> <span class="o">=</span> <span class="n">val_acc</span>
                    <span class="n">best_params_set1</span> <span class="o">=</span> <span class="p">[(</span><span class="n">w_2</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span><span class="n">b_2</span><span class="o">.</span><span class="n">eval</span><span class="p">()),(</span><span class="n">w_3</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span><span class="n">b_3</span><span class="o">.</span><span class="n">eval</span><span class="p">())]</span>
                <span class="k">if</span><span class="p">(</span><span class="n">i</span><span class="o">%</span><span class="k">2</span>==0):
                    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;validation cost:{} and validation accuracy:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">val_cost</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">))</span>   
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="nb">iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">a_1</span><span class="p">:</span> <span class="n">train_images_set</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">train_labels_set</span><span class="p">,</span>
                                                      <span class="n">batch_size</span><span class="p">:</span> <span class="n">BATCH_SIZE</span><span class="p">})</span>
                <span class="k">if</span><span class="p">(</span><span class="n">i</span><span class="o">%</span><span class="k">2</span>==0):
                    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Training on :{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">current_set</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_batches</span><span class="p">):</span>

                    <span class="k">if</span><span class="p">(</span><span class="ow">not</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">w_2</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">w_3</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span><span class="o">.</span><span class="n">any</span><span class="p">()))):</span>
                        <span class="c1">#if(a_set==1):</span>
                        <span class="c1">#    print(j, w_2.eval().sum(), w_3.eval().sum())</span>
                        <span class="k">if</span><span class="p">(((</span><span class="n">j</span><span class="p">)</span><span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span><span class="mi">0</span><span class="p">)):</span>
                            <span class="n">logging_count</span><span class="o">+=</span><span class="mi">1</span>
                            <span class="k">if</span><span class="p">(</span><span class="n">i</span><span class="o">==</span><span class="n">epochs</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>   
                                <span class="n">summary</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">merged</span><span class="p">,</span><span class="n">step</span><span class="p">,</span> <span class="n">omega_step</span><span class="p">],</span> 
                                                     <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span><span class="n">batch_size</span><span class="p">:</span> <span class="n">BATCH_SIZE</span><span class="p">,</span><span class="n">tau</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span>
                                                                  <span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">,</span><span class="n">eta</span><span class="p">:</span><span class="mf">0.001</span><span class="p">,</span>
                                                                  <span class="n">lmbda</span><span class="p">:</span><span class="n">lmbdas</span><span class="p">[</span><span class="n">l</span><span class="p">],</span><span class="n">n_tot</span><span class="p">:</span><span class="n">train_total</span><span class="p">,</span>
                                                                 <span class="n">gradient_gate</span><span class="p">:</span><span class="mi">1</span><span class="p">})</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">summary</span><span class="p">,</span><span class="n">_</span><span class="p">,</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">merged</span><span class="p">,</span><span class="n">step</span><span class="p">],</span> 
                                                     <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span><span class="n">batch_size</span><span class="p">:</span> <span class="n">BATCH_SIZE</span><span class="p">,</span><span class="n">tau</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span>
                                                                  <span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">,</span><span class="n">eta</span><span class="p">:</span><span class="mf">0.001</span><span class="p">,</span>
                                                                  <span class="n">lmbda</span><span class="p">:</span><span class="n">lmbdas</span><span class="p">[</span><span class="n">l</span><span class="p">],</span><span class="n">n_tot</span><span class="p">:</span><span class="n">train_total</span><span class="p">,</span>
                                                                 <span class="n">gradient_gate</span><span class="p">:</span><span class="mi">1</span><span class="p">})</span>
                            <span class="c1">#train_writer.add_summary(summary, (i+1)*j)</span>
                            <span class="n">train_writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="n">logging_count</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">if</span><span class="p">(</span><span class="n">i</span><span class="o">==</span><span class="n">epochs</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">step</span><span class="p">,</span> <span class="n">omega_step</span><span class="p">],</span><span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span><span class="n">batch_size</span><span class="p">:</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                                                                         <span class="n">tau</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span><span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">,</span>
                                                                         <span class="n">eta</span><span class="p">:</span><span class="mf">0.001</span><span class="p">,</span><span class="n">lmbda</span><span class="p">:</span><span class="n">lmbdas</span><span class="p">[</span><span class="n">l</span><span class="p">],</span>
                                                                         <span class="n">n_tot</span><span class="p">:</span><span class="n">train_total</span><span class="p">,</span>
                                                                        <span class="n">gradient_gate</span><span class="p">:</span><span class="mi">1</span><span class="p">})</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">step</span><span class="p">],</span><span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span><span class="n">batch_size</span><span class="p">:</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                                                                     <span class="n">tau</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span><span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">,</span>
                                                                     <span class="n">eta</span><span class="p">:</span><span class="mf">0.001</span><span class="p">,</span><span class="n">lmbda</span><span class="p">:</span><span class="n">lmbdas</span><span class="p">[</span><span class="n">l</span><span class="p">],</span>
                                                                     <span class="n">n_tot</span><span class="p">:</span><span class="n">train_total</span><span class="p">,</span>
                                                            <span class="n">gradient_gate</span><span class="p">:</span><span class="mi">1</span><span class="p">})</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Nan encountered in epoch:{} and batch:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">))</span>
                <span class="c1">#@@print(&#39;Epoch time:{}&#39;.format(time.time()-t1))</span>


            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="nb">iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">a_1</span><span class="p">:</span> <span class="n">test_images_set</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">test_labels_set</span><span class="p">,</span>
                                                      <span class="n">batch_size</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_images_set</span><span class="p">)})</span>
            <span class="n">_</span><span class="p">,</span><span class="n">final_test_acc</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">predictions</span><span class="p">,</span> <span class="n">acct_res</span><span class="p">,</span> <span class="n">a_3</span><span class="p">],</span> 
                                                                  <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span> 
                                                                               <span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">})</span>
            <span class="c1">#@@print(&#39;Final test accuracy is:{}&#39;.format(final_test_acc))</span>
            <span class="n">end_w2</span><span class="p">,</span> <span class="n">end_b2</span><span class="p">,</span> <span class="n">end_w3</span><span class="p">,</span> <span class="n">end_b3</span> <span class="o">=</span> <span class="n">w_2</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">b_2</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">w_3</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">b_3</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="c1">#@@update_star_wbs = [tf.assign(star_w2,end_w2),tf.assign(star_b2,end_b2)]</span>
            <span class="c1">#@@sess.run(update_star_wbs)</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">star_w2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">star_w2_update_placeholder</span><span class="p">:</span><span class="n">end_w2</span><span class="p">})</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">star_b2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">star_b2_update_placeholder</span><span class="p">:</span><span class="n">end_b2</span><span class="p">})</span>
            
            
            <span class="c1">#all_final_test_accs_set1.append(final_test_acc)</span>


            <span class="c1">#@@best_step = [tf.assign(w_2,best_params_set1[0][0]), tf.assign(b_2,best_params_set1[0][1]),</span>
            <span class="c1">#@@             tf.assign(w_3,best_params_set1[1][0]),tf.assign(b_3,best_params_set1[1][1])]</span>
            <span class="c1">#@@sess.run(best_step)</span>
            
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w_2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">w_2_update_placeholder</span><span class="p">:</span><span class="n">best_params_set1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]})</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b_2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">b_2_update_placeholder</span><span class="p">:</span><span class="n">best_params_set1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]})</span>
            
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w_3_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">w_3_update_placeholder</span><span class="p">:</span><span class="n">best_params_set1</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]})</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b_3_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">b_3_update_placeholder</span><span class="p">:</span><span class="n">best_params_set1</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]})</span>
            
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="nb">iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">a_1</span><span class="p">:</span> <span class="n">test_images_set</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">test_labels_set</span><span class="p">,</span>
                                                      <span class="n">batch_size</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_images_set</span><span class="p">)})</span>
            <span class="n">_</span><span class="p">,</span><span class="n">test_acc_corresp_best_val</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">predictions</span><span class="p">,</span> <span class="n">acct_res</span><span class="p">,</span> <span class="n">a_3</span><span class="p">],</span>
                                                     <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span><span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">})</span>

            <span class="c1">#@@print(&#39;Test accuracy corresp to best val acc:{}&#39;.format(test_acc_corresp_best_val))</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Time taken:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">T1</span><span class="p">))</span>
            <span class="c1">#w3_list.append(w_3.eval())</span>
            <span class="n">w3_accum</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w_3</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span>
            <span class="c1">#b3_list.append(b_3.eval())</span>
            <span class="n">b3_accum</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">b_3</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span>
            <span class="k">if</span><span class="p">(</span><span class="n">i</span><span class="o">==</span><span class="n">epochs</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="k">if</span><span class="p">(</span><span class="n">test_acc_corresp_best_val</span><span class="o">&gt;</span><span class="n">final_test_acc</span><span class="p">):</span>
                    <span class="n">end_w2</span><span class="p">,</span> <span class="n">end_b2</span><span class="p">,</span> <span class="n">end_w3</span><span class="p">,</span> <span class="n">end_b3</span> <span class="o">=</span> <span class="n">w_2</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">b_2</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">w_3</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">b_3</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
                    <span class="c1">#all_final_test_accs_set1[-1] = test_acc_corresp_best_val</span>
                    <span class="c1">#@@update_star_wbs = [tf.assign(star_w2,end_w2),tf.assign(star_b2,end_b2)]</span>
                    <span class="c1">#@@sess.run(update_star_wbs)</span>
                    
                    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">star_w2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">star_w2_update_placeholder</span><span class="p">:</span><span class="n">end_w2</span><span class="p">})</span>
                    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">star_b2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">star_b2_update_placeholder</span><span class="p">:</span><span class="n">end_b2</span><span class="p">})</span>
                    

                <span class="c1">#@@best_step = [tf.assign(w_2,end_w2), tf.assign(b_2,end_b2),</span>
                <span class="c1">#@@         tf.assign(w_3,end_w3),tf.assign(b_3,end_b3)]</span>
                <span class="c1">#@@sess.run(best_step)</span>
                
                
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w_2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">w_2_update_placeholder</span><span class="p">:</span><span class="n">end_w2</span><span class="p">})</span>
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b_2_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">b_2_update_placeholder</span><span class="p">:</span><span class="n">end_b2</span><span class="p">})</span>
                
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w_3_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">w_3_update_placeholder</span><span class="p">:</span><span class="n">end_w3</span><span class="p">})</span>
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b_3_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">b_3_update_placeholder</span><span class="p">:</span><span class="n">end_b3</span><span class="p">})</span>

                <span class="n">first_params_set</span> <span class="o">=</span> <span class="p">[(</span><span class="n">start_w2</span><span class="p">,</span> <span class="n">start_b2</span><span class="p">)]</span>
                <span class="n">last_params_set</span> <span class="o">=</span> <span class="p">[(</span><span class="n">end_w2</span><span class="p">,</span> <span class="n">end_b2</span><span class="p">)]</span>

                <span class="n">small_omegas</span> <span class="o">=</span> <span class="p">[(</span><span class="n">w2_grad_accum</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span><span class="n">b2_grad_accum</span><span class="o">.</span><span class="n">eval</span><span class="p">())]</span>

                <span class="n">delta_ws</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">+</span><span class="n">zeta</span><span class="p">,[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">last_params_set</span><span class="p">],</span>
                           <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">first_params_set</span><span class="p">])</span>

                <span class="n">delta_bs</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">+</span><span class="n">zeta</span><span class="p">,[</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">last_params_set</span><span class="p">],</span>
                           <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">first_params_set</span><span class="p">])</span>
                <span class="n">delta_wbs</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">delta_ws</span><span class="p">,</span> <span class="n">delta_bs</span><span class="p">)</span>

                <span class="n">big_omegas_ws</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="o">/</span><span class="n">y</span><span class="p">),[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">small_omegas</span><span class="p">],</span>
                           <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">delta_wbs</span><span class="p">])</span>            
                <span class="n">big_omegas_bs</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="o">/</span><span class="n">y</span><span class="p">),[</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">small_omegas</span><span class="p">],</span>
                           <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">delta_wbs</span><span class="p">])</span>

                <span class="n">big_omegas</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">big_omegas_ws</span><span class="p">,</span> <span class="n">big_omegas_bs</span><span class="p">)</span>
                <span class="n">new_big_omeg_w2</span> <span class="o">+=</span> <span class="n">big_omegas</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">new_big_omeg_b2</span> <span class="o">+=</span> <span class="n">big_omegas</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
                <span class="c1">#@@print(&#39;omegW2-MAXIMUM:{},MEAN:{},STD:{}&#39;.format(new_big_omeg_w2.max(),</span>
                <span class="c1">#@@                                                new_big_omeg_w2.mean(),</span>
                <span class="c1">#@@                                                new_big_omeg_w2.std()))</span>
                <span class="c1">#@@print(&#39;omegb2-MAXIMUM:{},MEAN:{},STD:{}&#39;.format(new_big_omeg_b2.max(),</span>
                <span class="c1">#@@                                                new_big_omeg_b2.mean(),</span>
                <span class="c1">#@@                                                new_big_omeg_b2.std()))</span>

        <span class="n">historical_train_accuracies</span><span class="p">[</span><span class="n">current_set_name</span><span class="p">]</span><span class="o">=</span><span class="n">train_accuracies</span>
        <span class="n">historical_train_costs</span><span class="p">[</span><span class="n">current_set_name</span><span class="p">]</span><span class="o">=</span><span class="n">train_costs</span>
        <span class="n">historical_val_accuracies</span><span class="p">[</span><span class="n">current_set_name</span><span class="p">]</span><span class="o">=</span><span class="n">val_accuracies</span>
        <span class="n">historical_val_costs</span><span class="p">[</span><span class="n">current_set_name</span><span class="p">]</span><span class="o">=</span><span class="n">val_costs</span>
        
        <span class="n">old_test_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_data_set</span><span class="p">)</span>
        <span class="n">frac_old_train_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_images_set</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_images_set</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">*</span><span class="mf">0.1</span><span class="p">),:])</span>
        <span class="n">frac_old_train_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_labels_set</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_images_set</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">*</span><span class="mf">0.1</span><span class="p">),:])</span>
        <span class="c1">#######Method 3 ###########</span>
        <span class="n">w3_set_rows</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">offset</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">w3_accum</span><span class="p">:</span>
            <span class="n">w3_set_rows</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">[:,</span><span class="n">offset</span><span class="p">:</span><span class="n">offset</span><span class="o">+</span><span class="mi">2</span><span class="p">])</span>
            <span class="n">offset</span><span class="o">+=</span><span class="mi">2</span>


        <span class="n">w3_set_row_avgs</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">w3_set_rows</span><span class="p">]</span>
        <span class="n">final_w3</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">,</span><span class="n">w3_set_rows</span><span class="p">,</span> <span class="n">w3_set_row_avgs</span><span class="p">)</span>
        <span class="c1">#final_w3 = np.concatenate(final_w3, axis=1)</span>
        <span class="n">final_w3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">final_w3</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1500</span><span class="p">,</span><span class="mi">10</span><span class="o">-</span><span class="n">offset</span><span class="p">))],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">b3_set_rows</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">offset</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">b3_accum</span><span class="p">:</span>
            <span class="n">b3_set_rows</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">[:,</span><span class="n">offset</span><span class="p">:</span><span class="n">offset</span><span class="o">+</span><span class="mi">2</span><span class="p">])</span>
            <span class="n">offset</span><span class="o">+=</span><span class="mi">2</span>
        <span class="n">b3_set_row_avgs</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">b3_set_rows</span><span class="p">]</span>
        <span class="n">final_b3</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">,</span><span class="n">b3_set_rows</span><span class="p">,</span> <span class="n">b3_set_row_avgs</span><span class="p">)</span>
        <span class="c1">#final_b3 = np.concatenate(final_b3, axis=1)</span>
        <span class="n">final_b3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">final_b3</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="o">-</span><span class="n">offset</span><span class="p">))],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1">#@@set_w3 = [tf.assign(w_3, final_w3), tf.assign(b_3, final_b3)]</span>
        <span class="c1">#@@sess.run(set_w3)</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w_3_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">w_3_update_placeholder</span><span class="p">:</span><span class="n">final_w3</span><span class="p">})</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b_3_update_op</span><span class="p">,</span> <span class="p">{</span><span class="n">b_3_update_placeholder</span><span class="p">:</span><span class="n">final_b3</span><span class="p">})</span>
        
        <span class="k">for</span> <span class="n">items</span> <span class="ow">in</span> <span class="n">old_test_data</span><span class="p">:</span>
            <span class="n">test_images_set</span><span class="p">,</span> <span class="n">test_labels_set</span> <span class="o">=</span> <span class="n">items</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">items</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="nb">iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">a_1</span><span class="p">:</span> <span class="n">test_images_set</span><span class="p">,</span> 
                                                  <span class="n">y</span><span class="p">:</span><span class="n">test_labels_set</span><span class="p">,</span>
                                                  <span class="n">batch_size</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_images_set</span><span class="p">)})</span>
            <span class="n">_</span><span class="p">,</span><span class="n">final_test_acc</span><span class="p">,</span><span class="n">final_test_activ</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">predictions</span><span class="p">,</span> <span class="n">acct_res</span><span class="p">,</span> <span class="n">a_3</span><span class="p">],</span>
                                      <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span><span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">})</span>
            <span class="n">prev_task_test_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_test_acc</span><span class="p">)</span>
            <span class="n">prev_task_test_activs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_test_activ</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Method 3 test accuracy:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">final_test_acc</span><span class="p">))</span>
        
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Extra training..&#39;</span><span class="p">)</span>
        <span class="n">enlarged_train_imgs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">frac_old_train_images</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">enlarged_train_lbls</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">frac_old_train_labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">extra_X</span><span class="p">,</span> <span class="n">extra_y</span> <span class="o">=</span> <span class="n">shuffle</span><span class="p">(</span><span class="n">enlarged_train_imgs</span><span class="p">,</span> <span class="n">enlarged_train_lbls</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1">#extra_X = extra_X.astype(np.float32)</span>
        <span class="c1">#extra_y = extra_y.astype(np.float32)</span>
        <span class="k">for</span> <span class="n">rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="nb">iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">a_1</span><span class="p">:</span> <span class="n">extra_X</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">extra_y</span><span class="p">,</span>
                                                      <span class="n">batch_size</span><span class="p">:</span> <span class="n">BATCH_SIZE</span><span class="p">})</span>
            <span class="n">enlarged_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">enlarged_train_imgs</span><span class="p">)</span><span class="o">/</span><span class="n">BATCH_SIZE</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">enlarged_batches</span><span class="p">):</span>
                <span class="k">if</span><span class="p">(</span><span class="ow">not</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">w_2</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span> <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">w_3</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span><span class="o">.</span><span class="n">any</span><span class="p">()))):</span>        
                    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">step</span><span class="p">,</span> <span class="n">omega_step</span><span class="p">],</span><span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span><span class="n">batch_size</span><span class="p">:</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                                                             <span class="n">tau</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span><span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">,</span>
                                                             <span class="n">eta</span><span class="p">:</span><span class="mf">0.001</span><span class="p">,</span><span class="n">lmbda</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span>
                                                             <span class="n">n_tot</span><span class="p">:</span><span class="n">train_total</span><span class="p">,</span>
                                                            <span class="n">gradient_gate</span><span class="p">:</span><span class="mf">1.0</span><span class="p">})</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Nan encountered in epoch:{} and batch:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">))</span>
        
        <span class="k">for</span> <span class="n">items</span> <span class="ow">in</span> <span class="n">old_test_data</span><span class="p">:</span>
            <span class="n">test_images_set</span><span class="p">,</span> <span class="n">test_labels_set</span> <span class="o">=</span> <span class="n">items</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">items</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="nb">iter</span><span class="o">.</span><span class="n">initializer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">a_1</span><span class="p">:</span> <span class="n">test_images_set</span><span class="p">,</span> 
                                                  <span class="n">y</span><span class="p">:</span><span class="n">test_labels_set</span><span class="p">,</span>
                                                  <span class="n">batch_size</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_images_set</span><span class="p">)})</span>
            <span class="n">_</span><span class="p">,</span><span class="n">final_test_acc</span><span class="p">,</span><span class="n">final_test_activ</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">predictions</span><span class="p">,</span> <span class="n">acct_res</span><span class="p">,</span> <span class="n">a_3</span><span class="p">],</span>
                                      <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">drop_out</span><span class="p">:</span><span class="mf">0.0</span><span class="p">,</span><span class="n">set1_mask</span><span class="p">:</span><span class="n">set_mask_val</span><span class="p">})</span>
            <span class="n">prev_task_test_accs_extra</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_test_acc</span><span class="p">)</span>
            <span class="n">prev_task_test_activs_extra</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_test_activ</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Method 3 test accuracy after extra trai:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">final_test_acc</span><span class="p">))</span>
        
        <span class="n">w3_accum</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">w_3</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">b3_accum</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">b_3</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    
    <span class="n">all_prev_task_test_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prev_task_test_accs</span><span class="p">)</span>
    <span class="n">all_prev_task_test_activs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prev_task_test_activs</span><span class="p">)</span>
    
    <span class="n">all_prev_task_test_accs_extra</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prev_task_test_accs_extra</span><span class="p">)</span>
    <span class="n">all_prev_task_test_activs_extra</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prev_task_test_activs_extra</span><span class="p">)</span>
    
    <span class="c1">#sess.run(iter.initializer, feed_dict={a_1: test_images, y: to_categorical(test_labels,num_classes=num_classes),</span>
    <span class="c1">#                                                      batch_size: len(test_images)})</span>
    <span class="c1">#_,final_test_acc,_ = sess.run([predictions, acct_res, a_3],</span>
    <span class="c1">#                              feed_dict = {drop_out:0.0,set1_mask:set_mask_val})</span>
    <span class="c1">#method3_test_accs.append(final_test_acc)</span>
    <span class="c1">#print(&#39;Final test accuracy before extra training:{}&#39;.format(final_test_acc))</span>
    
    <span class="c1">#print(&#39;5pc training after sequential training is done&#39;)</span>
    
    <span class="c1">#sess.run(iter.initializer, feed_dict={a_1: test_images, y: to_categorical(test_labels,num_classes=num_classes),</span>
    <span class="c1">#                                                      batch_size: len(test_images)})</span>
    <span class="c1">#_,final_test_acc,_ = sess.run([predictions, acct_res, a_3],</span>
    <span class="c1">#                              feed_dict = {drop_out:0.0,set1_mask:set_mask_val})</span>
    <span class="c1">#method3_test_accs.append(final_test_acc)</span>
    <span class="c1">#print(&#39;Final test accuracy after extra training:{}&#39;.format(final_test_acc))</span>
    <span class="c1">#retrain_tes_acc.append(final_test_acc)</span>
                        
<span class="n">train_writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Total time:{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">START_TIME</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training with lmbda:20308059.8423, 0
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.0546306855977 and training accuracy:0.998178005219
validation cost:0.0556919276714 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226408895105 and training accuracy:0.998785376549
validation cost:0.0242020450532 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0147487148643 and training accuracy:0.998872101307
validation cost:0.016287503764 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0111239394173 and training accuracy:0.998872101307
validation cost:0.0125813987106 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:145.423539877
Method 3 test accuracy:0.999054372311
Extra training..
Method 3 test accuracy after extra trai:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.176673233509 and training accuracy:0.963003337383
validation cost:0.183698013425 and validation accuracy:0.961397051811
Training on :(2, 3)
training cost:0.0969242528081 and training accuracy:0.976547598839
validation cost:0.104484908283 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0705497935414 and training accuracy:0.983546972275
validation cost:0.0772370249033 and validation accuracy:0.978860318661
Training on :(2, 3)
training cost:0.05672320351 and training accuracy:0.986364901066
validation cost:0.0623193122447 and validation accuracy:0.983455896378
Training on :(2, 3)
Time taken:139.279695988
Method 3 test accuracy:0.988652467728
Method 3 test accuracy:0.92066603899
Extra training..
Method 3 test accuracy after extra trai:0.977777779102
Method 3 test accuracy after extra trai:0.955925583839
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.131810560822 and training accuracy:0.991317093372
validation cost:0.12752482295 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0694095939398 and training accuracy:0.994926810265
validation cost:0.0625713914633 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0486946590245 and training accuracy:0.995804905891
validation cost:0.0417511574924 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0382052697241 and training accuracy:0.996487796307
validation cost:0.0315381139517 and validation accuracy:1.0
Training on :(4, 5)
Time taken:129.177549124
Method 3 test accuracy:0.982978701591
Method 3 test accuracy:0.929480910301
Method 3 test accuracy:0.586446106434
Extra training..
Method 3 test accuracy after extra trai:0.977304935455
Method 3 test accuracy after extra trai:0.933398604393
Method 3 test accuracy after extra trai:0.844717204571
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.0951351970434 and training accuracy:0.995490193367
validation cost:0.0930638834834 and validation accuracy:0.994525551796
Training on :(6, 7)
training cost:0.0510101318359 and training accuracy:0.997203946114
validation cost:0.050360340625 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0365131273866 and training accuracy:0.998015701771
validation cost:0.0361876226962 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0290644336492 and training accuracy:0.998827457428
validation cost:0.0288508888334 and validation accuracy:1.0
Training on :(6, 7)
Time taken:140.482092857
Method 3 test accuracy:0.98156028986
Method 3 test accuracy:0.910871684551
Method 3 test accuracy:0.692636072636
Method 3 test accuracy:0.883182287216
Extra training..
Method 3 test accuracy after extra trai:0.970685601234
Method 3 test accuracy after extra trai:0.918217420578
Method 3 test accuracy after extra trai:0.860725700855
Method 3 test accuracy after extra trai:0.920443117619
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.162354066968 and training accuracy:0.967871129513
validation cost:0.163827449083 and validation accuracy:0.966101706028
Training on :(8, 9)
training cost:0.110276035964 and training accuracy:0.973272502422
validation cost:0.111833877861 and validation accuracy:0.973634660244
Training on :(8, 9)
training cost:0.0890907719731 and training accuracy:0.978208243847
validation cost:0.090332172811 and validation accuracy:0.983050823212
Training on :(8, 9)
training cost:0.0766249522567 and training accuracy:0.981374561787
validation cost:0.0775314718485 and validation accuracy:0.985875725746
Training on :(8, 9)
Time taken:137.065821171
Method 3 test accuracy:0.98061466217
Method 3 test accuracy:0.894221365452
Method 3 test accuracy:0.667022407055
Method 3 test accuracy:0.890735149384
Method 3 test accuracy:0.617750883102
Extra training..
Method 3 test accuracy after extra trai:0.966903090477
Method 3 test accuracy after extra trai:0.89177274704
Method 3 test accuracy after extra trai:0.800960540771
Method 3 test accuracy after extra trai:0.881168186665
Method 3 test accuracy after extra trai:0.839132606983
Training with lmbda:30462089.7634, 1
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.0546306855977 and training accuracy:0.998178005219
validation cost:0.0556919276714 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226408895105 and training accuracy:0.998785376549
validation cost:0.0242020450532 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0147487148643 and training accuracy:0.998872101307
validation cost:0.016287503764 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0111239394173 and training accuracy:0.998872101307
validation cost:0.0125813987106 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:144.409271955
Method 3 test accuracy:0.999054372311
Extra training..
Method 3 test accuracy after extra trai:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.17864818871 and training accuracy:0.963003337383
validation cost:0.185658425093 and validation accuracy:0.961397051811
Training on :(2, 3)
training cost:0.0984297245741 and training accuracy:0.976456701756
validation cost:0.105959877372 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0718252956867 and training accuracy:0.983183324337
validation cost:0.078507758677 and validation accuracy:0.977941155434
Training on :(2, 3)
training cost:0.0578409545124 and training accuracy:0.986274003983
validation cost:0.0634545683861 and validation accuracy:0.983455896378
Training on :(2, 3)
Time taken:139.516835213
Method 3 test accuracy:0.988652467728
Method 3 test accuracy:0.919196844101
Extra training..
Method 3 test accuracy after extra trai:0.977777779102
Method 3 test accuracy after extra trai:0.954946160316
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.138595372438 and training accuracy:0.991024374962
validation cost:0.134653329849 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0733894705772 and training accuracy:0.994829297066
validation cost:0.0667333453894 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0514821708202 and training accuracy:0.995707333088
validation cost:0.0446430183947 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0403481572866 and training accuracy:0.996292710304
validation cost:0.0337439626455 and validation accuracy:1.0
Training on :(4, 5)
Time taken:130.21454215
Method 3 test accuracy:0.983451545238
Method 3 test accuracy:0.928011775017
Method 3 test accuracy:0.597652077675
Extra training..
Method 3 test accuracy after extra trai:0.976832151413
Method 3 test accuracy after extra trai:0.93241918087
Method 3 test accuracy after extra trai:0.844717204571
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.102902777493 and training accuracy:0.995400011539
validation cost:0.100875586271 and validation accuracy:0.993613123894
Training on :(6, 7)
training cost:0.0556292161345 and training accuracy:0.997203946114
validation cost:0.0550914108753 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0398971959949 and training accuracy:0.997925519943
validation cost:0.0397024974227 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0317656733096 and training accuracy:0.998827457428
validation cost:0.0316872745752 and validation accuracy:1.0
Training on :(6, 7)
Time taken:139.859623909
Method 3 test accuracy:0.982033073902
Method 3 test accuracy:0.912340819836
Method 3 test accuracy:0.694770514965
Method 3 test accuracy:0.882175207138
Extra training..
Method 3 test accuracy after extra trai:0.970685601234
Method 3 test accuracy after extra trai:0.916748285294
Method 3 test accuracy after extra trai:0.855389535427
Method 3 test accuracy after extra trai:0.919939577579
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.173241958022 and training accuracy:0.966846704483
validation cost:0.174659848213 and validation accuracy:0.963276863098
Training on :(8, 9)
training cost:0.118262939155 and training accuracy:0.972341239452
validation cost:0.119837239385 and validation accuracy:0.971751391888
Training on :(8, 9)
training cost:0.0959713235497 and training accuracy:0.976438820362
validation cost:0.0973205715418 and validation accuracy:0.975517868996
Training on :(8, 9)
training cost:0.0828476324677 and training accuracy:0.978673875332
validation cost:0.083930939436 and validation accuracy:0.982109248638
Training on :(8, 9)
Time taken:135.062433958
Method 3 test accuracy:0.98061466217
Method 3 test accuracy:0.892262458801
Method 3 test accuracy:0.655816435814
Method 3 test accuracy:0.883182287216
Method 3 test accuracy:0.668179512024
Extra training..
Method 3 test accuracy after extra trai:0.967848718166
Method 3 test accuracy after extra trai:0.889324188232
Method 3 test accuracy after extra trai:0.794023454189
Method 3 test accuracy after extra trai:0.880664646626
Method 3 test accuracy after extra trai:0.839132606983
Training with lmbda:20308059.8423, 2
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.0555005222559 and training accuracy:0.998004496098
validation cost:0.0558135248721 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0225480105728 and training accuracy:0.998525083065
validation cost:0.0235897265375 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0145617239177 and training accuracy:0.998698592186
validation cost:0.0156639441848 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0109299588948 and training accuracy:0.998872101307
validation cost:0.0120089538395 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:144.64618206
Method 3 test accuracy:0.999054372311
Extra training..
Method 3 test accuracy after extra trai:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.177765607834 and training accuracy:0.96136713028
validation cost:0.18324676156 and validation accuracy:0.959558844566
Training on :(2, 3)
training cost:0.0979659035802 and training accuracy:0.975184082985
validation cost:0.104389593005 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0711897313595 and training accuracy:0.982183456421
validation cost:0.0770348832011 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.057101432234 and training accuracy:0.985819458961
validation cost:0.062054079026 and validation accuracy:0.980698525906
Training on :(2, 3)
Time taken:138.917208195
Method 3 test accuracy:0.988652467728
Method 3 test accuracy:0.92409402132
Extra training..
Method 3 test accuracy after extra trai:0.98061466217
Method 3 test accuracy after extra trai:0.960822701454
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.134575337172 and training accuracy:0.98946338892
validation cost:0.129823550582 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0705809593201 and training accuracy:0.994634151459
validation cost:0.0634420961142 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0493103787303 and training accuracy:0.995609760284
validation cost:0.0421929992735 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0385583490133 and training accuracy:0.996682941914
validation cost:0.0317967571318 and validation accuracy:1.0
Training on :(4, 5)
Time taken:133.73584795
Method 3 test accuracy:0.984397172928
Method 3 test accuracy:0.934378087521
Method 3 test accuracy:0.578975439072
Extra training..
Method 3 test accuracy after extra trai:0.979196190834
Method 3 test accuracy after extra trai:0.933888316154
Method 3 test accuracy after extra trai:0.850053369999
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.0932315289974 and training accuracy:0.994588255882
validation cost:0.0895357131958 and validation accuracy:0.994525551796
Training on :(6, 7)
training cost:0.0511328838766 and training accuracy:0.996933341026
validation cost:0.0488969236612 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0369884073734 and training accuracy:0.997835278511
validation cost:0.0351772345603 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0296172071248 and training accuracy:0.998466670513
validation cost:0.0280050355941 and validation accuracy:0.999087572098
Training on :(6, 7)
Time taken:139.778424025
Method 3 test accuracy:0.983924329281
Method 3 test accuracy:0.916748285294
Method 3 test accuracy:0.691035211086
Method 3 test accuracy:0.881168186665
Extra training..
Method 3 test accuracy after extra trai:0.971158385277
Method 3 test accuracy after extra trai:0.922624886036
Method 3 test accuracy after extra trai:0.864461064339
Method 3 test accuracy after extra trai:0.920443117619
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.164028078318 and training accuracy:0.966474175453
validation cost:0.163732260466 and validation accuracy:0.96516007185
Training on :(8, 9)
training cost:0.111271351576 and training accuracy:0.974390029907
validation cost:0.111451886594 and validation accuracy:0.97834277153
Training on :(8, 9)
training cost:0.089862652123 and training accuracy:0.978860139847
validation cost:0.0899702832103 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.077216386795 and training accuracy:0.981002032757
validation cost:0.0771088823676 and validation accuracy:0.98399245739
Training on :(8, 9)
Time taken:136.220026016
Method 3 test accuracy:0.979669034481
Method 3 test accuracy:0.89373165369
Method 3 test accuracy:0.646744906902
Method 3 test accuracy:0.893252789974
Method 3 test accuracy:0.64750379324
Extra training..
Method 3 test accuracy after extra trai:0.968794345856
Method 3 test accuracy after extra trai:0.894221365452
Method 3 test accuracy after extra trai:0.795624315739
Method 3 test accuracy after extra trai:0.883685827255
Method 3 test accuracy after extra trai:0.841149747372
Training with lmbda:30462089.7634, 3
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.0555005222559 and training accuracy:0.998004496098
validation cost:0.0558135248721 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0225480105728 and training accuracy:0.998525083065
validation cost:0.0235897265375 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0145617239177 and training accuracy:0.998698592186
validation cost:0.0156639441848 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0109299588948 and training accuracy:0.998872101307
validation cost:0.0120089538395 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:146.206530094
Method 3 test accuracy:0.999054372311
Extra training..
Method 3 test accuracy after extra trai:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.179689362645 and training accuracy:0.96136713028
validation cost:0.185165807605 and validation accuracy:0.958639681339
Training on :(2, 3)
training cost:0.0993841215968 and training accuracy:0.975093185902
validation cost:0.105783991516 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0723647624254 and training accuracy:0.982092559338
validation cost:0.0782119035721 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0581203922629 and training accuracy:0.985637664795
validation cost:0.0630946829915 and validation accuracy:0.980698525906
Training on :(2, 3)
Time taken:137.060606003
Method 3 test accuracy:0.988652467728
Method 3 test accuracy:0.924583733082
Extra training..
Method 3 test accuracy after extra trai:0.980141818523
Method 3 test accuracy after extra trai:0.959843277931
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.141061455011 and training accuracy:0.989268302917
validation cost:0.136626392603 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0743732824922 and training accuracy:0.994634151459
validation cost:0.0673781335354 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0519459806383 and training accuracy:0.995609760284
validation cost:0.0448944568634 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0405687950552 and training accuracy:0.996682941914
validation cost:0.0338371023536 and validation accuracy:1.0
Training on :(4, 5)
Time taken:128.891334057
Method 3 test accuracy:0.98486995697
Method 3 test accuracy:0.933398604393
Method 3 test accuracy:0.592315912247
Extra training..
Method 3 test accuracy after extra trai:0.979196190834
Method 3 test accuracy after extra trai:0.934867799282
Method 3 test accuracy after extra trai:0.847918868065
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.100690864027 and training accuracy:0.994407892227
validation cost:0.0969003513455 and validation accuracy:0.994525551796
Training on :(6, 7)
training cost:0.0557160787284 and training accuracy:0.996933341026
validation cost:0.0534512884915 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0403551384807 and training accuracy:0.997474491596
validation cost:0.0385488942266 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0322967916727 and training accuracy:0.998196065426
validation cost:0.030706256628 and validation accuracy:0.999087572098
Training on :(6, 7)
Time taken:141.057194948
Method 3 test accuracy:0.983924329281
Method 3 test accuracy:0.919196844101
Method 3 test accuracy:0.696371376514
Method 3 test accuracy:0.869587123394
Extra training..
Method 3 test accuracy after extra trai:0.971158385277
Method 3 test accuracy after extra trai:0.923604309559
Method 3 test accuracy after extra trai:0.859124839306
Method 3 test accuracy after extra trai:0.918429017067
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.174566730857 and training accuracy:0.966008543968
validation cost:0.174082145095 and validation accuracy:0.966101706028
Training on :(8, 9)
training cost:0.118920505047 and training accuracy:0.973365604877
validation cost:0.118878796697 and validation accuracy:0.976459503174
Training on :(8, 9)
training cost:0.096406981349 and training accuracy:0.977742612362
validation cost:0.0963543206453 and validation accuracy:0.98116761446
Training on :(8, 9)
training cost:0.0831161811948 and training accuracy:0.979791402817
validation cost:0.0829119607806 and validation accuracy:0.982109248638
Training on :(8, 9)
Time taken:136.458171844
Method 3 test accuracy:0.981087446213
Method 3 test accuracy:0.89373165369
Method 3 test accuracy:0.643543243408
Method 3 test accuracy:0.881671726704
Method 3 test accuracy:0.666666686535
Extra training..
Method 3 test accuracy after extra trai:0.969267129898
Method 3 test accuracy after extra trai:0.895200788975
Method 3 test accuracy after extra trai:0.790288150311
Method 3 test accuracy after extra trai:0.881168186665
Method 3 test accuracy after extra trai:0.838124036789
Training with lmbda:20308059.8423, 4
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.055508248508 and training accuracy:0.99809128046
validation cost:0.0561634711921 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0225540343672 and training accuracy:0.998698592186
validation cost:0.0237094499171 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0145592540503 and training accuracy:0.998785376549
validation cost:0.0157190151513 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0109200486913 and training accuracy:0.99895888567
validation cost:0.0120275393128 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:144.274086952
Method 3 test accuracy:0.999054372311
Extra training..
Method 3 test accuracy after extra trai:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.172346457839 and training accuracy:0.961912572384
validation cost:0.17839486897 and validation accuracy:0.959558844566
Training on :(2, 3)
training cost:0.0951601862907 and training accuracy:0.976638495922
validation cost:0.102140903473 and validation accuracy:0.966911792755
Training on :(2, 3)
training cost:0.0692198649049 and training accuracy:0.982637941837
validation cost:0.0754370093346 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0555538646877 and training accuracy:0.986546695232
validation cost:0.0606970861554 and validation accuracy:0.981617629528
Training on :(2, 3)
Time taken:138.605073929
Method 3 test accuracy:0.951300263405
Method 3 test accuracy:0.970127344131
Extra training..
Method 3 test accuracy after extra trai:0.977304935455
Method 3 test accuracy after extra trai:0.957884430885
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.131261855364 and training accuracy:0.990634143353
validation cost:0.127983137965 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0682520866394 and training accuracy:0.994731724262
validation cost:0.0624351799488 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.0475542247295 and training accuracy:0.995804905891
validation cost:0.0416084453464 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0371433459222 and training accuracy:0.99658536911
validation cost:0.0314334779978 and validation accuracy:0.999012827873
Training on :(4, 5)
Time taken:128.736809969
Method 3 test accuracy:0.933806121349
Method 3 test accuracy:0.958374142647
Method 3 test accuracy:0.7374599576
Extra training..
Method 3 test accuracy after extra trai:0.973995268345
Method 3 test accuracy after extra trai:0.935357511044
Method 3 test accuracy after extra trai:0.857524037361
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.0894195213914 and training accuracy:0.995850980282
validation cost:0.0865095481277 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0486732460558 and training accuracy:0.997654914856
validation cost:0.0469493977726 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0351247042418 and training accuracy:0.998015701771
validation cost:0.0337153449655 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0281074717641 and training accuracy:0.9987372756
validation cost:0.0268340855837 and validation accuracy:0.999087572098
Training on :(6, 7)
Time taken:138.853459835
Method 3 test accuracy:0.902600467205
Method 3 test accuracy:0.944172382355
Method 3 test accuracy:0.797225177288
Method 3 test accuracy:0.914904356003
Extra training..
Method 3 test accuracy after extra trai:0.967375874519
Method 3 test accuracy after extra trai:0.920176327229
Method 3 test accuracy after extra trai:0.874599814415
Method 3 test accuracy after extra trai:0.925478339195
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.164813309908 and training accuracy:0.964797914028
validation cost:0.166525200009 and validation accuracy:0.964218437672
Training on :(8, 9)
training cost:0.112539179623 and training accuracy:0.973644971848
validation cost:0.114754579961 and validation accuracy:0.975517868996
Training on :(8, 9)
training cost:0.0911723151803 and training accuracy:0.977556347847
validation cost:0.0933778658509 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.0785533860326 and training accuracy:0.980815768242
validation cost:0.0806043669581 and validation accuracy:0.982109248638
Training on :(8, 9)
Time taken:134.917087793
Method 3 test accuracy:0.89503544569
Method 3 test accuracy:0.914789438248
Method 3 test accuracy:0.768943428993
Method 3 test accuracy:0.907351434231
Method 3 test accuracy:0.695915281773
Extra training..
Method 3 test accuracy after extra trai:0.963593363762
Method 3 test accuracy after extra trai:0.891283035278
Method 3 test accuracy after extra trai:0.813233733177
Method 3 test accuracy after extra trai:0.885196387768
Method 3 test accuracy after extra trai:0.834089756012
Training with lmbda:30462089.7634, 5
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.055508248508 and training accuracy:0.99809128046
validation cost:0.0561634711921 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0225540343672 and training accuracy:0.998698592186
validation cost:0.0237094499171 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0145592540503 and training accuracy:0.998785376549
validation cost:0.0157190151513 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0109200486913 and training accuracy:0.99895888567
validation cost:0.0120275393128 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:144.549359083
Method 3 test accuracy:0.999054372311
Extra training..
Method 3 test accuracy after extra trai:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.174094676971 and training accuracy:0.961821675301
validation cost:0.180145397782 and validation accuracy:0.959558844566
Training on :(2, 3)
training cost:0.0964664965868 and training accuracy:0.976911187172
validation cost:0.103449784219 and validation accuracy:0.967830896378
Training on :(2, 3)
training cost:0.0703201070428 and training accuracy:0.982365250587
validation cost:0.076578065753 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0565215051174 and training accuracy:0.986728489399
validation cost:0.0617284849286 and validation accuracy:0.981617629528
Training on :(2, 3)
Time taken:138.671497822
Method 3 test accuracy:0.951300263405
Method 3 test accuracy:0.970127344131
Extra training..
Method 3 test accuracy after extra trai:0.976832151413
Method 3 test accuracy after extra trai:0.957884430885
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.137685969472 and training accuracy:0.990341484547
validation cost:0.134715914726 and validation accuracy:0.994077026844
Training on :(4, 5)
training cost:0.0718876123428 and training accuracy:0.994731724262
validation cost:0.0662267133594 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.0500529594719 and training accuracy:0.995804905891
validation cost:0.0441943630576 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0390500351787 and training accuracy:0.996487796307
validation cost:0.033394291997 and validation accuracy:0.999012827873
Training on :(4, 5)
Time taken:131.121545076
Method 3 test accuracy:0.933806121349
Method 3 test accuracy:0.958863854408
Method 3 test accuracy:0.742796182632
Extra training..
Method 3 test accuracy after extra trai:0.974940896034
Method 3 test accuracy after extra trai:0.935847222805
Method 3 test accuracy after extra trai:0.856456756592
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.0964604094625 and training accuracy:0.995760798454
validation cost:0.0935290530324 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0529270097613 and training accuracy:0.997654914856
validation cost:0.0512303039432 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0382729358971 and training accuracy:0.998105883598
validation cost:0.0369083359838 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0306594669819 and training accuracy:0.998647093773
validation cost:0.0294314585626 and validation accuracy:0.999087572098
Training on :(6, 7)
Time taken:141.061393976
Method 3 test accuracy:0.899290800095
Method 3 test accuracy:0.944662094116
Method 3 test accuracy:0.797758817673
Method 3 test accuracy:0.912890255451
Extra training..
Method 3 test accuracy after extra trai:0.967848718166
Method 3 test accuracy after extra trai:0.92066603899
Method 3 test accuracy after extra trai:0.87406617403
Method 3 test accuracy after extra trai:0.924471318722
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.175656497478 and training accuracy:0.963587284088
validation cost:0.177316874266 and validation accuracy:0.963276863098
Training on :(8, 9)
training cost:0.120664231479 and training accuracy:0.972620606422
validation cost:0.122833251953 and validation accuracy:0.971751391888
Training on :(8, 9)
training cost:0.0982600077987 and training accuracy:0.976811349392
validation cost:0.100484974682 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.0850254818797 and training accuracy:0.978487610817
validation cost:0.0871660560369 and validation accuracy:0.980225980282
Training on :(8, 9)
Time taken:134.388657808
Method 3 test accuracy:0.890307307243
Method 3 test accuracy:0.914299726486
Method 3 test accuracy:0.7625400424
Method 3 test accuracy:0.905840873718
Method 3 test accuracy:0.706505298615
Extra training..
Method 3 test accuracy after extra trai:0.963593363762
Method 3 test accuracy after extra trai:0.892262458801
Method 3 test accuracy after extra trai:0.80683028698
Method 3 test accuracy after extra trai:0.883182287216
Method 3 test accuracy after extra trai:0.831064045429
Training with lmbda:20308059.8423, 6
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.0548925288022 and training accuracy:0.998178005219
validation cost:0.0557739771903 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0224072262645 and training accuracy:0.998525083065
validation cost:0.0238557700068 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0145130045712 and training accuracy:0.998872101307
validation cost:0.0159453377128 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0109167657793 and training accuracy:0.999045610428
validation cost:0.0122721334919 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:144.856848955
Method 3 test accuracy:0.999054372311
Extra training..
Method 3 test accuracy after extra trai:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.174114122987 and training accuracy:0.963185191154
validation cost:0.178453266621 and validation accuracy:0.958639681339
Training on :(2, 3)
training cost:0.0968520715833 and training accuracy:0.976365804672
validation cost:0.101878151298 and validation accuracy:0.972426474094
Training on :(2, 3)
training cost:0.0706677436829 and training accuracy:0.982456147671
validation cost:0.0752144828439 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0568571351469 and training accuracy:0.986728489399
validation cost:0.0606752969325 and validation accuracy:0.985294103622
Training on :(2, 3)
Time taken:137.771406889
Method 3 test accuracy:0.986288428307
Method 3 test accuracy:0.929970622063
Extra training..
Method 3 test accuracy after extra trai:0.978723406792
Method 3 test accuracy after extra trai:0.958374142647
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.133445546031 and training accuracy:0.989560961723
validation cost:0.13000664115 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0701068267226 and training accuracy:0.993951201439
validation cost:0.0637895092368 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0491824261844 and training accuracy:0.995414614677
validation cost:0.0426119528711 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0386112853885 and training accuracy:0.996195137501
validation cost:0.0322372615337 and validation accuracy:1.0
Training on :(4, 5)
Time taken:129.506872892
Method 3 test accuracy:0.981087446213
Method 3 test accuracy:0.922135174274
Method 3 test accuracy:0.782283902168
Extra training..
Method 3 test accuracy after extra trai:0.978250563145
Method 3 test accuracy after extra trai:0.937316358089
Method 3 test accuracy after extra trai:0.851654231548
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.0927839204669 and training accuracy:0.995941221714
validation cost:0.0901629030704 and validation accuracy:0.994525551796
Training on :(6, 7)
training cost:0.0503793209791 and training accuracy:0.997835278511
validation cost:0.0491694062948 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.036322247237 and training accuracy:0.998466670513
validation cost:0.0354858413339 and validation accuracy:1.0
Training on :(6, 7)
training cost:0.0290678013116 and training accuracy:0.998827457428
validation cost:0.0283893384039 and validation accuracy:1.0
Training on :(6, 7)
Time taken:139.168591022
Method 3 test accuracy:0.981087446213
Method 3 test accuracy:0.911361396313
Method 3 test accuracy:0.827107787132
Method 3 test accuracy:0.834340393543
Extra training..
Method 3 test accuracy after extra trai:0.971631228924
Method 3 test accuracy after extra trai:0.918707132339
Method 3 test accuracy after extra trai:0.865528285503
Method 3 test accuracy after extra trai:0.914904356003
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.169550955296 and training accuracy:0.963028490543
validation cost:0.171564087272 and validation accuracy:0.961393594742
Training on :(8, 9)
training cost:0.114921808243 and training accuracy:0.971503078938
validation cost:0.117255322635 and validation accuracy:0.969868183136
Training on :(8, 9)
training cost:0.0926839336753 and training accuracy:0.977090716362
validation cost:0.0948332026601 and validation accuracy:0.979284346104
Training on :(8, 9)
training cost:0.0795948654413 and training accuracy:0.981188297272
validation cost:0.0814597010612 and validation accuracy:0.983050823212
Training on :(8, 9)
Time taken:135.05658102
Method 3 test accuracy:0.978723406792
Method 3 test accuracy:0.889324188232
Method 3 test accuracy:0.824973344803
Method 3 test accuracy:0.856998980045
Method 3 test accuracy:0.636913776398
Extra training..
Method 3 test accuracy after extra trai:0.970212757587
Method 3 test accuracy after extra trai:0.892262458801
Method 3 test accuracy after extra trai:0.820704400539
Method 3 test accuracy after extra trai:0.881671726704
Method 3 test accuracy after extra trai:0.838628351688
Training with lmbda:30462089.7634, 7
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.0548925288022 and training accuracy:0.998178005219
validation cost:0.0557739771903 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0224072262645 and training accuracy:0.998525083065
validation cost:0.0238557700068 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0145130045712 and training accuracy:0.998872101307
validation cost:0.0159453377128 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0109167657793 and training accuracy:0.999045610428
validation cost:0.0122721334919 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:144.8726511
Method 3 test accuracy:0.999054372311
Extra training..
Method 3 test accuracy after extra trai:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.176110476255 and training accuracy:0.963094234467
validation cost:0.180447757244 and validation accuracy:0.958639681339
Training on :(2, 3)
training cost:0.0983678922057 and training accuracy:0.976184010506
validation cost:0.103378280997 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0719466432929 and training accuracy:0.982456147671
validation cost:0.0764936134219 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0579792931676 and training accuracy:0.986364901066
validation cost:0.0618119724095 and validation accuracy:0.985294103622
Training on :(2, 3)
Time taken:138.216485977
Method 3 test accuracy:0.986288428307
Method 3 test accuracy:0.930950045586
Extra training..
Method 3 test accuracy after extra trai:0.979669034481
Method 3 test accuracy after extra trai:0.958374142647
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.140374183655 and training accuracy:0.98907315731
validation cost:0.13728658855 and validation accuracy:0.994077026844
Training on :(4, 5)
training cost:0.0741766542196 and training accuracy:0.993951201439
validation cost:0.0680406242609 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0520427413285 and training accuracy:0.995414614677
validation cost:0.0455714315176 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0408200137317 and training accuracy:0.996292710304
validation cost:0.0345016643405 and validation accuracy:1.0
Training on :(4, 5)
Time taken:129.084851027
Method 3 test accuracy:0.982033073902
Method 3 test accuracy:0.92066603899
Method 3 test accuracy:0.784951984882
Extra training..
Method 3 test accuracy after extra trai:0.978723406792
Method 3 test accuracy after extra trai:0.938295781612
Method 3 test accuracy after extra trai:0.851120591164
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.100383169949 and training accuracy:0.995670616627
validation cost:0.0977528989315 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0551327988505 and training accuracy:0.997654914856
validation cost:0.0539576262236 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0399021245539 and training accuracy:0.998376488686
validation cost:0.0391245670617 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.031990006566 and training accuracy:0.998647093773
validation cost:0.0313815437257 and validation accuracy:1.0
Training on :(6, 7)
Time taken:139.194628
Method 3 test accuracy:0.979669034481
Method 3 test accuracy:0.911361396313
Method 3 test accuracy:0.827641427517
Method 3 test accuracy:0.850453197956
Extra training..
Method 3 test accuracy after extra trai:0.972104012966
Method 3 test accuracy after extra trai:0.921155750751
Method 3 test accuracy after extra trai:0.862860202789
Method 3 test accuracy after extra trai:0.914400815964
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.181167438626 and training accuracy:0.961724698544
validation cost:0.18307903409 and validation accuracy:0.958568751812
Training on :(8, 9)
training cost:0.123298130929 and training accuracy:0.970292448997
validation cost:0.125557005405 and validation accuracy:0.969868183136
Training on :(8, 9)
training cost:0.0998485609889 and training accuracy:0.975693821907
validation cost:0.102005302906 and validation accuracy:0.975517868996
Training on :(8, 9)
training cost:0.0860515981913 and training accuracy:0.979139506817
validation cost:0.0879942402244 and validation accuracy:0.98116761446
Training on :(8, 9)
Time taken:134.406751156
Method 3 test accuracy:0.978723406792
Method 3 test accuracy:0.887365341187
Method 3 test accuracy:0.817502677441
Method 3 test accuracy:0.86606246233
Method 3 test accuracy:0.66011095047
Extra training..
Method 3 test accuracy after extra trai:0.969739973545
Method 3 test accuracy after extra trai:0.889324188232
Method 3 test accuracy after extra trai:0.812166512012
Method 3 test accuracy after extra trai:0.879657626152
Method 3 test accuracy after extra trai:0.839636921883
Training with lmbda:20308059.8423, 8
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.0560917071998 and training accuracy:0.99809128046
validation cost:0.0573302432895 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0230844113976 and training accuracy:0.998351573944
validation cost:0.0249240230769 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0149912079796 and training accuracy:0.998611807823
validation cost:0.0168148633093 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0112824933603 and training accuracy:0.99895888567
validation cost:0.013022984378 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:144.363873959
Method 3 test accuracy:0.999054372311
Extra training..
Method 3 test accuracy after extra trai:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.177127286792 and training accuracy:0.96027636528
validation cost:0.181349694729 and validation accuracy:0.959558844566
Training on :(2, 3)
training cost:0.0978262871504 and training accuracy:0.975911259651
validation cost:0.102456279099 and validation accuracy:0.972426474094
Training on :(2, 3)
training cost:0.0712583735585 and training accuracy:0.982001662254
validation cost:0.075361289084 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0573512203991 and training accuracy:0.985092282295
validation cost:0.0607381425798 and validation accuracy:0.982536792755
Training on :(2, 3)
Time taken:137.967857122
Method 3 test accuracy:0.987234055996
Method 3 test accuracy:0.919196844101
Extra training..
Method 3 test accuracy after extra trai:0.977304935455
Method 3 test accuracy after extra trai:0.957394719124
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.133111536503 and training accuracy:0.989560961723
validation cost:0.129414483905 and validation accuracy:0.994077026844
Training on :(4, 5)
training cost:0.0701169520617 and training accuracy:0.994536578655
validation cost:0.0636991336942 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0491697080433 and training accuracy:0.995707333088
validation cost:0.0425557605922 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0385769605637 and training accuracy:0.996292710304
validation cost:0.0321723110974 and validation accuracy:1.0
Training on :(4, 5)
Time taken:128.241633177
Method 3 test accuracy:0.983451545238
Method 3 test accuracy:0.892262458801
Method 3 test accuracy:0.847918868065
Extra training..
Method 3 test accuracy after extra trai:0.975886523724
Method 3 test accuracy after extra trai:0.936336934566
Method 3 test accuracy after extra trai:0.866061925888
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.0935435444117 and training accuracy:0.994949042797
validation cost:0.0912909656763 and validation accuracy:0.993613123894
Training on :(6, 7)
training cost:0.0509523823857 and training accuracy:0.997113764286
validation cost:0.0500413328409 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.036668844521 and training accuracy:0.997835278511
validation cost:0.0360532775521 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0292532742023 and training accuracy:0.998466670513
validation cost:0.0287265311927 and validation accuracy:0.999087572098
Training on :(6, 7)
Time taken:139.124980927
Method 3 test accuracy:0.982505917549
Method 3 test accuracy:0.876101851463
Method 3 test accuracy:0.875133395195
Method 3 test accuracy:0.864551842213
Extra training..
Method 3 test accuracy after extra trai:0.972576856613
Method 3 test accuracy after extra trai:0.918217420578
Method 3 test accuracy after extra trai:0.87406617403
Method 3 test accuracy after extra trai:0.916918456554
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.162968322635 and training accuracy:0.967591702938
validation cost:0.162734776735 and validation accuracy:0.967043340206
Training on :(8, 9)
training cost:0.109307430685 and training accuracy:0.974390029907
validation cost:0.109192200005 and validation accuracy:0.976459503174
Training on :(8, 9)
training cost:0.0878904685378 and training accuracy:0.979418873787
validation cost:0.0876291617751 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.0754620432854 and training accuracy:0.982305824757
validation cost:0.0749981403351 and validation accuracy:0.985875725746
Training on :(8, 9)
Time taken:134.642755985
Method 3 test accuracy:0.980141818523
Method 3 test accuracy:0.846718907356
Method 3 test accuracy:0.871398091316
Method 3 test accuracy:0.879657626152
Method 3 test accuracy:0.582450807095
Extra training..
Method 3 test accuracy after extra trai:0.967375874519
Method 3 test accuracy after extra trai:0.887855052948
Method 3 test accuracy after extra trai:0.827641427517
Method 3 test accuracy after extra trai:0.880664646626
Method 3 test accuracy after extra trai:0.834594070911
Training with lmbda:30462089.7634, 9
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.0560917071998 and training accuracy:0.99809128046
validation cost:0.0573302432895 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0230844113976 and training accuracy:0.998351573944
validation cost:0.0249240230769 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0149912079796 and training accuracy:0.998611807823
validation cost:0.0168148633093 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0112824933603 and training accuracy:0.99895888567
validation cost:0.013022984378 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:144.769546986
Method 3 test accuracy:0.999054372311
Extra training..
Method 3 test accuracy after extra trai:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.179137229919 and training accuracy:0.959912717342
validation cost:0.183375924826 and validation accuracy:0.959558844566
Training on :(2, 3)
training cost:0.0993753522635 and training accuracy:0.975729465485
validation cost:0.103996761143 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0725760012865 and training accuracy:0.981638014317
validation cost:0.0766844749451 and validation accuracy:0.980698525906
Training on :(2, 3)
training cost:0.0585091859102 and training accuracy:0.985001385212
validation cost:0.0619165599346 and validation accuracy:0.982536792755
Training on :(2, 3)
Time taken:138.123511076
Method 3 test accuracy:0.987234055996
Method 3 test accuracy:0.918707132339
Extra training..
Method 3 test accuracy after extra trai:0.978250563145
Method 3 test accuracy after extra trai:0.957394719124
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.139820411801 and training accuracy:0.989365875721
validation cost:0.136485487223 and validation accuracy:0.994077026844
Training on :(4, 5)
training cost:0.0740035995841 and training accuracy:0.994243919849
validation cost:0.0677642971277 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0518963597715 and training accuracy:0.995707333088
validation cost:0.0453829616308 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0406937114894 and training accuracy:0.996292710304
validation cost:0.0343504026532 and validation accuracy:0.999012827873
Training on :(4, 5)
Time taken:129.47994709
Method 3 test accuracy:0.982505917549
Method 3 test accuracy:0.874632716179
Method 3 test accuracy:0.881536841393
Extra training..
Method 3 test accuracy after extra trai:0.976359367371
Method 3 test accuracy after extra trai:0.935357511044
Method 3 test accuracy after extra trai:0.868730008602
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.100861690938 and training accuracy:0.99485886097
validation cost:0.0986290872097 and validation accuracy:0.992700755596
Training on :(6, 7)
training cost:0.0552909485996 and training accuracy:0.996933341026
validation cost:0.0544827133417 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0398568511009 and training accuracy:0.997745096684
validation cost:0.0393721759319 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0318152867258 and training accuracy:0.998376488686
validation cost:0.0314260385931 and validation accuracy:0.999087572098
Training on :(6, 7)
Time taken:138.861022949
Method 3 test accuracy:0.98156028986
Method 3 test accuracy:0.865328133106
Method 3 test accuracy:0.893810033798
Method 3 test accuracy:0.864048361778
Extra training..
Method 3 test accuracy after extra trai:0.972576856613
Method 3 test accuracy after extra trai:0.918707132339
Method 3 test accuracy after extra trai:0.87406617403
Method 3 test accuracy after extra trai:0.915911376476
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.173859357834 and training accuracy:0.967219233513
validation cost:0.173432424664 and validation accuracy:0.967043340206
Training on :(8, 9)
training cost:0.117183916271 and training accuracy:0.973738133907
validation cost:0.116820953786 and validation accuracy:0.975517868996
Training on :(8, 9)
training cost:0.09463994205 and training accuracy:0.977463185787
validation cost:0.0941612273455 and validation accuracy:0.979284346104
Training on :(8, 9)
training cost:0.0815606489778 and training accuracy:0.981002032757
validation cost:0.0809277370572 and validation accuracy:0.98399245739
Training on :(8, 9)
Time taken:134.28659606
Method 3 test accuracy:0.978723406792
Method 3 test accuracy:0.831537723541
Method 3 test accuracy:0.878335118294
Method 3 test accuracy:0.873615324497
Method 3 test accuracy:0.623802304268
Extra training..
Method 3 test accuracy after extra trai:0.967375874519
Method 3 test accuracy after extra trai:0.887365341187
Method 3 test accuracy after extra trai:0.826040565968
Method 3 test accuracy after extra trai:0.876636445522
Method 3 test accuracy after extra trai:0.833585500717
Training with lmbda:20308059.8423, 10
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.0551121495664 and training accuracy:0.998178005219
validation cost:0.0553850792348 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0225060489029 and training accuracy:0.998351573944
validation cost:0.0235052797943 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.014548827894 and training accuracy:0.998872101307
validation cost:0.0156352259219 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0109188891947 and training accuracy:0.99895888567
validation cost:0.0120074385777 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:144.764646053
Method 3 test accuracy:0.999054372311
Extra training..
Method 3 test accuracy after extra trai:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.172353744507 and training accuracy:0.962548851967
validation cost:0.176611214876 and validation accuracy:0.960477948189
Training on :(2, 3)
training cost:0.0956995487213 and training accuracy:0.976638495922
validation cost:0.10134871304 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0697918608785 and training accuracy:0.982547044754
validation cost:0.0749620869756 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0561297126114 and training accuracy:0.986274003983
validation cost:0.0604806095362 and validation accuracy:0.981617629528
Training on :(2, 3)
Time taken:138.076318979
Method 3 test accuracy:0.986288428307
Method 3 test accuracy:0.935357511044
Extra training..
Method 3 test accuracy after extra trai:0.979196190834
Method 3 test accuracy after extra trai:0.961312413216
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.130611270666 and training accuracy:0.99014633894
validation cost:0.127402558923 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.068724475801 and training accuracy:0.994536578655
validation cost:0.0625447630882 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.048284471035 and training accuracy:0.995707333088
validation cost:0.0417766198516 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0379704274237 and training accuracy:0.996097564697
validation cost:0.0316060595214 and validation accuracy:1.0
Training on :(4, 5)
Time taken:128.806128025
Method 3 test accuracy:0.982978701591
Method 3 test accuracy:0.941723823547
Method 3 test accuracy:0.66808962822
Extra training..
Method 3 test accuracy after extra trai:0.979196190834
Method 3 test accuracy after extra trai:0.94270324707
Method 3 test accuracy after extra trai:0.845250785351
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.0951158925891 and training accuracy:0.995039224625
validation cost:0.0913835689425 and validation accuracy:0.993613123894
Training on :(6, 7)
training cost:0.0515707656741 and training accuracy:0.997203946114
validation cost:0.0492933727801 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0370814725757 and training accuracy:0.997925519943
validation cost:0.0351762510836 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0295848250389 and training accuracy:0.998376488686
validation cost:0.0278410054743 and validation accuracy:0.999087572098
Training on :(6, 7)
Time taken:137.753988981
Method 3 test accuracy:0.978723406792
Method 3 test accuracy:0.923114597797
Method 3 test accuracy:0.751334071159
Method 3 test accuracy:0.889728069305
Extra training..
Method 3 test accuracy after extra trai:0.971158385277
Method 3 test accuracy after extra trai:0.92409402132
Method 3 test accuracy after extra trai:0.859658479691
Method 3 test accuracy after extra trai:0.924471318722
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.161812782288 and training accuracy:0.965542912483
validation cost:0.163936406374 and validation accuracy:0.963276863098
Training on :(8, 9)
training cost:0.110402092338 and training accuracy:0.974296867847
validation cost:0.112709537148 and validation accuracy:0.975517868996
Training on :(8, 9)
training cost:0.0895037725568 and training accuracy:0.977928876877
validation cost:0.0916390195489 and validation accuracy:0.979284346104
Training on :(8, 9)
training cost:0.0772219449282 and training accuracy:0.980163931847
validation cost:0.0791233628988 and validation accuracy:0.982109248638
Training on :(8, 9)
Time taken:135.005560875
Method 3 test accuracy:0.974468111992
Method 3 test accuracy:0.894711077213
Method 3 test accuracy:0.727854847908
Method 3 test accuracy:0.897280991077
Method 3 test accuracy:0.626828014851
Extra training..
Method 3 test accuracy after extra trai:0.967375874519
Method 3 test accuracy after extra trai:0.894221365452
Method 3 test accuracy after extra trai:0.80683028698
Method 3 test accuracy after extra trai:0.882678747177
Method 3 test accuracy after extra trai:0.842662632465
Training with lmbda:30462089.7634, 11
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.0551121495664 and training accuracy:0.998178005219
validation cost:0.0553850792348 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0225060489029 and training accuracy:0.998351573944
validation cost:0.0235052797943 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.014548827894 and training accuracy:0.998872101307
validation cost:0.0156352259219 and validation accuracy:0.998244047165
Training on :(0, 1)
training cost:0.0109188891947 and training accuracy:0.99895888567
validation cost:0.0120074385777 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:155.387768984
Method 3 test accuracy:0.999054372311
Extra training..
Method 3 test accuracy after extra trai:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.174234777689 and training accuracy:0.962457954884
validation cost:0.178486257792 and validation accuracy:0.960477948189
Training on :(2, 3)
training cost:0.0970977172256 and training accuracy:0.976274907589
validation cost:0.102731876075 and validation accuracy:0.970588207245
Training on :(2, 3)
training cost:0.0709616392851 and training accuracy:0.982365250587
validation cost:0.076163880527 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0571512654424 and training accuracy:0.986092150211
validation cost:0.0615561157465 and validation accuracy:0.980698525906
Training on :(2, 3)
Time taken:144.828455925
Method 3 test accuracy:0.986761212349
Method 3 test accuracy:0.935357511044
Extra training..
Method 3 test accuracy after extra trai:0.979196190834
Method 3 test accuracy after extra trai:0.961312413216
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.136917114258 and training accuracy:0.99014633894
validation cost:0.134103387594 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0725125521421 and training accuracy:0.994341492653
validation cost:0.0665539875627 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0510011985898 and training accuracy:0.995804905891
validation cost:0.0446213856339 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0401034131646 and training accuracy:0.996097564697
validation cost:0.0338150151074 and validation accuracy:1.0
Training on :(4, 5)
Time taken:129.414355993
Method 3 test accuracy:0.983451545238
Method 3 test accuracy:0.945151805878
Method 3 test accuracy:0.595517635345
Extra training..
Method 3 test accuracy after extra trai:0.979669034481
Method 3 test accuracy after extra trai:0.941234111786
Method 3 test accuracy after extra trai:0.838847398758
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.103073693812 and training accuracy:0.995039224625
validation cost:0.0992664769292 and validation accuracy:0.993613123894
Training on :(6, 7)
training cost:0.056355163455 and training accuracy:0.997113764286
validation cost:0.0540618114173 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0405761823058 and training accuracy:0.997925519943
validation cost:0.0386753156781 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0323611758649 and training accuracy:0.998286306858
validation cost:0.0306249260902 and validation accuracy:0.999087572098
Training on :(6, 7)
Time taken:138.858330011
Method 3 test accuracy:0.979196190834
Method 3 test accuracy:0.930460333824
Method 3 test accuracy:0.692636072636
Method 3 test accuracy:0.895266890526
Extra training..
Method 3 test accuracy after extra trai:0.971631228924
Method 3 test accuracy after extra trai:0.924583733082
Method 3 test accuracy after extra trai:0.847918868065
Method 3 test accuracy after extra trai:0.920443117619
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.172078937292 and training accuracy:0.964704811573
validation cost:0.174101412296 and validation accuracy:0.963276863098
Training on :(8, 9)
training cost:0.118011184037 and training accuracy:0.972806870937
validation cost:0.120248906314 and validation accuracy:0.971751391888
Training on :(8, 9)
training cost:0.0961526408792 and training accuracy:0.976531922817
validation cost:0.0982870236039 and validation accuracy:0.976459503174
Training on :(8, 9)
training cost:0.083327434957 and training accuracy:0.979325771332
validation cost:0.0852804109454 and validation accuracy:0.98116761446
Training on :(8, 9)
Time taken:134.63853693
Method 3 test accuracy:0.974940896034
Method 3 test accuracy:0.902546525002
Method 3 test accuracy:0.656883656979
Method 3 test accuracy:0.896777451038
Method 3 test accuracy:0.644982337952
Extra training..
Method 3 test accuracy after extra trai:0.967848718166
Method 3 test accuracy after extra trai:0.892752230167
Method 3 test accuracy after extra trai:0.790288150311
Method 3 test accuracy after extra trai:0.879657626152
Method 3 test accuracy after extra trai:0.838628351688
Training with lmbda:20308059.8423, 12
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.0536804720759 and training accuracy:0.997917771339
validation cost:0.0552427694201 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0221254955977 and training accuracy:0.998351573944
validation cost:0.0239604897797 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0143707823008 and training accuracy:0.998872101307
validation cost:0.0160710196942 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0108183240518 and training accuracy:0.999045610428
validation cost:0.0123760458082 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:143.942449093
Method 3 test accuracy:0.999054372311
Extra training..
Method 3 test accuracy after extra trai:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.175298959017 and training accuracy:0.962185263634
validation cost:0.178326755762 and validation accuracy:0.962316155434
Training on :(2, 3)
training cost:0.097148373723 and training accuracy:0.976638495922
validation cost:0.101975932717 and validation accuracy:0.976102948189
Training on :(2, 3)
training cost:0.0708995908499 and training accuracy:0.983365178108
validation cost:0.0755577236414 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0570811145008 and training accuracy:0.985910356045
validation cost:0.0611222982407 and validation accuracy:0.981617629528
Training on :(2, 3)
Time taken:138.215154886
Method 3 test accuracy:0.989125311375
Method 3 test accuracy:0.921155750751
Extra training..
Method 3 test accuracy after extra trai:0.982505917549
Method 3 test accuracy after extra trai:0.956905007362
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.13607467711 and training accuracy:0.989170730114
validation cost:0.132473826408 and validation accuracy:0.994077026844
Training on :(4, 5)
training cost:0.0711994245648 and training accuracy:0.993756115437
validation cost:0.0647230297327 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.04980064556 and training accuracy:0.995121955872
validation cost:0.0430971644819 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0390145629644 and training accuracy:0.99590241909
validation cost:0.0325070843101 and validation accuracy:0.999012827873
Training on :(4, 5)
Time taken:128.917185068
Method 3 test accuracy:0.986761212349
Method 3 test accuracy:0.921155750751
Method 3 test accuracy:0.738527238369
Extra training..
Method 3 test accuracy after extra trai:0.98156028986
Method 3 test accuracy after extra trai:0.934867799282
Method 3 test accuracy after extra trai:0.856456756592
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.0953091681004 and training accuracy:0.995129406452
validation cost:0.0919786542654 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0518285408616 and training accuracy:0.997203946114
validation cost:0.0499598942697 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.037259850651 and training accuracy:0.997925519943
validation cost:0.0357767157257 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0297109112144 and training accuracy:0.998376488686
validation cost:0.0283927787095 and validation accuracy:0.9981752038
Training on :(6, 7)
Time taken:138.330507994
Method 3 test accuracy:0.984397172928
Method 3 test accuracy:0.90205681324
Method 3 test accuracy:0.799359679222
Method 3 test accuracy:0.879657626152
Extra training..
Method 3 test accuracy after extra trai:0.973995268345
Method 3 test accuracy after extra trai:0.918217420578
Method 3 test accuracy after extra trai:0.874599814415
Method 3 test accuracy after extra trai:0.926485419273
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.165381133556 and training accuracy:0.964425384998
validation cost:0.166257381439 and validation accuracy:0.96233522892
Training on :(8, 9)
training cost:0.112863078713 and training accuracy:0.973365604877
validation cost:0.113580577075 and validation accuracy:0.972693026066
Training on :(8, 9)
training cost:0.0913694500923 and training accuracy:0.977742612362
validation cost:0.0917146503925 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.0786854922771 and training accuracy:0.980536401272
validation cost:0.0786927714944 and validation accuracy:0.98399245739
Training on :(8, 9)
Time taken:134.910398006
Method 3 test accuracy:0.983451545238
Method 3 test accuracy:0.882957875729
Method 3 test accuracy:0.792422652245
Method 3 test accuracy:0.891238689423
Method 3 test accuracy:0.60766518116
Extra training..
Method 3 test accuracy after extra trai:0.968794345856
Method 3 test accuracy after extra trai:0.89177274704
Method 3 test accuracy after extra trai:0.818569898605
Method 3 test accuracy after extra trai:0.882678747177
Method 3 test accuracy after extra trai:0.841149747372
Training with lmbda:30462089.7634, 13
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.0536804720759 and training accuracy:0.997917771339
validation cost:0.0552427694201 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0221254955977 and training accuracy:0.998351573944
validation cost:0.0239604897797 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0143707823008 and training accuracy:0.998872101307
validation cost:0.0160710196942 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0108183240518 and training accuracy:0.999045610428
validation cost:0.0123760458082 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:144.35054493
Method 3 test accuracy:0.999054372311
Extra training..
Method 3 test accuracy after extra trai:0.999054372311
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.17732411623 and training accuracy:0.962185263634
validation cost:0.180330246687 and validation accuracy:0.962316155434
Training on :(2, 3)
training cost:0.098709307611 and training accuracy:0.976638495922
validation cost:0.103487834334 and validation accuracy:0.974264681339
Training on :(2, 3)
training cost:0.0722185447812 and training accuracy:0.983183324337
validation cost:0.0768501609564 and validation accuracy:0.981617629528
Training on :(2, 3)
training cost:0.0582318231463 and training accuracy:0.985728561878
validation cost:0.0622624158859 and validation accuracy:0.981617629528
Training on :(2, 3)
Time taken:137.520015955
Method 3 test accuracy:0.989125311375
Method 3 test accuracy:0.925073444843
Extra training..
Method 3 test accuracy after extra trai:0.98156028986
Method 3 test accuracy after extra trai:0.957394719124
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.142495930195 and training accuracy:0.988878071308
validation cost:0.139019161463 and validation accuracy:0.994077026844
Training on :(4, 5)
training cost:0.075058311224 and training accuracy:0.993756115437
validation cost:0.068626858294 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.0525645725429 and training accuracy:0.995121955872
validation cost:0.0458572618663 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0411762483418 and training accuracy:0.995707333088
validation cost:0.0346418991685 and validation accuracy:0.999012827873
Training on :(4, 5)
Time taken:130.295991182
Method 3 test accuracy:0.98581558466
Method 3 test accuracy:0.922624886036
Method 3 test accuracy:0.740661680698
Extra training..
Method 3 test accuracy after extra trai:0.982033073902
Method 3 test accuracy after extra trai:0.937316358089
Method 3 test accuracy after extra trai:0.858057618141
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.102822333574 and training accuracy:0.994949042797
validation cost:0.0994498729706 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0564254149795 and training accuracy:0.996933341026
validation cost:0.05456065014 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0406745783985 and training accuracy:0.997835278511
validation cost:0.0392163805664 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0324678383768 and training accuracy:0.998196065426
validation cost:0.0311851855367 and validation accuracy:0.9981752038
Training on :(6, 7)
Time taken:139.081988096
Method 3 test accuracy:0.983924329281
Method 3 test accuracy:0.905974507332
Method 3 test accuracy:0.803628623486
Method 3 test accuracy:0.848439097404
Extra training..
Method 3 test accuracy after extra trai:0.974468111992
Method 3 test accuracy after extra trai:0.921645462513
Method 3 test accuracy after extra trai:0.869797229767
Method 3 test accuracy after extra trai:0.921450138092
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.176167830825 and training accuracy:0.963866651058
validation cost:0.17679682374 and validation accuracy:0.95951038599
Training on :(8, 9)
training cost:0.120794303715 and training accuracy:0.972806870937
validation cost:0.121324397624 and validation accuracy:0.972693026066
Training on :(8, 9)
training cost:0.0982307270169 and training accuracy:0.976531922817
validation cost:0.0984504967928 and validation accuracy:0.979284346104
Training on :(8, 9)
training cost:0.0849253758788 and training accuracy:0.979232609272
validation cost:0.0848564580083 and validation accuracy:0.982109248638
Training on :(8, 9)
Time taken:134.885094881
Method 3 test accuracy:0.983451545238
Method 3 test accuracy:0.885896205902
Method 3 test accuracy:0.787086427212
Method 3 test accuracy:0.863544821739
Method 3 test accuracy:0.643469512463
Extra training..
Method 3 test accuracy after extra trai:0.969267129898
Method 3 test accuracy after extra trai:0.895200788975
Method 3 test accuracy after extra trai:0.812166512012
Method 3 test accuracy after extra trai:0.873615324497
Method 3 test accuracy after extra trai:0.839636921883
Training with lmbda:20308059.8423, 14
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.054135248065 and training accuracy:0.998004496098
validation cost:0.0547703653574 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226018596441 and training accuracy:0.998351573944
validation cost:0.0237815957516 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0147457355633 and training accuracy:0.99895888567
validation cost:0.0159146208316 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0111242728308 and training accuracy:0.99895888567
validation cost:0.0122250914574 and validation accuracy:0.997366130352
Training on :(0, 1)
Time taken:143.997546911
Method 3 test accuracy:0.998581588268
Extra training..
Method 3 test accuracy after extra trai:0.998581588268
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.173513427377 and training accuracy:0.963276088238
validation cost:0.178897291422 and validation accuracy:0.960477948189
Training on :(2, 3)
training cost:0.0969279035926 and training accuracy:0.976547598839
validation cost:0.102853238583 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0711780562997 and training accuracy:0.982637941837
validation cost:0.0763814151287 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0575596317649 and training accuracy:0.986183047295
validation cost:0.0618864521384 and validation accuracy:0.983455896378
Training on :(2, 3)
Time taken:137.954248905
Method 3 test accuracy:0.953664302826
Method 3 test accuracy:0.970127344131
Extra training..
Method 3 test accuracy after extra trai:0.977304935455
Method 3 test accuracy after extra trai:0.958374142647
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.133149206638 and training accuracy:0.989951193333
validation cost:0.129248097539 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0698135867715 and training accuracy:0.994634151459
validation cost:0.0632747486234 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.0489182323217 and training accuracy:0.99590241909
validation cost:0.0422627776861 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.038401696831 and training accuracy:0.996487796307
validation cost:0.0320140086114 and validation accuracy:1.0
Training on :(4, 5)
Time taken:129.881681919
Method 3 test accuracy:0.938061475754
Method 3 test accuracy:0.95935356617
Method 3 test accuracy:0.738527238369
Extra training..
Method 3 test accuracy after extra trai:0.977304935455
Method 3 test accuracy after extra trai:0.939764916897
Method 3 test accuracy after extra trai:0.852721452713
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.0935730859637 and training accuracy:0.995129406452
validation cost:0.0906948074698 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0501976273954 and training accuracy:0.997654914856
validation cost:0.048805128783 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0358056090772 and training accuracy:0.998196065426
validation cost:0.0347996391356 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.02840664424 and training accuracy:0.998466670513
validation cost:0.0275528915226 and validation accuracy:0.999087572098
Training on :(6, 7)
Time taken:138.851990938
Method 3 test accuracy:0.880378246307
Method 3 test accuracy:0.94074434042
Method 3 test accuracy:0.790821790695
Method 3 test accuracy:0.927492439747
Extra training..
Method 3 test accuracy after extra trai:0.966903090477
Method 3 test accuracy after extra trai:0.922624886036
Method 3 test accuracy after extra trai:0.870864450932
Method 3 test accuracy after extra trai:0.924471318722
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.165393382311 and training accuracy:0.965449810028
validation cost:0.165284857154 and validation accuracy:0.966101706028
Training on :(8, 9)
training cost:0.112540133297 and training accuracy:0.972806870937
validation cost:0.112495996058 and validation accuracy:0.975517868996
Training on :(8, 9)
training cost:0.0909292325377 and training accuracy:0.978021979332
validation cost:0.0906835272908 and validation accuracy:0.982109248638
Training on :(8, 9)
training cost:0.0781559199095 and training accuracy:0.981281459332
validation cost:0.0776641070843 and validation accuracy:0.984934091568
Training on :(8, 9)
Time taken:135.48269701
Method 3 test accuracy:0.879432618618
Method 3 test accuracy:0.909892261028
Method 3 test accuracy:0.757203817368
Method 3 test accuracy:0.921953678131
Method 3 test accuracy:0.670196652412
Extra training..
Method 3 test accuracy after extra trai:0.963593363762
Method 3 test accuracy after extra trai:0.89373165369
Method 3 test accuracy after extra trai:0.812700092793
Method 3 test accuracy after extra trai:0.885196387768
Method 3 test accuracy after extra trai:0.840645492077
Training with lmbda:30462089.7634, 15
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.054135248065 and training accuracy:0.998004496098
validation cost:0.0547703653574 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226018596441 and training accuracy:0.998351573944
validation cost:0.0237815957516 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0147457355633 and training accuracy:0.99895888567
validation cost:0.0159146208316 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0111242728308 and training accuracy:0.99895888567
validation cost:0.0122250914574 and validation accuracy:0.997366130352
Training on :(0, 1)
Time taken:144.295533895
Method 3 test accuracy:0.998581588268
Extra training..
Method 3 test accuracy after extra trai:0.998581588268
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.175582334399 and training accuracy:0.963094234467
validation cost:0.180952474475 and validation accuracy:0.960477948189
Training on :(2, 3)
training cost:0.0985320657492 and training accuracy:0.976365804672
validation cost:0.10442866385 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0725395828485 and training accuracy:0.982547044754
validation cost:0.0777347907424 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0587511844933 and training accuracy:0.986274003983
validation cost:0.0630826354027 and validation accuracy:0.983455896378
Training on :(2, 3)
Time taken:138.229244947
Method 3 test accuracy:0.953664302826
Method 3 test accuracy:0.970617055893
Extra training..
Method 3 test accuracy after extra trai:0.977304935455
Method 3 test accuracy after extra trai:0.958374142647
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.139826893806 and training accuracy:0.989853680134
validation cost:0.136235952377 and validation accuracy:0.995064139366
Training on :(4, 5)
training cost:0.0738286525011 and training accuracy:0.994439005852
validation cost:0.0674533843994 and validation accuracy:0.998025655746
Training on :(4, 5)
training cost:0.05180317536 and training accuracy:0.995999991894
validation cost:0.0452457256615 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0406726971269 and training accuracy:0.996292710304
validation cost:0.0343485288322 and validation accuracy:1.0
Training on :(4, 5)
Time taken:129.232310057
Method 3 test accuracy:0.938534259796
Method 3 test accuracy:0.958374142647
Method 3 test accuracy:0.743863403797
Extra training..
Method 3 test accuracy after extra trai:0.977304935455
Method 3 test accuracy after extra trai:0.940254628658
Method 3 test accuracy after extra trai:0.851120591164
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.100910522044 and training accuracy:0.994949042797
validation cost:0.0979874804616 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0545453466475 and training accuracy:0.997294127941
validation cost:0.0531822964549 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.0390099361539 and training accuracy:0.998196065426
validation cost:0.0380570292473 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0310077201575 and training accuracy:0.998466670513
validation cost:0.0302127469331 and validation accuracy:0.999087572098
Training on :(6, 7)
Time taken:139.976118088
Method 3 test accuracy:0.897399544716
Method 3 test accuracy:0.943682670593
Method 3 test accuracy:0.79188901186
Method 3 test accuracy:0.903323233128
Extra training..
Method 3 test accuracy after extra trai:0.968794345856
Method 3 test accuracy after extra trai:0.925563156605
Method 3 test accuracy after extra trai:0.866595506668
Method 3 test accuracy after extra trai:0.921953678131
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.176205158234 and training accuracy:0.965077280998
validation cost:0.17611554265 and validation accuracy:0.964218437672
Training on :(8, 9)
training cost:0.12039860338 and training accuracy:0.971782445908
validation cost:0.120318755507 and validation accuracy:0.974576294422
Training on :(8, 9)
training cost:0.0976915732026 and training accuracy:0.976904451847
validation cost:0.0974344685674 and validation accuracy:0.98116761446
Training on :(8, 9)
training cost:0.0842807665467 and training accuracy:0.979139506817
validation cost:0.0838046222925 and validation accuracy:0.983050823212
Training on :(8, 9)
Time taken:134.568964958
Method 3 test accuracy:0.892198562622
Method 3 test accuracy:0.911851108074
Method 3 test accuracy:0.755069375038
Method 3 test accuracy:0.897280991077
Method 3 test accuracy:0.715078175068
Extra training..
Method 3 test accuracy after extra trai:0.965957462788
Method 3 test accuracy after extra trai:0.896669924259
Method 3 test accuracy after extra trai:0.798826038837
Method 3 test accuracy after extra trai:0.876636445522
Method 3 test accuracy after extra trai:0.8366112113
Training with lmbda:20308059.8423, 16
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.0556595101953 and training accuracy:0.997917771339
validation cost:0.0566286668181 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226054172963 and training accuracy:0.998351573944
validation cost:0.024216093123 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0146277258173 and training accuracy:0.998698592186
validation cost:0.0162140671164 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.010999395512 and training accuracy:0.99895888567
validation cost:0.0124963019043 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:144.385536194
Method 3 test accuracy:0.998581588268
Extra training..
Method 3 test accuracy after extra trai:0.998581588268
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.175295725465 and training accuracy:0.962003469467
validation cost:0.17899261415 and validation accuracy:0.958639681339
Training on :(2, 3)
training cost:0.0970592573285 and training accuracy:0.976729393005
validation cost:0.102138839662 and validation accuracy:0.971507370472
Training on :(2, 3)
training cost:0.0707861855626 and training accuracy:0.98300153017
validation cost:0.0755029246211 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0569494441152 and training accuracy:0.985455870628
validation cost:0.0609613992274 and validation accuracy:0.980698525906
Training on :(2, 3)
Time taken:138.556399822
Method 3 test accuracy:0.989598095417
Method 3 test accuracy:0.922624886036
Extra training..
Method 3 test accuracy after extra trai:0.980141818523
Method 3 test accuracy after extra trai:0.95935356617
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.132356345654 and training accuracy:0.990243911743
validation cost:0.129243910313 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.069614879787 and training accuracy:0.994731724262
validation cost:0.0633565485477 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0487425997853 and training accuracy:0.99590241909
validation cost:0.0421532355249 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0381969548762 and training accuracy:0.996487796307
validation cost:0.0317724309862 and validation accuracy:1.0
Training on :(4, 5)
Time taken:128.847719908
Method 3 test accuracy:0.986761212349
Method 3 test accuracy:0.931439757347
Method 3 test accuracy:0.595517635345
Extra training..
Method 3 test accuracy after extra trai:0.979669034481
Method 3 test accuracy after extra trai:0.937806069851
Method 3 test accuracy after extra trai:0.848986148834
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.0930539220572 and training accuracy:0.995760798454
validation cost:0.0901347473264 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0503677614033 and training accuracy:0.997564733028
validation cost:0.0489712134004 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0362119823694 and training accuracy:0.998015701771
validation cost:0.0351822711527 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0288841519505 and training accuracy:0.998556852341
validation cost:0.0279944688082 and validation accuracy:0.999087572098
Training on :(6, 7)
Time taken:138.907145023
Method 3 test accuracy:0.984397172928
Method 3 test accuracy:0.907933413982
Method 3 test accuracy:0.692636072636
Method 3 test accuracy:0.885196387768
Extra training..
Method 3 test accuracy after extra trai:0.973049640656
Method 3 test accuracy after extra trai:0.921645462513
Method 3 test accuracy after extra trai:0.858057618141
Method 3 test accuracy after extra trai:0.922960698605
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.164435997605 and training accuracy:0.964239180088
validation cost:0.163218036294 and validation accuracy:0.963276863098
Training on :(8, 9)
training cost:0.111688882113 and training accuracy:0.974203765392
validation cost:0.110651724041 and validation accuracy:0.974576294422
Training on :(8, 9)
training cost:0.0903365164995 and training accuracy:0.977649450302
validation cost:0.0892153084278 and validation accuracy:0.980225980282
Training on :(8, 9)
training cost:0.0777892917395 and training accuracy:0.981095194817
validation cost:0.0765197128057 and validation accuracy:0.984934091568
Training on :(8, 9)
Time taken:134.8635149
Method 3 test accuracy:0.982505917549
Method 3 test accuracy:0.885896205902
Method 3 test accuracy:0.662219822407
Method 3 test accuracy:0.892245709896
Method 3 test accuracy:0.634896636009
Extra training..
Method 3 test accuracy after extra trai:0.968321502209
Method 3 test accuracy after extra trai:0.895200788975
Method 3 test accuracy after extra trai:0.799359679222
Method 3 test accuracy after extra trai:0.88418930769
Method 3 test accuracy after extra trai:0.843166947365
Training with lmbda:30462089.7634, 17
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.0556595101953 and training accuracy:0.997917771339
validation cost:0.0566286668181 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226054172963 and training accuracy:0.998351573944
validation cost:0.024216093123 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0146277258173 and training accuracy:0.998698592186
validation cost:0.0162140671164 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.010999395512 and training accuracy:0.99895888567
validation cost:0.0124963019043 and validation accuracy:0.998244047165
Training on :(0, 1)
Time taken:145.028650999
Method 3 test accuracy:0.998581588268
Extra training..
Method 3 test accuracy after extra trai:0.998581588268
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.177412077785 and training accuracy:0.961821675301
validation cost:0.181069016457 and validation accuracy:0.958639681339
Training on :(2, 3)
training cost:0.0986515209079 and training accuracy:0.976820290089
validation cost:0.103674091399 and validation accuracy:0.972426474094
Training on :(2, 3)
training cost:0.0721189901233 and training accuracy:0.982819736004
validation cost:0.0768073648214 and validation accuracy:0.979779422283
Training on :(2, 3)
training cost:0.0581107214093 and training accuracy:0.985183179379
validation cost:0.0621227659285 and validation accuracy:0.980698525906
Training on :(2, 3)
Time taken:138.342305183
Method 3 test accuracy:0.989598095417
Method 3 test accuracy:0.922135174274
Extra training..
Method 3 test accuracy after extra trai:0.98061466217
Method 3 test accuracy after extra trai:0.95935356617
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.139053091407 and training accuracy:0.990048766136
validation cost:0.136354610324 and validation accuracy:0.996051311493
Training on :(4, 5)
training cost:0.0735111758113 and training accuracy:0.994731724262
validation cost:0.0674653723836 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0514899715781 and training accuracy:0.995804905891
validation cost:0.0450155027211 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0403354726732 and training accuracy:0.996487796307
validation cost:0.0339740663767 and validation accuracy:1.0
Training on :(4, 5)
Time taken:129.544763088
Method 3 test accuracy:0.988179683685
Method 3 test accuracy:0.930950045586
Method 3 test accuracy:0.601387381554
Extra training..
Method 3 test accuracy after extra trai:0.979669034481
Method 3 test accuracy after extra trai:0.938295781612
Method 3 test accuracy after extra trai:0.846318006516
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.100721620023 and training accuracy:0.995490193367
validation cost:0.0977532863617 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0549295581877 and training accuracy:0.997564733028
validation cost:0.0535682588816 and validation accuracy:0.997262775898
Training on :(6, 7)
training cost:0.0395097620785 and training accuracy:0.998015701771
validation cost:0.0385582335293 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0314866751432 and training accuracy:0.998376488686
validation cost:0.0306922402233 and validation accuracy:0.999087572098
Training on :(6, 7)
Time taken:138.830854177
Method 3 test accuracy:0.98486995697
Method 3 test accuracy:0.908912837505
Method 3 test accuracy:0.696371376514
Method 3 test accuracy:0.885699927807
Extra training..
Method 3 test accuracy after extra trai:0.973522484303
Method 3 test accuracy after extra trai:0.921155750751
Method 3 test accuracy after extra trai:0.854322314262
Method 3 test accuracy after extra trai:0.92245721817
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.175193324685 and training accuracy:0.963587284088
validation cost:0.173799276352 and validation accuracy:0.96233522892
Training on :(8, 9)
training cost:0.119612805545 and training accuracy:0.971968710423
validation cost:0.118330456316 and validation accuracy:0.970809817314
Training on :(8, 9)
training cost:0.0972027331591 and training accuracy:0.976997554302
validation cost:0.0958811491728 and validation accuracy:0.97834277153
Training on :(8, 9)
training cost:0.0840348228812 and training accuracy:0.979791402817
validation cost:0.0826187133789 and validation accuracy:0.98399245739
Training on :(8, 9)
Time taken:134.165263891
Method 3 test accuracy:0.983451545238
Method 3 test accuracy:0.886385917664
Method 3 test accuracy:0.662219822407
Method 3 test accuracy:0.887210488319
Method 3 test accuracy:0.645486652851
Extra training..
Method 3 test accuracy after extra trai:0.969267129898
Method 3 test accuracy after extra trai:0.894221365452
Method 3 test accuracy after extra trai:0.79188901186
Method 3 test accuracy after extra trai:0.880664646626
Method 3 test accuracy after extra trai:0.844679772854
Training with lmbda:20308059.8423, 18
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.0543369539082 and training accuracy:0.997570693493
validation cost:0.0553945638239 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226058047265 and training accuracy:0.997917771339
validation cost:0.0243187975138 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0147604439408 and training accuracy:0.998525083065
validation cost:0.0164875015616 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0111444368958 and training accuracy:0.998785376549
validation cost:0.0128030572087 and validation accuracy:0.997366130352
Training on :(0, 1)
Time taken:144.212083817
Method 3 test accuracy:0.998581588268
Extra training..
Method 3 test accuracy after extra trai:0.998108744621
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.172104716301 and training accuracy:0.964094161987
validation cost:0.180323973298 and validation accuracy:0.957720577717
Training on :(2, 3)
training cost:0.095734372735 and training accuracy:0.976547598839
validation cost:0.104238443077 and validation accuracy:0.972426474094
Training on :(2, 3)
training cost:0.0699908733368 and training accuracy:0.983183324337
validation cost:0.077467776835 and validation accuracy:0.978860318661
Training on :(2, 3)
training cost:0.0564038977027 and training accuracy:0.986637592316
validation cost:0.0627030134201 and validation accuracy:0.982536792755
Training on :(2, 3)
Time taken:137.484496832
Method 3 test accuracy:0.975886523724
Method 3 test accuracy:0.952497541904
Extra training..
Method 3 test accuracy after extra trai:0.978723406792
Method 3 test accuracy after extra trai:0.95935356617
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.13411359489 and training accuracy:0.989560961723
validation cost:0.131229937077 and validation accuracy:0.994077026844
Training on :(4, 5)
training cost:0.0701832547784 and training accuracy:0.994634151459
validation cost:0.0642522498965 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0491492524743 and training accuracy:0.995999991894
validation cost:0.0429118648171 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0385529436171 and training accuracy:0.996390223503
validation cost:0.0324784033 and validation accuracy:1.0
Training on :(4, 5)
Time taken:129.009850025
Method 3 test accuracy:0.971158385277
Method 3 test accuracy:0.949559271336
Method 3 test accuracy:0.68089646101
Extra training..
Method 3 test accuracy after extra trai:0.977304935455
Method 3 test accuracy after extra trai:0.939275205135
Method 3 test accuracy after extra trai:0.842049121857
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.0923123955727 and training accuracy:0.995941221714
validation cost:0.0889578834176 and validation accuracy:0.996350347996
Training on :(6, 7)
training cost:0.050219360739 and training accuracy:0.997384309769
validation cost:0.0482273511589 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0362238548696 and training accuracy:0.998105883598
validation cost:0.0345826745033 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0289757698774 and training accuracy:0.9987372756
validation cost:0.0274862349033 and validation accuracy:1.0
Training on :(6, 7)
Time taken:138.812727928
Method 3 test accuracy:0.960756480694
Method 3 test accuracy:0.933398604393
Method 3 test accuracy:0.763607263565
Method 3 test accuracy:0.894763350487
Extra training..
Method 3 test accuracy after extra trai:0.970685601234
Method 3 test accuracy after extra trai:0.918217420578
Method 3 test accuracy after extra trai:0.865528285503
Method 3 test accuracy after extra trai:0.921450138092
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.162153512239 and training accuracy:0.965822339058
validation cost:0.163502201438 and validation accuracy:0.961393594742
Training on :(8, 9)
training cost:0.109738491476 and training accuracy:0.973644971848
validation cost:0.111354701221 and validation accuracy:0.976459503174
Training on :(8, 9)
training cost:0.0885073393583 and training accuracy:0.978953242302
validation cost:0.0899195149541 and validation accuracy:0.98116761446
Training on :(8, 9)
training cost:0.0760596171021 and training accuracy:0.981095194817
validation cost:0.0771894156933 and validation accuracy:0.982109248638
Training on :(8, 9)
Time taken:134.724134922
Method 3 test accuracy:0.956501185894
Method 3 test accuracy:0.906953990459
Method 3 test accuracy:0.745464265347
Method 3 test accuracy:0.900805652142
Method 3 test accuracy:0.655068099499
Extra training..
Method 3 test accuracy after extra trai:0.966903090477
Method 3 test accuracy after extra trai:0.89177274704
Method 3 test accuracy after extra trai:0.8062967062
Method 3 test accuracy after extra trai:0.883182287216
Method 3 test accuracy after extra trai:0.837115466595
Training with lmbda:30462089.7634, 19
Current mask:[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
Test features:(2115, 3630)
Length of test labels:2115
Train features:(11526, 3630)
Length of train labels:11526
Valid features:(1139, 3630)
Length of valid labels:1139
Repeat:0
training cost:2.30258536339 and training accuracy:0.467811912298
validation cost:2.30258536339 and validation accuracy:0.473222136497
Training on :(0, 1)
training cost:0.0543369539082 and training accuracy:0.997570693493
validation cost:0.0553945638239 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0226058047265 and training accuracy:0.997917771339
validation cost:0.0243187975138 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0147604439408 and training accuracy:0.998525083065
validation cost:0.0164875015616 and validation accuracy:0.997366130352
Training on :(0, 1)
training cost:0.0111444368958 and training accuracy:0.998785376549
validation cost:0.0128030572087 and validation accuracy:0.997366130352
Training on :(0, 1)
Time taken:145.099943876
Method 3 test accuracy:0.998581588268
Extra training..
Method 3 test accuracy after extra trai:0.998108744621
Current mask:[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]
Test features:(2042, 3630)
Length of test labels:2042
Train features:(11001, 3630)
Length of train labels:11001
Valid features:(1088, 3630)
Length of valid labels:1088
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(2, 3)
training cost:0.174029320478 and training accuracy:0.964185059071
validation cost:0.182279422879 and validation accuracy:0.957720577717
Training on :(2, 3)
training cost:0.0971557050943 and training accuracy:0.976456701756
validation cost:0.10566649586 and validation accuracy:0.972426474094
Training on :(2, 3)
training cost:0.0711865350604 and training accuracy:0.98327422142
validation cost:0.0786899775267 and validation accuracy:0.977941155434
Training on :(2, 3)
training cost:0.0574555024505 and training accuracy:0.986455798149
validation cost:0.0637934505939 and validation accuracy:0.982536792755
Training on :(2, 3)
Time taken:138.640448093
Method 3 test accuracy:0.975886523724
Method 3 test accuracy:0.952987253666
Extra training..
Method 3 test accuracy after extra trai:0.978723406792
Method 3 test accuracy after extra trai:0.95935356617
Current mask:[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]
Test features:(1874, 3630)
Length of test labels:1874
Train features:(10250, 3630)
Length of train labels:10250
Valid features:(1013, 3630)
Length of valid labels:1013
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(4, 5)
training cost:0.140911459923 and training accuracy:0.988975584507
validation cost:0.1384627074 and validation accuracy:0.993089854717
Training on :(4, 5)
training cost:0.0742115229368 and training accuracy:0.994341492653
validation cost:0.0685358271003 and validation accuracy:0.999012827873
Training on :(4, 5)
training cost:0.0520099401474 and training accuracy:0.995999991894
validation cost:0.0459322221577 and validation accuracy:1.0
Training on :(4, 5)
training cost:0.0407851934433 and training accuracy:0.996487796307
validation cost:0.0348159447312 and validation accuracy:1.0
Training on :(4, 5)
Time taken:128.791535854
Method 3 test accuracy:0.971158385277
Method 3 test accuracy:0.948579847813
Method 3 test accuracy:0.686232686043
Extra training..
Method 3 test accuracy after extra trai:0.977304935455
Method 3 test accuracy after extra trai:0.939764916897
Method 3 test accuracy after extra trai:0.843116343021
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]
Test features:(1986, 3630)
Length of test labels:1986
Train features:(11087, 3630)
Length of train labels:11087
Valid features:(1096, 3630)
Length of valid labels:1096
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(6, 7)
training cost:0.0998879000545 and training accuracy:0.995580434799
validation cost:0.0965028107166 and validation accuracy:0.995437979698
Training on :(6, 7)
training cost:0.0548264048994 and training accuracy:0.997294127941
validation cost:0.0528527200222 and validation accuracy:0.9981752038
Training on :(6, 7)
training cost:0.0396286360919 and training accuracy:0.998105883598
validation cost:0.0380246043205 and validation accuracy:0.999087572098
Training on :(6, 7)
training cost:0.0317057147622 and training accuracy:0.998647093773
validation cost:0.0302600543946 and validation accuracy:1.0
Training on :(6, 7)
Time taken:138.885513067
Method 3 test accuracy:0.958865225315
Method 3 test accuracy:0.934378087521
Method 3 test accuracy:0.76414090395
Method 3 test accuracy:0.892749249935
Extra training..
Method 3 test accuracy after extra trai:0.971158385277
Method 3 test accuracy after extra trai:0.918217420578
Method 3 test accuracy after extra trai:0.859124839306
Method 3 test accuracy after extra trai:0.919939577579
Current mask:[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
Test features:(1983, 3630)
Length of test labels:1983
Train features:(10738, 3630)
Length of train labels:10738
Valid features:(1062, 3630)
Length of valid labels:1062
Repeat:0
training cost:2.30258536339 and training accuracy:0.0
validation cost:2.30258536339 and validation accuracy:0.0
Training on :(8, 9)
training cost:0.172592535615 and training accuracy:0.964891016483
validation cost:0.17379142344 and validation accuracy:0.95951038599
Training on :(8, 9)
training cost:0.117418661714 and training accuracy:0.972527444363
validation cost:0.118905492127 and validation accuracy:0.973634660244
Training on :(8, 9)
training cost:0.0952094495296 and training accuracy:0.977276980877
validation cost:0.0965666621923 and validation accuracy:0.98116761446
Training on :(8, 9)
training cost:0.0822370350361 and training accuracy:0.979698240757
validation cost:0.083379149437 and validation accuracy:0.982109248638
Training on :(8, 9)
Time taken:135.231433153
Method 3 test accuracy:0.956028342247
Method 3 test accuracy:0.908912837505
Method 3 test accuracy:0.740661680698
Method 3 test accuracy:0.896777451038
Method 3 test accuracy:0.664145231247
Extra training..
Method 3 test accuracy after extra trai:0.966903090477
Method 3 test accuracy after extra trai:0.890793323517
Method 3 test accuracy after extra trai:0.797225177288
Method 3 test accuracy after extra trai:0.879154086113
Method 3 test accuracy after extra trai:0.8361068964
Total time:14558.9083831
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Final-accuracy">Final accuracy<a class="anchor-link" href="#Final-accuracy">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">all_test_samples</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">n_test_samples</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">all_test_samples</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">n_test_samples</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">i</span><span class="p">])</span>
<span class="n">all_test_samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">all_test_samples</span><span class="p">)]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">all_prev_task_test_accs</span><span class="p">)</span>

<span class="n">indices</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">15</span><span class="p">]]</span>

<span class="n">np_all_test_accs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">all_prev_task_test_accs</span><span class="p">]</span>
<span class="n">scaled_all_accs</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="p">,</span> <span class="n">all_test_samples</span><span class="p">,</span> <span class="n">np_all_test_accs</span><span class="p">)</span>

<span class="n">sum_scaled</span> <span class="o">=</span> <span class="p">[</span><span class="n">thing</span><span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">all_test_samples</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="k">for</span> <span class="n">thing</span> <span class="ow">in</span> <span class="n">scaled_all_accs</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>
<span class="n">sum_scaled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sum_scaled</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">all_test_samples</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">n_test_samples</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">all_test_samples</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">n_test_samples</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">i</span><span class="p">])</span>
<span class="n">all_test_samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">all_test_samples</span><span class="p">)]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">all_prev_task_test_accs</span><span class="p">)</span>

<span class="n">indices</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">15</span><span class="p">]]</span>

<span class="n">np_all_test_accs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">all_prev_task_test_accs_extra</span><span class="p">]</span>
<span class="n">scaled_all_accs</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="p">,</span> <span class="n">all_test_samples</span><span class="p">,</span> <span class="n">np_all_test_accs</span><span class="p">)</span>

<span class="n">sum_scaled</span> <span class="o">=</span> <span class="p">[</span><span class="n">thing</span><span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">all_test_samples</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="k">for</span> <span class="n">thing</span> <span class="ow">in</span> <span class="n">scaled_all_accs</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>
<span class="n">sum_scaled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sum_scaled</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">sum_scaled</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[22]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[0.99905437, 0.96704355, 0.92124025, 0.91917176, 0.8781    ],
       [0.99905437, 0.96656244, 0.92074283, 0.91742548, 0.87639999],
       [0.99905437, 0.97089246, 0.92372739, 0.92129226, 0.8789    ],
       [0.99905437, 0.97017078, 0.92339578, 0.91979543, 0.8771    ],
       [0.99905437, 0.9677652 , 0.92472228, 0.92328802, 0.8794    ],
       [0.99905437, 0.96752466, 0.92488808, 0.9231633 , 0.87739999],
       [0.99905437, 0.96872745, 0.92505388, 0.9192965 , 0.8826    ],
       [0.99905437, 0.96920857, 0.9253855 , 0.9192965 , 0.88010001],
       [0.99905437, 0.96752465, 0.9283701 , 0.92191594, 0.88140001],
       [0.99905437, 0.96800576, 0.92903335, 0.9217912 , 0.88000001],
       [0.99905437, 0.97041133, 0.92521969, 0.92154172, 0.8808    ],
       [0.99905437, 0.97041133, 0.92289837, 0.91804915, 0.87610002],
       [0.99905437, 0.96993025, 0.9268778 , 0.92478484, 0.88249999],
       [0.99905437, 0.96968969, 0.92837008, 0.92341276, 0.88000001],
       [0.99858159, 0.96800576, 0.92588292, 0.92266435, 0.8811    ],
       [0.99858159, 0.96800576, 0.9255513 , 0.92229013, 0.8771    ],
       [0.99858159, 0.96993022, 0.92488809, 0.92066857, 0.8802    ],
       [0.99858159, 0.97017079, 0.92422483, 0.91967072, 0.8784    ],
       [0.99810874, 0.96920856, 0.92240092, 0.92054384, 0.8791    ],
       [0.99810874, 0.96920856, 0.92289835, 0.91879754, 0.8762    ]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">MultiIndex</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">([</span><span class="n">lmbdas</span><span class="p">],</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;lmbdas&#39;</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">)],</span> <span class="n">data</span><span class="o">=</span><span class="n">sum_scaled</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;spike_mnist_ar1_final_10pc.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[24]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
    </tr>
    <tr>
      <th>lmbdas</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2.030806e+07</th>
      <td>0.999054</td>
      <td>0.967044</td>
      <td>0.921240</td>
      <td>0.919172</td>
      <td>0.8781</td>
    </tr>
    <tr>
      <th>3.046209e+07</th>
      <td>0.999054</td>
      <td>0.966562</td>
      <td>0.920743</td>
      <td>0.917425</td>
      <td>0.8764</td>
    </tr>
    <tr>
      <th>2.030806e+07</th>
      <td>0.999054</td>
      <td>0.970892</td>
      <td>0.923727</td>
      <td>0.921292</td>
      <td>0.8789</td>
    </tr>
    <tr>
      <th>3.046209e+07</th>
      <td>0.999054</td>
      <td>0.970171</td>
      <td>0.923396</td>
      <td>0.919795</td>
      <td>0.8771</td>
    </tr>
    <tr>
      <th>2.030806e+07</th>
      <td>0.999054</td>
      <td>0.967765</td>
      <td>0.924722</td>
      <td>0.923288</td>
      <td>0.8794</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Plots">Plots<a class="anchor-link" href="#Plots">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">group_by_lmbda</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;lmbdas&#39;</span><span class="p">])</span>
<span class="n">df1</span> <span class="o">=</span> <span class="n">group_by_lmbda</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
<span class="n">display</span><span class="p">(</span><span class="n">df1</span><span class="p">)</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">group_by_lmbda</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
<span class="n">display</span><span class="p">(</span><span class="n">df2</span><span class="p">)</span>
<span class="n">df3</span> <span class="o">=</span> <span class="n">group_by_lmbda</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
<span class="n">display</span><span class="p">(</span><span class="n">df3</span><span class="p">)</span>
<span class="n">df4</span> <span class="o">=</span> <span class="n">group_by_lmbda</span><span class="o">.</span><span class="n">median</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
<span class="n">display</span><span class="p">(</span><span class="n">df4</span><span class="p">)</span>
<span class="n">df5</span> <span class="o">=</span> <span class="n">group_by_lmbda</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
<span class="n">display</span><span class="p">(</span><span class="n">df5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>lmbdas</th>
      <th>20308059.84228695</th>
      <th>30462089.763430428</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.998109</td>
      <td>0.998109</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.967044</td>
      <td>0.966562</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.921240</td>
      <td>0.920743</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.919172</td>
      <td>0.917425</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.878100</td>
      <td>0.876100</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>lmbdas</th>
      <th>20308059.84228695</th>
      <th>30462089.763430428</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.999054</td>
      <td>0.999054</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.970892</td>
      <td>0.970411</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.928370</td>
      <td>0.929033</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.924785</td>
      <td>0.923413</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.882600</td>
      <td>0.880100</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>lmbdas</th>
      <th>20308059.84228695</th>
      <th>30462089.763430428</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.998865</td>
      <td>0.998865</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.968944</td>
      <td>0.968896</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.924838</td>
      <td>0.924739</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.921517</td>
      <td>0.920369</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.880410</td>
      <td>0.877880</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>lmbdas</th>
      <th>20308059.84228695</th>
      <th>30462089.763430428</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.999054</td>
      <td>0.999054</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.968968</td>
      <td>0.969209</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.924971</td>
      <td>0.924556</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.921417</td>
      <td>0.919733</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.880500</td>
      <td>0.877250</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>lmbdas</th>
      <th>20308059.84228695</th>
      <th>30462089.763430428</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.000331</td>
      <td>0.000331</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.001329</td>
      <td>0.001303</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.002056</td>
      <td>0.002529</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.001746</td>
      <td>0.002141</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.001534</td>
      <td>0.001627</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1">#fig, ax = plt.subplots(figsize=(4.5,2.5))</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">4.75</span><span class="p">,</span><span class="mf">3.0</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.linewidth&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.markersize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;xtick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">13</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;ytick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;legend.fontsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">df2</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">b</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasks&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[26]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Text(0.5,0,&#39;Tasks&#39;)</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span><span class="mf">3.25</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.linewidth&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.markersize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;xtick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">13</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;ytick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;legend.fontsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">df3</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">b</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasks&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[27]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Text(0.5,0,&#39;Tasks&#39;)</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">Min</span> <span class="o">=</span> <span class="n">df1</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">Max</span> <span class="o">=</span> <span class="n">df2</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">Mean</span> <span class="o">=</span> <span class="n">df3</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">final_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Min&#39;</span><span class="p">:</span><span class="n">Min</span><span class="p">,</span> <span class="s1">&#39;Max&#39;</span><span class="p">:</span><span class="n">Max</span><span class="p">,</span> <span class="s1">&#39;Mean&#39;</span><span class="p">:</span><span class="n">Mean</span><span class="p">})</span>
<span class="n">final_df</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[30]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Max</th>
      <th>Mean</th>
      <th>Min</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.999054</td>
      <td>0.998865</td>
      <td>0.998109</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.970892</td>
      <td>0.968944</td>
      <td>0.967044</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.928370</td>
      <td>0.924838</td>
      <td>0.921240</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.924785</td>
      <td>0.921517</td>
      <td>0.919172</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.882600</td>
      <td>0.880410</td>
      <td>0.878100</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[31]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">final_df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s1">&#39;Task&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">final_df</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[31]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Max</th>
      <th>Mean</th>
      <th>Min</th>
    </tr>
    <tr>
      <th>Task</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.999054</td>
      <td>0.998865</td>
      <td>0.998109</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.970892</td>
      <td>0.968944</td>
      <td>0.967044</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.928370</td>
      <td>0.924838</td>
      <td>0.921240</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.924785</td>
      <td>0.921517</td>
      <td>0.919172</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.882600</td>
      <td>0.880410</td>
      <td>0.878100</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[32]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">4.75</span><span class="p">,</span><span class="mf">3.0</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.linewidth&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;lines.markersize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;xtick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">13</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;ytick.labelsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;legend.fontsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">final_df</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Mean&#39;</span><span class="p">,</span><span class="s1">&#39;Max&#39;</span><span class="p">,</span><span class="s1">&#39;Min&#39;</span><span class="p">],</span><span class="n">x</span><span class="o">=</span><span class="n">final_df</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="nb">str</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span> <span class="nb">str</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)),</span> <span class="nb">str</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">)),</span> <span class="nb">str</span><span class="p">((</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">)),</span> <span class="nb">str</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">))])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">b</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;../outputs/tg_mnist_results_cl/buffered_accuracy.pdf&#39;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;../outputs/tg_mnist_results_cl/buffered_accuracy.png&#39;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;../outputs/tg_mnist_results_cl/buffered_accuracy.eps&#39;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
